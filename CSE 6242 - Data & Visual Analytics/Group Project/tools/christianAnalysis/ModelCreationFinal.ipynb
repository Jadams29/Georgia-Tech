{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseball Pitch Data Analysis\n",
    "Class: cse6242\n",
    "Christian Rivera\n",
    "Team: Philly Philly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(\"player_lookup.csv\")\n",
    "data = pd.read_csv(\"Modeling_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLBID</th>\n",
       "      <th>MLBNAME</th>\n",
       "      <th>last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>664023.0</td>\n",
       "      <td>Ian Happ</td>\n",
       "      <td>Happ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>457918.0</td>\n",
       "      <td>J.A. Happ</td>\n",
       "      <td>Happ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MLBID    MLBNAME  last\n",
       "841  664023.0   Ian Happ  Happ\n",
       "842  457918.0  J.A. Happ  Happ"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players['last'] = players['MLBNAME'].str.split(\" \").str.get(-1)\n",
    "players[players['last']=='Happ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below are the functions to clean the data, select a player and create training and testing data.  All the cleaning functions are called by the dataOrchestrator function so that the user be only concerned with the dataOrchestrator and createTrainTest functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(df):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical attributes + drop not useful attributes\n",
    "    input: df (pitch data)\n",
    "    output: df (cleaned pitched data)\n",
    "    \"\"\"\n",
    "    \n",
    "    attributes = ['stand','outcomelag3','outcomelag2','outcomelag1',\n",
    "                  'pitch_typelag1', 'pitch_typelag2', 'pitch_typelag3']\n",
    "    \n",
    "    for trait in attributes:\n",
    "        try:\n",
    "            dummies = pd.get_dummies(df[trait], prefix = trait)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    attributes = attributes + ['inning1', 'inning2',\n",
    "       'inning3', 'inning4', 'inning5', 'inning6', 'inning7', 'inning8',\n",
    "       'inning9', 'inning10', 'BR_EMPTY', 'BR_1B_2B', 'BR_1B_3B',\n",
    "        'BR_2B_3B','BR_FULL','batting_order1', 'batting_order2', 'batting_order3', 'batting_order4',\n",
    "       'batting_order5', 'batting_order6', 'batting_order7', 'batting_order8',\n",
    "       'batting_order9','pitcher','batter']\n",
    "    df.drop(attributes,axis=1,inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplifyOutcomes(df):\n",
    "    \"\"\"\n",
    "    Standardize pitch outcomes.  Shrink dimension space from 23 results to 6 for\n",
    "    all the \"outcome lag\" columns\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    subs = {'ball':'ball',\n",
    "         'called_strike':'strike',\n",
    "         'catcher_interf':'hit',\n",
    "         'double':'hit',\n",
    "         'double_play':'out',\n",
    "         'field_error':'hit',\n",
    "         'field_out':'out',\n",
    "         'fielders_choice':'hit',\n",
    "         'fielders_choice_out':'out',\n",
    "         'force_out':'out',\n",
    "         'foul':'foul',\n",
    "         'grounded_into_double_play':'out',\n",
    "         'hit_by_pitch':'hit',\n",
    "         'home_run':'score',\n",
    "         'offensive_substitution': 'other',\n",
    "         'sac_bunt': 'score',\n",
    "         'sac_bunt_double_play':'score',\n",
    "         'sac_fly': 'score',\n",
    "         'sac_fly_double_play': 'score',\n",
    "         'single': 'hit',\n",
    "         'swinging_strike':'strike',\n",
    "         'triple': 'hit',\n",
    "         'triple_play':'out'}\n",
    "    \n",
    "    attributes = ['outcomelag1', 'outcomelag2', 'outcomelag3']\n",
    "    for trait in attributes:\n",
    "        df[trait] = df[trait].map(subs)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Determine_Pitch_Type_To_Keep_Pitcher_Specific(the_pitcher_id, the_data=None):\n",
    "    print(\"Determining the PitchTypes to use with pitcher {}\\n\".format(the_pitcher_id))\n",
    "    all_pitch_types = list(data.pitch_type.unique())\n",
    "    # Getting count for each type of pitch\n",
    "    pitch_type_count_dict = the_data.pitch_type.value_counts()\n",
    "    num_of_pitch = len(the_data[\"pitch_type\"])\n",
    "    list_of_pitch_types_used = list(the_data.pitch_type.unique())\n",
    "    threshold = 0.02\n",
    "    knuckle_thresh = 0.5\n",
    "    # Remove woba and swstrike columns relating to pitch types not thrown by the pitcher\n",
    "    for pitchType in all_pitch_types:\n",
    "        if pitchType not in list_of_pitch_types_used:\n",
    "            woba_column_to_remove = \"woba.{}\".format(pitchType)\n",
    "            swstrike_column_to_remove = \"swstrike_pct.{}\".format(pitchType)\n",
    "            if woba_column_to_remove in the_data.columns:\n",
    "                the_data.drop(woba_column_to_remove, axis=1, inplace=True)\n",
    "            if swstrike_column_to_remove in the_data.columns:\n",
    "                the_data.drop(swstrike_column_to_remove, axis=1, inplace=True)\n",
    "\n",
    "    for key, value in pitch_type_count_dict.iteritems():\n",
    "        current_pitch_type_percentage_of_total = value/(len(the_data[\"pitch_type\"]))\n",
    "        # If the pitcher throws more than knuckle_thresh, KN, then we remove all woba and swstrike columns\n",
    "        if (key == \"KN\") and (current_pitch_type_percentage_of_total > knuckle_thresh):\n",
    "            current_pitch_types = list(the_data.pitch_type.unique())\n",
    "            for pitch in current_pitch_types:\n",
    "                if pitch in the_data.columns:\n",
    "                    the_data.drop(pitch, axis=1, inplace=True)\n",
    "                if pitch in the_data.columns:\n",
    "                    the_data.drop(pitch, axis=1, inplace=True)\n",
    "        # Finds and removes pitch types if they have not been used enough by the pitcher\n",
    "        #   specified by the threshold\n",
    "        if current_pitch_type_percentage_of_total < threshold:\n",
    "            print(\"Pitch total {}, current pitch type {} and total {}, percentage {}\".format(\n",
    "                (len(the_data[\"pitch_type\"])), key, value, current_pitch_type_percentage_of_total))\n",
    "            the_data = the_data[the_data.pitch_type != key]\n",
    "            print(\"The number of pitches now {}\".format(len(the_data[\"pitch_type\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillData(df):\n",
    "    \"\"\"\n",
    "    1. Fill NaN values in WOBA fields with mean value of dataset\n",
    "    2. Fill NaN values for all other fields with 0\n",
    "    \"\"\"\n",
    "    \n",
    "    attributes = ['woba.FF','woba.SL', 'woba.CH', 'woba.CU', 'woba.FT', 'woba.SI',\n",
    "                  'woba.FC','woba.FS', 'woba.KC', 'woba.KN','swstrike_pct.FF', 'swstrike_pct.SL',\n",
    "       'swstrike_pct.CH', 'swstrike_pct.CU', 'swstrike_pct.FT',\n",
    "       'swstrike_pct.SI', 'swstrike_pct.FC', 'swstrike_pct.FS',\n",
    "       'swstrike_pct.KC', 'swstrike_pct.KN']#pitch_number','score_diff']\n",
    "    \n",
    "    for trait in attributes:\n",
    "        try:\n",
    "            df[trait] = df[trait].fillna((df[trait].mean()))\n",
    "            #df[trait]=(df[trait]-df[trait].mean())/df[trait].std()\n",
    "            df[trait]=(df[trait]-df[trait].min())/(df[trait].max()-df[trait].min())\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    attributes = ['release_speedlag1', 'release_speedlag2',\n",
    "       'release_speedlag3', 'avg2_release_speed', 'avg3_release_speed',\n",
    "                  'plate_xlag1', 'plate_xlag2', 'plate_xlag3','plate_xlag1', \n",
    "                  'plate_xlag2', 'plate_xlag3', 'plate_zlag1',\n",
    "       'plate_zlag2', 'plate_zlag3', 'avg2_plate_x', 'avg2_plate_z',\n",
    "       'avg3_plate_x', 'avg3_plate_z', 'pfx_xlag1', 'pfx_xlag2', 'pfx_xlag3',\n",
    "       'pfx_zlag1', 'pfx_zlag2', 'pfx_zlag3', 'avg2_pfx_x', 'avg2_pfx_z',\n",
    "       'avg3_pfx_x', 'avg3_pfx_z']\n",
    "    \n",
    "    for trait in attributes:\n",
    "        try:\n",
    "            df[trait] = df[trait].fillna((0))\n",
    "            #df[trait]=(df[trait]-df[trait].mean())/df[trait].std()\n",
    "            df[trait]=(df[trait]-df[trait].min())/(df[trait].max()-df[trait].min())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataOrchestrator(mainData, reference, playerNames = [\"Justin Verlander\"]):\n",
    "    \"\"\"\n",
    "    Receives mainData, MLBID reference data, and specific player name.\n",
    "    \n",
    "    Runs all the above cleaning code to produce a \"cleaned\" dataset that can be \n",
    "    used as an input for the \"createTrainTest\" function\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    mlbids = list(reference[reference['MLBNAME'].isin(playerNames)]['MLBID'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = mainData[mainData['pitcher'].isin(mlbids)]\n",
    "    \n",
    "    Determine_Pitch_Type_To_Keep_Pitcher_Specific(mlbids,df)\n",
    "    \n",
    "    \"\"\"df = df[['game_year','pitch_type', 'pitch_number','game_pitch_number',\n",
    "             'outs_when_up', 'BR_1B',\n",
    "       'BR_2B', 'BR_3B','zero_zero_count',\n",
    "       'zero_one_count', 'zero_two_count', 'one_zero_count', 'one_one_count',\n",
    "       'one_two_count', 'two_zero_count', 'two_one_count', 'two_two_count',\n",
    "       'three_zero_count', 'three_one_count', 'three_two_count', 'score_diff',\n",
    "              'stand','outcomelag1', 'outcomelag2', 'outcomelag3','woba.FF',\n",
    "       'woba.SL', 'woba.CH', 'woba.CU', 'woba.FT', 'woba.SI', 'woba.FC',\n",
    "       'woba.FS', 'woba.KC', 'woba.KN','release_speedlag1', 'release_speedlag2',\n",
    "       'release_speedlag3', 'avg2_release_speed', 'avg3_release_speed','plate_xlag1', 'plate_xlag2', 'plate_xlag3'\n",
    "             ]]\"\"\"\n",
    "    \n",
    "    df = simplifyOutcomes(df)\n",
    "    df = cleanData(df)\n",
    "    \n",
    "    df = fillData(df)\n",
    "    print(\"Number of rows:{0}\".format(len(df)))\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainTest(df,testYear=2018,trainYearStart=2016):\n",
    "    \"\"\"\n",
    "    Create training and testing data outputs\n",
    "    \n",
    "    inputs:\n",
    "        - testYear (int)\n",
    "        - traingYearStart (int): all data starting from this value up to but not including\n",
    "                                the testYear\n",
    "    \n",
    "    outputs:\n",
    "        xTrain, yTrain, xTest, yTest numpy arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    yData = pd.get_dummies(df['pitch_type'])\n",
    "    \n",
    "    yData['game_year'] = df['game_year']\n",
    "    \n",
    "    xTrain = df[(df['game_year'] < testYear) & (df['game_year'] >= trainYearStart)]\n",
    "    xTest = df[df['game_year'] >= testYear]\n",
    "    \n",
    "    xTrain.drop(['game_year','pitch_type'],axis=1,inplace=True)\n",
    "    xTest.drop(['game_year','pitch_type'],axis=1,inplace=True)\n",
    "    \n",
    "    yTrain = yData[(yData['game_year'] < testYear) & (yData['game_year'] >= trainYearStart)]\n",
    "    yTest = yData[yData['game_year'] >= testYear]\n",
    "    \n",
    "    yTrain.drop(['game_year'],axis=1,inplace=True)\n",
    "    yTest.drop(['game_year'],axis=1,inplace=True)\n",
    "    \n",
    "    xTrain = xTrain.values\n",
    "    xTest = xTest.values\n",
    "    yTrain = yTrain.values\n",
    "    yTest = yTest.values\n",
    "    \n",
    "    return xTrain, xTest, yTrain, yTest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procure the cleaned data for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining the PitchTypes to use with pitcher [605483.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:6905\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array precision: 52.15\n"
     ]
    }
   ],
   "source": [
    "cleaned = dataOrchestrator(data, players, playerNames = ['Blake Snell']);\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = createTrainTest(cleaned,2018,2015)\n",
    "\n",
    "resultTrain = yTrain.argmax(axis=1)\n",
    "resultTest = yTest.argmax(axis=1)\n",
    "dtrain = xgb.DMatrix(xTrain, label=resultTrain)\n",
    "dtest = xgb.DMatrix(xTest, label=resultTest)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 4,  # the maximum depth of each tree\n",
    "    \"n_estimators\" :1000,\n",
    "    'learning_rate':0.1,\n",
    "    'eta': 0.1,  # the training step for each iteration\n",
    "    \"min_child_weight\" :1,\n",
    "    \"gamma\" : 1, \n",
    "    \"subsample\": 1,\n",
    "    \"colsample_bytree\" : 1, \n",
    "    \"scale_pos_weight\": 1,\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': yTrain.shape[1],\n",
    "    \"tree_method\" :'gpu_hist',\n",
    "    \"cv\":kfold}  \n",
    "num_round = 100  # the number of training iterations\n",
    "\n",
    "bst = xgb.train(param, dtrain,num_round)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "precision = round(precision_score(resultTest, best_preds, average='micro'),4)\n",
    "print (\"Numpy array precision:\", round(precision*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitch_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>559</td>\n",
       "      <td>19.189839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>588</td>\n",
       "      <td>20.185376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF</th>\n",
       "      <td>1500</td>\n",
       "      <td>51.493306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SL</th>\n",
       "      <td>266</td>\n",
       "      <td>9.131480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pitch_type       rate\n",
       "pitch_type                       \n",
       "CH                 559  19.189839\n",
       "CU                 588  20.185376\n",
       "FF                1500  51.493306\n",
       "SL                 266   9.131480"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive = cleaned[cleaned['game_year'] ==2018]\n",
    "naive = naive.groupby(['pitch_type'])[['pitch_type']].count()\n",
    "naive['rate'] = naive / naive.sum() * 100\n",
    "\n",
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1590\n",
      "P value is: 0.12411916914839463\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "num_pitches = naive['pitch_type'].sum()\n",
    "naive_guess = naive['pitch_type'].max()\n",
    "model_guess = round(num_pitches * precision)\n",
    "chi_inputs = [[num_pitches -model_guess,model_guess], [num_pitches-naive_guess,naive_guess]]\n",
    "print(naive_guess)\n",
    "g, p, dof, expctd = chi2_contingency(chi_inputs)\n",
    "print(\"P value is:\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive['pitch_type'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes\n",
    "1. Corey Kluber 'max_depth': 4,\"min_child_weight\" :0.5, wins 36.02% versus  slider at 32.67%  (depth = 4)\n",
    "2. Justin Verlander \"min_child_weight\" :0.5,'max_depth': 6,  wins 63.16% naive guess FF 61.17% (depth = 4)\n",
    "3. Clayton Kershaw (best pitcher in baseball 3 cy youngs + nl mvp) 'max_depth': 8,\"min_child_weight\" :0.5,\"colsample_bytree\" : 0.4, , 48.86% vs  ff 41.77% \n",
    "4. Max Scherzer (3 cy youngs) \"colsample_bytree\" : 0.5, wins.. 50.52% vs 50.17% FF\n",
    "5. Chris Sale (7 time all star 2012-2018) depth=8m, min_child_weight=0.1, colsample_bytree=0.5: 40.01% vs 39.10 FF\n",
    "6. Zack Greinke (5x all star) 'max_depth': 4,\"colsample_bytree\" : 0.5,  46.53% vs 44.35% FF , p=0.09\n",
    "7. Patrick Corbin (2x all star + 2018 but was bad in 2015-2017). 'max_depth': 4, \"min_child_weight\" :0.5, \"colsample_bytree\" : 0.5,   48.55% vs 40.93% SL.\n",
    "8. Dallas Keuchel (all-star and cy-young) 'max_depth': 8, 42.73% vs FT 41.1%, p=0.18\n",
    "9. Jake Arrieta (all star 2016 new team) 'max_depth': 4, \"min_child_weight\" :0.5, 54.04 vs 53.46% slider, p = 0.6\n",
    "10. Carlos Carrasco (AL wins leader 2017)  35.99% vs 31.88% slider but p = 0.001\n",
    "11. Trevor Bauer (2018 all star) 40.69% vs 36.38% FF p = 0.003\n",
    "12. Charlie Morton (2018 all star)  \"min_child_weight\" :0.1, 38.64% vs 30.79% FF (balanced pitcher)\n",
    "13. David Price (5x allstar, al comback 2017) 'max_depth': 8, \"min_child_weight\" :0.5, 33.91% vs 33.39% FT p = 0.7\n",
    "14. Gerrit Cole (allstar 15,18, new team 2018) 48.48% vs 50.32% FF.  definite fail\n",
    "15. Stephen Strasburg (3x allstar 16,17) 45.13% vs 45.41 FF.  fail\n",
    "16. J.A. Happ (allstar 2018) \"colsample_bytree\" : 0.5,'learning_rate':0.01,  59.3% vs 59.26 FF.\n",
    "17. Madison Bumgarner 30.3 vs 35.19% FC\n",
    "18. Luis Severino (young allstar 17,18) 'learning_rate':0.01, \"min_child_weight\" :0.5, 52.44% vs 50.47% FF\n",
    "19. Jacob deGrom (2018 cy young) \"min_child_weight\" :0.5, 42.93  42.88% FF\n",
    "20. Blake Snell (2018 sweep, crappy 2017) 52.15% vs 51.49% FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "myPitchers = ['Corey Kluber','Justin Verlander','Clayton Kershaw','Max Scherzer','Chris Sale',\n",
    "           'Zack Greinke','Patrick Corbin','Dallas Keuchel','Jake Arrieta','Carlos Carrasco','Trevor Bauer',\n",
    "           'Charlie Morton','David Price','Gerrit Cole','Stephen Strasburg','J.A. Happ','Madison Bumgarner',\n",
    "             'Luis Severino','Jacob deGrom','Blake Snell']\n",
    "print(len(myPitchers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining the PitchTypes to use with pitcher [446372.0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:19216\n",
      "Numpy array precision: 36.02\n"
     ]
    }
   ],
   "source": [
    "name = 'Corey Kluber'\n",
    "\n",
    "cleaned = dataOrchestrator(data, players, playerNames = [name]);\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = createTrainTest(cleaned,2018,2015)\n",
    "\n",
    "resultTrain = yTrain.argmax(axis=1)\n",
    "resultTest = yTest.argmax(axis=1)\n",
    "dtrain = xgb.DMatrix(xTrain, label=resultTrain)\n",
    "dtest = xgb.DMatrix(xTest, label=resultTest)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 4,  # the maximum depth of each tree\n",
    "    \"n_estimators\" :1000,\n",
    "    'learning_rate':0.1,\n",
    "    'eta': 0.1,  # the training step for each iteration\n",
    "    \"min_child_weight\" : 0.5,\n",
    "    \"gamma\" : 1, \n",
    "    \"subsample\": 1,\n",
    "    \"colsample_bytree\" : 1, \n",
    "    \"scale_pos_weight\": 1,\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': yTrain.shape[1],\n",
    "    \"tree_method\" :'gpu_hist',\n",
    "    \"cv\":kfold}  \n",
    "num_round = 100  # the number of training iterations\n",
    "\n",
    "bst = xgb.train(param, dtrain,num_round)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "precision = round(precision_score(resultTest, best_preds, average='micro'),4)\n",
    "print (\"Numpy array precision:\", round(precision*100,2))\n",
    "\n",
    "# save model to file\n",
    "pickle.dump(bst, open(\"models/\"+name+\".dat\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array precision: 52.15\n"
     ]
    }
   ],
   "source": [
    "# load model from file\n",
    "loaded_model = pickle.load(open(\"models/\"+name+\".dat\", \"rb\"))\n",
    "\n",
    "preds = loaded_model.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "precision = round(precision_score(resultTest, best_preds, average='micro'),4)\n",
    "print (\"Numpy array precision:\", round(precision*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=150,\n",
       "       n_jobs=1, nthread=None, num_class=6, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       scoring='merror', seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.1,\n",
    "                      n_estimators=150,\n",
    "                      max_depth=6,\n",
    "                      min_child_weight = 1,\n",
    "                     scoring=\"merror\",\n",
    "                      objective = \"multi:softprob\",\n",
    "                      num_class = yTrain.shape[1]\n",
    "                     )\n",
    "result = yTrain.argmax(axis=1)\n",
    "model.fit(xTrain, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([xTrain[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Grid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each fold takes 3 minutes\n",
    "n_estimators = [150,1000]\n",
    "max_depth = [4,6]\n",
    "learning_rate = [0.1,0.01]\n",
    "param_grid = dict(max_depth=max_depth, n_estimators=n_estimators,learning_rate=learning_rate)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "myModel = GridSearchCV(XGBClassifier(min_child_weight = 1,gamma = 0, subsample=0.8,\n",
    "                                     colsample_bytree = 0.8, scale_pos_weight=1,\n",
    "                 objective = \"multi:softprob\",tree_method = 'gpu_hist'\n",
    "                ,num_class= yTrain.shape[1]), \n",
    "                           param_grid, \n",
    "                           n_jobs=-1, \n",
    "                           cv=kfold, \n",
    "                           verbose=1)\n",
    "\n",
    "resultTrain = yTrain.argmax(axis=1)\n",
    "resultTest = yTest.argmax(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "Exception in thread QueueManagerThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 747, in _queue_management_worker\n",
      "    recursive_terminate(p)\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/utils.py\", line 28, in recursive_terminate\n",
      "    _recursive_terminate_without_psutil(process)\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/utils.py\", line 53, in _recursive_terminate_without_psutil\n",
      "    _recursive_terminate(process.pid)\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/backend/utils.py\", line 94, in _recursive_terminate\n",
      "    stderr=None\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/subprocess.py\", line 356, in check_output\n",
      "    **kwargs).stdout\n",
      "  File \"/home/christian/anaconda3/envs/tf-gpu/lib/python3.6/subprocess.py\", line 438, in run\n",
      "    output=stdout, stderr=stderr)\n",
      "subprocess.CalledProcessError: Command '['pgrep', '-P', '12122']' died with <Signals.SIGINT: 2>.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    853\u001b[0m                     \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    537\u001b[0m         \"\"\"\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, kill_workers)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                 \u001b[0mqmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0mcq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "myModel.fit(xTrain,resultTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array precision: 0.3514304291287386\n",
      "Numpy array accuracy: 35.14304291287386\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resultTrain = yTrain.argmax(axis=1)\n",
    "resultTest = yTest.argmax(axis=1)\n",
    "dtrain = xgb.DMatrix(xTrain, label=resultTrain)\n",
    "dtest = xgb.DMatrix(xTest, label=resultTest)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=20, shuffle=True, random_state=7)\n",
    "\n",
    "param = {\n",
    "    'max_depth': 6,  # the maximum depth of each tree\n",
    "    \"n_estimators\" :150,\n",
    "    'learning_rate':0.01,\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': yTrain.shape[1],\n",
    "    \"tree_method\" :'gpu_hist',\n",
    "    \"cv\":kfold}  \n",
    "num_round = 1000  # the number of training iterations\n",
    "\n",
    "bst = xgb.train(param, dtrain,num_round)\n",
    "\n",
    "preds = bst.predict(dtest)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(resultTest, best_preds, average='micro'))\n",
    "print (\"Numpy array accuracy:\", accuracy_score(resultTest, best_preds) * 100)\n",
    "\n",
    "naive = cleaned[cleaned['game_year'] ==2018]\n",
    "naive = naive.groupby(['pitch_type'])[['pitch_type']].count()\n",
    "naive['rate'] = naive / naive.sum() * 100\n",
    "\n",
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pitch_type</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pitch_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>202</td>\n",
       "      <td>6.566970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU</th>\n",
       "      <td>691</td>\n",
       "      <td>22.464239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FC</th>\n",
       "      <td>905</td>\n",
       "      <td>29.421326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FF</th>\n",
       "      <td>273</td>\n",
       "      <td>8.875163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>1005</td>\n",
       "      <td>32.672302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pitch_type       rate\n",
       "pitch_type                       \n",
       "CH                 202   6.566970\n",
       "CU                 691  22.464239\n",
       "FC                 905  29.421326\n",
       "FF                 273   8.875163\n",
       "SI                1005  32.672302"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive = cleaned[cleaned['game_year'] ==2018]\n",
    "naive = naive.groupby(['pitch_type'])[['pitch_type']].count()\n",
    "naive['rate'] = naive / naive.sum() * 100\n",
    "\n",
    "naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
