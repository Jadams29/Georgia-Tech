{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from LoadData import LoadData\n",
    "from sklearn.metrics import (auc, average_precision_score, accuracy_score, precision_recall_curve, \n",
    "                                classification_report, confusion_matrix, plot_confusion_matrix, \n",
    "                                f1_score, precision_score, recall_score, roc_curve)\n",
    "from sklearn.model_selection import (cross_val_predict, GridSearchCV, train_test_split, learning_curve, validation_curve)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "random_state = 7\n",
    "start = 10\n",
    "max_iterations=1000\n",
    "max_attempts=100\n",
    "cv = 5\n",
    "stop = 101\n",
    "step = 10\n",
    "size = 20\n",
    "problem_name = \"NeuralNetwork\"\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, \n",
    "                        cv=None, scoring='accuracy', n_jobs=None, \n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "            learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                           train_sizes=train_sizes,\n",
    "                           scoring=scoring,\n",
    "                           return_times=True, verbose=3)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid(True)\n",
    "    axes[0].minorticks_on()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid(True)\n",
    "    axes[1].minorticks_on()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "    axes[1].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "\n",
    "#     # Plot fit_time vs score\n",
    "#     axes[2].grid()\n",
    "#     axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "#     axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "#                          test_scores_mean + test_scores_std, alpha=0.1)\n",
    "#     axes[2].set_xlabel(\"fit_times\")\n",
    "#     axes[2].set_ylabel(\"Score\")\n",
    "#     axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator,X, y, param_name, param_range, \n",
    "                          cv, n_jobs, title, xlabel, ylim = None, scoring='f1'):     \n",
    "    with parallel_backend('threading'):\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            estimator, X, y, param_name, param_range, cv=cv,\n",
    "            scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)    \n",
    "    plt.plot(param_range,train_scores_mean-test_scores_mean, label = 'Error'\n",
    "                    , color=\"red\", lw=lw)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    \n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "       \n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score)      \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                             ''.format(roc_auc), linewidth=2.5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    optimal_idx = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    print(\"Optimal Threshold: \")\n",
    "    print(optimal_threshold)    \n",
    "\n",
    "    \n",
    "def plot_pr_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precision, recall, threshold = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "    plt.plot(recall, precision, label='Precision Recall curve (AP = {0:0.2f})'\n",
    "                             ''.format(average_precision),\n",
    "             linewidth=2.5)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "       \n",
    "    max_f1 = 0\n",
    "    for r, p, t in zip(recall, precision, threshold):\n",
    "        if p + r == 0: continue\n",
    "        if (2 * p * r) / (p + r) > max_f1:\n",
    "            max_f1 = (2 * p * r) / (p + r)\n",
    "            max_f1_threshold = t\n",
    "\n",
    "    print(\"Optimal Threshold: \") \n",
    "    print(max_f1_threshold)\n",
    "    print(\"Maximized F1 score: \") \n",
    "    print(max_f1)\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(title)\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "def ConvertFrom1HToIndex(arr):\n",
    "    results = np.argwhere(arr==1)\n",
    "    return np.vstack(results[:,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: mnist-train-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 3000 \n",
      "   Shape of Entry: (785,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "# testing_data_path = \"{}/medium-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "\n",
    "training_labels, training_data, training_combined = LoadData(training_data_path, normalize=False)\n",
    "# testing_labels, testing_data, testing_combined = LoadData(testing_data_path, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network - Randomized Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels,\n",
    "                                                    test_size = 0.2, random_state = random_state)\n",
    "\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "\n",
    "# print(\"Y_Test_Hot: \\n\", y_test_hot.shape)\n",
    "# print(\"\\nTraining Labels: \\n\", training_labels.shape)\n",
    "# print(\"\\nTraining Data: \\n\", training_data.shape)\n",
    "\n",
    "\n",
    "# print(\"\\nX Train: \\n\", X_train.shape)\n",
    "# print(\"\\ny Train: \\n\", y_train.shape)\n",
    "# print(\"\\nX Test: \\n\", X_test.shape)\n",
    "# print(\"\\ny Test: \\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list = [\"random_hill_climb\", \"simulated_annealing\", \"genetic_alg\", \"gradient_descent\"]\n",
    "curve_list = []\n",
    "accuracy_training_list = []\n",
    "f1_training_list = []\n",
    "\n",
    "accuracy_testing_list = []\n",
    "f1_testing_list = []\n",
    "time_list = []\n",
    "classifiers = {\"random_hill_climb\": None, \"simulated_annealing\": None, \"genetic_alg\": None, \"gradient_descent\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=\"gradient_descent\"\n",
    "fig0, axes0 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network1 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                           max_iters=max_iterations,bias=True,max_attempts=max_attempts,is_classifier=True,\n",
    "                           early_stopping=False,pop_size = 1000,mutation_prob = 0.9,\n",
    "                           learning_rate=0.00001,random_state = random_state,curve = True)\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network1.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network1, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network1.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network1, title, X_train_scaled, y_train_hot, axes=axes0, ylim=(0.5, 1.02),\n",
    "                cv=cv, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=\"random_hill_climb\"\n",
    "fig1, axes1 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network2 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                           max_iters=max_iterations,bias=True,max_attempts=max_attempts,is_classifier=True,\n",
    "                           early_stopping=False,pop_size = 100,mutation_prob = 0.9,restarts=3,\n",
    "                           learning_rate=0.001,random_state = random_state,curve = True)\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network2.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network2, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network2.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network2.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network2, title, X_train_scaled, y_train_hot, axes=axes1, ylim=(0.5, 1.02),\n",
    "                cv=cv, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated_annealing\n",
      "Finished Fitting simulated_annealing\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'j' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5a032fa37835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0my_train_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train_hot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Accuracy ({}, schedule: {}): \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# Predict labels for test set and assess accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'j' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm=\"simulated_annealing\"\n",
    "print(algorithm)\n",
    "fig2, axes2 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network3 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                       max_iters=20000,bias=True,is_classifier=True,max_attempts=100,\n",
    "                       early_stopping=True,clip_max = 1,\n",
    "                       learning_rate=1,random_state = random_state,curve = True, schedule= mlrose.GeomDecay(decay=0.9))\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network3.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network3, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network3.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy ({}): \".format(algorithm), y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network3.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy ({}): \".format(algorithm), y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "\n",
    "plot_learning_curve(neural_network3, title, X_train_scaled, y_train_hot, axes=axes2, ylim=(0.5, 1.02),\n",
    "                cv=2, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic_alg\n",
      "Starting to Fit\n"
     ]
    }
   ],
   "source": [
    "algorithm=\"genetic_alg\"\n",
    "print(algorithm)\n",
    "fig3, axes3 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network4 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                                       bias=True,is_classifier=True,\n",
    "                                       early_stopping=False,pop_size=1000,\n",
    "                                       mutation_prob=0.9,learning_rate=0.00001,\n",
    "                                       random_state=random_state,curve=True)\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "print(\"Starting to Fit\")\n",
    "with parallel_backend('threading'):\n",
    "    neural_network4.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network4, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network4.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network4.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network4, title, X_train_scaled, y_train_hot, axes=axes3, ylim=(0.1, 1.02),\n",
    "                cv=2, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
