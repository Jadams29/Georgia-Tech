{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from LoadData import LoadData\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV, train_test_split\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "random_state = 7\n",
    "start = 10\n",
    "stop = 101\n",
    "step = 10\n",
    "size = 20\n",
    "problem_name = \"NeuralNetwork\"\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, exp_score=0.8, \n",
    "                        ylim=None, cv=None, n_jobs=None, \n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.xlim(0,y.size)\n",
    "    with parallel_backend('threading'):\n",
    "        train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                                                                              train_sizes=train_sizes,\n",
    "                                                                              return_times=True, random_state=1,\n",
    "                                                                              scoring='f1')\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.axhline(y=exp_score, color='b', linestyle='-', label=\"Acceptable score\")\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator,X, y, param_name, param_range, \n",
    "                          cv, n_jobs, title, xlabel, ylim = None, scoring='f1'):     \n",
    "    with parallel_backend('threading'):\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            estimator, X, y, param_name, param_range, cv=cv,\n",
    "            scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)    \n",
    "    plt.plot(param_range,train_scores_mean-test_scores_mean, label = 'Error'\n",
    "                    , color=\"red\", lw=lw)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.colors.BASE_COLORS):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_roc_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    \n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "       \n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score)      \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                             ''.format(roc_auc), linewidth=2.5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    optimal_idx = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    print(\"Optimal Threshold: \")\n",
    "    print(optimal_threshold)    \n",
    "\n",
    "    \n",
    "def plot_pr_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precision, recall, threshold = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "    plt.plot(recall, precision, label='Precision Recall curve (AP = {0:0.2f})'\n",
    "                             ''.format(average_precision),\n",
    "             linewidth=2.5)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "       \n",
    "    max_f1 = 0\n",
    "    for r, p, t in zip(recall, precision, threshold):\n",
    "        if p + r == 0: continue\n",
    "        if (2 * p * r) / (p + r) > max_f1:\n",
    "            max_f1 = (2 * p * r) / (p + r)\n",
    "            max_f1_threshold = t\n",
    "\n",
    "    print(\"Optimal Threshold: \") \n",
    "    print(max_f1_threshold)\n",
    "    print(\"Maximized F1 score: \") \n",
    "    print(max_f1)\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(title)\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: mnist-train-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 3000 \n",
      "   Shape of Entry: (785,)\n",
      "\n",
      "Attempting to load: mnist-test-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 3000 \n",
      "   Shape of Entry: (785,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "testing_data_path = \"{}/mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "\n",
    "training_labels, training_data, training_combined = LoadData(training_data_path, normalize=True)\n",
    "testing_labels, testing_data, testing_combined = LoadData(testing_data_path, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network - Randomized Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Hill Climbing\n",
    "random_hill_climbing_NN = mlrose.NeuralNetwork(hidden_nodes=[784,100], activation='relu',\n",
    "                                               algorithm='random_hill_climb', max_iters=100,\n",
    "                                               restarts=90, bias=True, is_classifier=True, \n",
    "                                               learning_rate=1, max_attempts= 50, mutation_prob=0.1, \n",
    "                                               pop_size=100, random_state=random_state, curve=True)\n",
    "\n",
    "# Genetic Algorithm\n",
    "genetic_algorithm_NN = mlrose.NeuralNetwork(hidden_nodes=[784,100], activation='relu',\n",
    "                                            algorithm='genetic_alg', max_iters=100, pop_size=1000,\n",
    "                                            bias=True, is_classifier=True, learning_rate=1, mutation_prob=0.9,\n",
    "                                            max_attempts=50, random_state=random_state, curve=True)\n",
    "\n",
    "\n",
    "# Simulated Annealing\n",
    "\n",
    "simulated_annealing_NN = mlrose.NeuralNetwork(hidden_nodes=[784,100], activation='relu',\n",
    "                                              algorithm='simulated_annealing', max_iters=100,\n",
    "                                              schedule=mlrose.ExpDecay(),bias=True, \n",
    "                                              is_classifier=True, learning_rate=1, max_attempts=50, \n",
    "                                              mutation_prob=0.1, pop_size=100, random_state=random_state, curve=True)\n",
    "\n",
    "# MIMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 10, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2 3 4 5 6 7 8 9]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-be1a5b6f4f47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom_hill_climbing_NN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\neural\\_nn_core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, init_weights)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'random_hill_climb'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mfitness_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__run_with_rhc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'simulated_annealing'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\neural\\_nn_core.py\u001b[0m in \u001b[0;36m__run_with_rhc\u001b[1;34m(self, init_weights, num_nodes, problem)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                       \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                                       \u001b[0mrestarts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m                                       curve=self.curve)\n\u001b[0m\u001b[0;32m    250\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                 current_weights, current_loss, _ = random_hill_climb(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\algorithms\\rhc.py\u001b[0m in \u001b[0;36mrandom_hill_climb\u001b[1;34m(problem, max_attempts, max_iters, restarts, init_state, curve, random_state, state_fitness_callback, callback_user_info)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mfitness_curve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\opt_probs\\_opt_prob.py\u001b[0m in \u001b[0;36mset_state\u001b[1;34m(self, new_state)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_fitness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcan_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\opt_probs\\_opt_prob.py\u001b[0m in \u001b[0;36meval_fitness\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"state length must match problem length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfitness_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\neural\\fitness\\network_weights.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[1;31m# Evaluate loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mfitness\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfitness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[1;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[0;32m   2285\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[0;32m   2286\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2287\u001b[1;33m                                                   lb.classes_))\n\u001b[0m\u001b[0;32m   2288\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 10, 2. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 1 2 3 4 5 6 7 8 9]"
     ]
    }
   ],
   "source": [
    "with parallel_backend('threading'):\n",
    "    random_hill_climbing_NN.fit(testing_data, testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with parallel_backend('threading'):\n",
    "        plot_learning_curve(simulated_annealing_NN, \"Random Hill Climbing - Learning Curve\", training_data, training_labels, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7059489980c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_hill_climbing_NN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtemp_confusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\mlrose_hiive\\neural\\_nn_core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \"\"\"\n\u001b[1;32m--> 277\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             raise Exception(\"\"\"The number of columns in X must equal %d\"\"\"\n\u001b[0;32m    279\u001b[0m                             % ((self.node_list[0] - self.bias),))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "y_pred = random_hill_climbing_NN.predict(testing_data)\n",
    "temp_confusion_matrix = confusion_matrix(testing_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(simulated_annealing_NN, \"Random Hill Climbing - Learning Curve\", training_data, training_labels, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
