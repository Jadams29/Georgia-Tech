{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\envs\\cs7641\\lib\\site-packages (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.14 in c:\\programdata\\anaconda3\\envs\\cs7641\\lib\\site-packages (from pyarrow) (1.19.2)\n",
      "Requirement already satisfied: six>=1.0.0 in c:\\programdata\\anaconda3\\envs\\cs7641\\lib\\site-packages (from pyarrow) (1.15.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import ml_util_assignment_2 as utl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "import mlrose_hiive\n",
    "from mlrose_hiive import GeomDecay, ArithDecay, ExpDecay\n",
    "from mlrose_hiive.runners import NNGSRunner\n",
    "from mlrose_hiive.neural.activation import relu\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "save_directory = \"figures/NeuralNetwork\"\n",
    "model_name = \"NeuralNetwork\"\n",
    "\n",
    "folders = [\"figures/NeuralNetwork/Complexity_Analysis\",\n",
    "           \"figures/NeuralNetwork/Grid_Search_Results\",\n",
    "           \"figures/NeuralNetwork/Learning_Curves\",\n",
    "           \"figures/NeuralNetwork/Confusion_Matrix\",\n",
    "           \"figures/NeuralNetwork/Metrics\"]\n",
    "\n",
    "directories = {\n",
    "    \"Save Directory\": \"figures/NeuralNetwork\",\n",
    "    \"Initial Complexity Analysis\": \"figures/NeuralNetwork/Initial Complexity Analysis\",\n",
    "    \"Grid Search Results\": \"figures/NeuralNetwork/Grid Search Results\",\n",
    "    \"Learning Curves\": \"figures/NeuralNetwork/Learning Curves\",\n",
    "    \"Final Complexity Analysis\": \"figures/NeuralNetwork/Final Complexity Analysis\"\n",
    "}\n",
    "\n",
    "Random_Number = 42\n",
    "TESTING = True\n",
    "cv = 5\n",
    "n_jobs = -1\n",
    "np.random.seed(42)\n",
    "get_ipython().system('pip install pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset folder already exists.\n",
      "MNIST dataset found:\n",
      "\tLoading MNIST.feather\n",
      "\tFinished loading MNIST dataset\n"
     ]
    }
   ],
   "source": [
    "gathered_data = utl.setup([\"MNIST\"])\n",
    "# gathered_data_fashion = utl.setup([\"Fashion-MNIST\"])\n",
    "train_X, train_y, valid_X, valid_y, test_X, test_y = utl.split_data(gathered_data[\"MNIST\"][\"X\"],\n",
    "                                                                    gathered_data[\"MNIST\"][\"y\"], minMax=True, oneHot=True)\n",
    "# fashion_train_X, fashion_train_y, fashion_valid_X, fashion_valid_y, fashion_test_X, fashion_test_y = utl.split_data(\n",
    "#     gathered_data_fashion[\"Fashion-MNIST\"][\"X\"], \n",
    "#     gathered_data_fashion[\"Fashion-MNIST\"][\"y\"], minMax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figures/NeuralNetwork folder already exists.\n",
      "figures/NeuralNetwork/Complexity_Analysis folder already exists.\n",
      "figures/NeuralNetwork/Grid_Search_Results folder already exists.\n",
      "figures/NeuralNetwork/Learning_Curves folder already exists.\n",
      "figures/NeuralNetwork/Confusion_Matrix folder already exists.\n",
      "figures/NeuralNetwork/Metrics folder already exists.\n"
     ]
    }
   ],
   "source": [
    "CHECK_FOLDER = os.path.isdir(save_directory)\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not CHECK_FOLDER:\n",
    "    os.makedirs(save_directory)\n",
    "    print(\"created folder : \", save_directory)\n",
    "else:\n",
    "    print(save_directory, \"folder already exists.\")\n",
    "\n",
    "for f in folders:\n",
    "    if not os.path.isdir(f):\n",
    "        os.makedirs(f)\n",
    "        print(\"created folder : \", f)\n",
    "    else:\n",
    "        print(f, \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Neural Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_sizes=[[100]] # was (100,) in previous but mlrose needs a list\n",
    "\n",
    "random_state=42\n",
    "\n",
    "val = 3000\n",
    "pred_val = 3000\n",
    "\n",
    "activation='relu'\n",
    "\n",
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.iloc[:val, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running nngs_rhc\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  20 out of  20 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time: 1135.9817591\n",
      "Saving: [C:\\Users\\joshu\\OneDrive - Georgia Institute of Technology\\Georgia-Tech\\CS 7641 - Machine Learning\\Assignments\\Randomized Optimization/results/nn_rhc_test\\nngs_rhc__nn_rhc_test__cv_results_df.csv]\n",
      "Saving: [C:\\Users\\joshu\\OneDrive - Georgia Institute of Technology\\Georgia-Tech\\CS 7641 - Machine Learning\\Assignments\\Randomized Optimization/results/nn_rhc_test\\nngs_rhc__nn_rhc_test__grid_search_results.p]\n",
      "**********\n",
      "Score: nan\n",
      "**********\n",
      "********************************\n",
      "*** Spawn Count Remaining: 2 ***\n",
      "********************************\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid_search_parameters = ({\n",
    "    'max_iters': [1000],\n",
    "    'learning_rate': 10. ** np.arange(-4,4,1) # nn params\n",
    "})\n",
    "\n",
    "nn_rhc_gs = NNGSRunner(x_train=train_X.iloc[:val, :].to_numpy(),\n",
    "                       y_train=train_y.iloc[:val, :].to_numpy(),\n",
    "                       x_test=test_X.iloc[:val, :].to_numpy(),\n",
    "                       y_test=test_y.iloc[:val, :].to_numpy(),\n",
    "                       experiment_name='nn_rhc_test',\n",
    "                       activation=[relu],\n",
    "                       algorithm=mlrose_hiive.algorithms.rhc.random_hill_climb,\n",
    "                       grid_search_scorer_method=accuracy_score,\n",
    "                       grid_search_parameters=grid_search_parameters,\n",
    "                       iteration_list=[10, 50, 100, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "                       hidden_layer_sizes=hidden_layer_sizes,\n",
    "                       bias=True,\n",
    "                       early_stopping=True,\n",
    "                       clip_max=1e+10,\n",
    "                       max_attempts=500,\n",
    "                       generate_curves=True,\n",
    "                       output_directory=f\"{os.getcwd()}/results/\",\n",
    "                       n_jobs=6,\n",
    "                       cv=5,\n",
    "                       seed=3)\n",
    "rhc_res = nn_rhc_gs.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       " Empty DataFrame\n",
       " Columns: []\n",
       " Index: [],\n",
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       " 0     322.220272      0.379883         0.009801        0.000981   \n",
       " 1     312.530259      5.337827         0.008200        0.001327   \n",
       " 2     309.058902      7.642343         0.010602        0.002579   \n",
       " 3     262.598546     49.077920         0.006997        0.000632   \n",
       " \n",
       "   param_activation param_hidden_layer_sizes  param_learning_rate  \\\n",
       " 0             relu                    [100]               0.1000   \n",
       " 1             relu                    [100]               0.0100   \n",
       " 2             relu                    [100]               0.0010   \n",
       " 3             relu                    [100]               0.0001   \n",
       " \n",
       "    param_max_iters                                             params  \\\n",
       " 0             1000  {'activation': <function relu at 0x000001D779C...   \n",
       " 1             1000  {'activation': <function relu at 0x000001D779C...   \n",
       " 2             1000  {'activation': <function relu at 0x000001D779C...   \n",
       " 3             1000  {'activation': <function relu at 0x000001D779C...   \n",
       " \n",
       "    split0_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       " 0           0.063333  ...         0.074667        0.012401                1   \n",
       " 1           0.063333  ...         0.074667        0.012401                1   \n",
       " 2           0.063333  ...         0.074667        0.012401                1   \n",
       " 3           0.063333  ...         0.074667        0.012401                1   \n",
       " \n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       " 0            0.077917            0.075417            0.075833   \n",
       " 1            0.077917            0.075417            0.075833   \n",
       " 2            0.077917            0.075417            0.075833   \n",
       " 3            0.077917            0.075417            0.075833   \n",
       " \n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       " 0            0.069167            0.077083          0.075083         0.003089  \n",
       " 1            0.069167            0.077083          0.075083         0.003089  \n",
       " 2            0.069167            0.077083          0.075083         0.003089  \n",
       " 3            0.069167            0.077083          0.075083         0.003089  \n",
       " \n",
       " [4 rows x 24 columns],\n",
       " GridSearchCV(cv=5,\n",
       "              estimator=NNClassifier(algorithm=<function random_hill_climb at 0x000001D779508798>,\n",
       "                                     early_stopping=True, learning_rate=None,\n",
       "                                     max_attempts=500,\n",
       "                                     runner=<mlrose_hiive.runners.nngs_runner.NNGSRunner object at 0x000001D70503E148>,\n",
       "                                     seed=3),\n",
       "              n_jobs=6,\n",
       "              param_grid={'activation': [<function relu at 0x000001D779C70168>],\n",
       "                          'hidden_layer_sizes': [[100]],\n",
       "                          'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
       "                          'max_iters': [1000]},\n",
       "              return_train_score=True,\n",
       "              scoring=make_scorer(_grid_search_score_intercept), verbose=True))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Hill Climb Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_random_hill = mlr_h.NeuralNetwork(hidden_nodes = hidden_layer_sizes, activation = activation, \n",
    "                                            algorithm = 'random_hill_climb', max_iters = max_iterations, \n",
    "                                            bias = True, is_classifier = True, learning_rate = 10.0,\n",
    "                                            early_stopping = True, clip_max = 5, max_attempts = 1000, \n",
    "                                            random_state = random_state, curve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model_random_hill.fit(fashion_train_X.iloc[:val, :], fashion_train_y.iloc[:val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nn_model_random_hill.predict(fashion_train_X.iloc[:val, :])\n",
    "y_train_acc = accuracy_score(np.argmax(fashion_train_y.iloc[:val,:].to_numpy(), axis=1), np.argmax(y_pred, axis=1))\n",
    "print(y_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(fashion_train_y.iloc[:val,:].to_numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn_model_random_hill.node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,max_iterations),nn_model_random_hill.fitness_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,max_iterations),nn_model_random_hill.fitness_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,max_iterations),nn_model_random_hill.fitness_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(0,1000),nn_model_random_hill.fitness_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated Annealing Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algortihm Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
