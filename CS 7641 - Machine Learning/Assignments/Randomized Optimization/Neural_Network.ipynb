{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlrose_hiive as mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "\n",
    "from LoadData import LoadData\n",
    "from sklearn.metrics import (auc, average_precision_score, accuracy_score, precision_recall_curve, \n",
    "                                classification_report, confusion_matrix, plot_confusion_matrix, \n",
    "                                f1_score, precision_score, recall_score, roc_curve)\n",
    "from sklearn.model_selection import (cross_val_predict, GridSearchCV, train_test_split, learning_curve, validation_curve)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "random_state = 7\n",
    "start = 10\n",
    "max_iterations=1000\n",
    "max_attempts=100\n",
    "cv = 5\n",
    "stop = 101\n",
    "step = 10\n",
    "size = 20\n",
    "problem_name = \"NeuralNetwork\"\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, \n",
    "                        cv=None, scoring='accuracy', n_jobs=None, \n",
    "                        train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "            learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                           train_sizes=train_sizes,\n",
    "                           scoring=scoring,\n",
    "                           return_times=True, verbose=3)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid(True)\n",
    "    axes[0].minorticks_on()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid(True)\n",
    "    axes[1].minorticks_on()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "    axes[1].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "\n",
    "#     # Plot fit_time vs score\n",
    "#     axes[2].grid()\n",
    "#     axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "#     axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "#                          test_scores_mean + test_scores_std, alpha=0.1)\n",
    "#     axes[2].set_xlabel(\"fit_times\")\n",
    "#     axes[2].set_ylabel(\"Score\")\n",
    "#     axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_validation_curve(estimator,X, y, param_name, param_range, \n",
    "                          cv, n_jobs, title, xlabel, ylim = None, scoring='f1'):     \n",
    "    with parallel_backend('threading'):\n",
    "        train_scores, test_scores = validation_curve(\n",
    "            estimator, X, y, param_name, param_range, cv=cv,\n",
    "            scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "\n",
    "    lw = 2\n",
    "    plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "    plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                 color=\"navy\", lw=lw)\n",
    "    plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=lw)    \n",
    "    plt.plot(param_range,train_scores_mean-test_scores_mean, label = 'Error'\n",
    "                    , color=\"red\", lw=lw)\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    \n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "       \n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score)      \n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = {0:0.2f})'\n",
    "                             ''.format(roc_auc), linewidth=2.5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    optimal_idx = np.argmin(np.sqrt(np.square(1-tpr) + np.square(fpr)))\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    print(\"Optimal Threshold: \")\n",
    "    print(optimal_threshold)    \n",
    "\n",
    "    \n",
    "def plot_pr_curve(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precision, recall, threshold = precision_recall_curve(y_test, y_score)\n",
    "\n",
    "    plt.plot(recall, precision, label='Precision Recall curve (AP = {0:0.2f})'\n",
    "                             ''.format(average_precision),\n",
    "             linewidth=2.5)\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "       \n",
    "    max_f1 = 0\n",
    "    for r, p, t in zip(recall, precision, threshold):\n",
    "        if p + r == 0: continue\n",
    "        if (2 * p * r) / (p + r) > max_f1:\n",
    "            max_f1 = (2 * p * r) / (p + r)\n",
    "            max_f1_threshold = t\n",
    "\n",
    "    print(\"Optimal Threshold: \") \n",
    "    print(max_f1_threshold)\n",
    "    print(\"Maximized F1 score: \") \n",
    "    print(max_f1)\n",
    "\n",
    "\n",
    "def plot_precision_recall_vs_threshold(clf, X_test, y_test, title, dfunc=False):\n",
    "    if dfunc:\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    with parallel_backend('threading'):\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        precisions, recalls, thresholds = precision_recall_curve(y_test, y_score)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.title(title)\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.xlabel(\"Decision Threshold\")\n",
    "    plt.xlim(0,1.1)\n",
    "    plt.ylim(0,1.1)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "def ConvertFrom1HToIndex(arr):\n",
    "    results = np.argwhere(arr==1)\n",
    "    return np.vstack(results[:,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: mnist-train-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 3000 \n",
      "   Shape of Entry: (785,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "# testing_data_path = \"{}/medium-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "\n",
    "training_labels, training_data, training_combined = LoadData(training_data_path, normalize=False)\n",
    "# testing_labels, testing_data, testing_combined = LoadData(testing_data_path, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Neural Network - Randomized Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, training_labels,\n",
    "                                                    test_size = 0.2, random_state = random_state)\n",
    "\n",
    "\n",
    "# Normalize feature data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One hot encode target values\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1, 1)).todense()\n",
    "y_test_hot = one_hot.transform(y_test.reshape(-1, 1)).todense()\n",
    "\n",
    "# print(\"Y_Test_Hot: \\n\", y_test_hot.shape)\n",
    "# print(\"\\nTraining Labels: \\n\", training_labels.shape)\n",
    "# print(\"\\nTraining Data: \\n\", training_data.shape)\n",
    "\n",
    "\n",
    "# print(\"\\nX Train: \\n\", X_train.shape)\n",
    "# print(\"\\ny Train: \\n\", y_train.shape)\n",
    "# print(\"\\nX Test: \\n\", X_test.shape)\n",
    "# print(\"\\ny Test: \\n\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list = [\"random_hill_climb\", \"simulated_annealing\", \"genetic_alg\", \"gradient_descent\"]\n",
    "curve_list = []\n",
    "accuracy_training_list = []\n",
    "f1_training_list = []\n",
    "\n",
    "accuracy_testing_list = []\n",
    "f1_testing_list = []\n",
    "time_list = []\n",
    "classifiers = {\"random_hill_climb\": None, \"simulated_annealing\": None, \"genetic_alg\": None, \"gradient_descent\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=\"gradient_descent\"\n",
    "fig0, axes0 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network1 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                           max_iters=max_iterations,bias=True,max_attempts=max_attempts,is_classifier=True,\n",
    "                           early_stopping=False,pop_size = 1000,mutation_prob = 0.9,\n",
    "                           learning_rate=0.00001,random_state = random_state,curve = True)\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network1.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network1, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network1.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network1.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network1, title, X_train_scaled, y_train_hot, axes=axes0, ylim=(0.5, 1.02),\n",
    "                cv=cv, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=\"random_hill_climb\"\n",
    "fig1, axes1 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network2 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                           max_iters=max_iterations,bias=True,max_attempts=max_attempts,is_classifier=True,\n",
    "                           early_stopping=False,pop_size = 100,mutation_prob = 0.9,restarts=3,\n",
    "                           learning_rate=0.001,random_state = random_state,curve = True)\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network2.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network2, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network2.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network2.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network2, title, X_train_scaled, y_train_hot, axes=axes1, ylim=(0.5, 1.02),\n",
    "                cv=cv, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm=\"simulated_annealing\"\n",
    "print(algorithm)\n",
    "fig2, axes2 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network3 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                       max_iters=20000,bias=True,is_classifier=True,max_attempts=100,\n",
    "                       early_stopping=True,clip_max = 1,\n",
    "                       learning_rate=1,random_state = random_state,curve = True, schedule= mlrose.GeomDecay(decay=0.9))\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "with parallel_backend('threading'):\n",
    "    neural_network3.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network3, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network3.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy ({}): \".format(algorithm), y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network3.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy ({}): \".format(algorithm), y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "\n",
    "plot_learning_curve(neural_network3, title, X_train_scaled, y_train_hot, axes=axes2, ylim=(0.5, 1.02),\n",
    "                cv=2, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genetic_alg\n",
      "Starting to Fit\n"
     ]
    }
   ],
   "source": [
    "algorithm=\"genetic_alg\"\n",
    "print(algorithm)\n",
    "fig3, axes3 = plt.subplots(1, 2, figsize=(11, 5))\n",
    "neural_network4 = mlrose.NeuralNetwork(hidden_nodes = [100], activation='relu', algorithm=algorithm,\n",
    "                                       bias=True,is_classifier=True,\n",
    "                                       random_state=random_state,curve=True)\n",
    "start_time = time.time()\n",
    "# Fit the neural network\n",
    "print(\"Starting to Fit\")\n",
    "with parallel_backend('threading'):\n",
    "    neural_network4.fit(X_train_scaled, y_train_hot)\n",
    "print(\"Finished Fitting {}\\n\".format(algorithm))\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "classifiers[algorithm] = [neural_network4, elapsed_time]\n",
    "title=\"Neural Network - {}\".format(algorithm)\n",
    "\n",
    "# Predict labels for train set and assess accuracy\n",
    "y_train_pred = neural_network4.predict(X_train_scaled)\n",
    "\n",
    "y_train_accuracy = accuracy_score(y_train_hot, y_train_pred)\n",
    "\n",
    "print(\"Training Accuracy: \", y_train_accuracy)\n",
    "\n",
    "# Predict labels for test set and assess accuracy\n",
    "y_test_pred = neural_network4.predict(X_test_scaled)\n",
    "\n",
    "y_test_accuracy = accuracy_score(y_test_hot, y_test_pred)\n",
    "print(\"Testing Accuracy: \", y_test_accuracy)\n",
    "print(\"Fit Runtime ({}): {}sec\\n\".format(algorithm, elapsed_time))\n",
    "\n",
    "plot_learning_curve(neural_network4, title, X_train_scaled, y_train_hot, axes=axes3, ylim=(0.1, 1.02),\n",
    "                cv=2, scoring='accuracy')\n",
    "total_end = time.time()\n",
    "total_time = (total_end-start_time)\n",
    "print(\"Plotting Time: {}\\n\".format((total_end - end_time)))\n",
    "print(\"Total Runtime ({}): {}sec\\n\".format(algorithm, total_time))\n",
    "time_list.append(elapsed_time)\n",
    "plt.savefig(\"Learning_Curve_{}.png\".format(algorithm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}