{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import unsupervised_learning_util as utl\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA, FastICA, KernelPCA\n",
    "from sklearn.manifold import TSNE, LocallyLinearEmbedding, MDS, Isomap, SpectralEmbedding\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, homogeneity_completeness_v_measure\n",
    "from sklearn.metrics import homogeneity_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "from warnings import simplefilter\n",
    "from scipy import linalg\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.style.use(\"ggplot\")\n",
    "mpl.rcParams['figure.figsize'] = [8, 6]\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "mpl.rcParams['savefig.dpi'] = 500\n",
    "\n",
    "\n",
    "NJOBS = 32\n",
    "VERBOSE = 0\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_data = utl.setup([\"MNIST\"])\n",
    "mnist_scaled = {}\n",
    "mnist_scaled['train_X'], mnist_scaled['train_y'], \\\n",
    "mnist_scaled['valid_X'], mnist_scaled['valid_y'], \\\n",
    "mnist_scaled['test_X'], mnist_scaled['test_y'] = utl.split_data(gathered_data[\"MNIST\"][\"X\"],\n",
    "                                                                gathered_data[\"MNIST\"][\"y\"], scale=True)\n",
    "mnist_not_scaled = {}\n",
    "mnist_not_scaled['train_X'], mnist_not_scaled['train_y'], \\\n",
    "mnist_not_scaled['valid_X'], mnist_not_scaled['valid_y'], \\\n",
    "mnist_not_scaled['test_X'], mnist_not_scaled['test_y'] = utl.split_data(gathered_data[\"MNIST\"][\"X\"],\n",
    "                                                                        gathered_data[\"MNIST\"][\"y\"], \n",
    "                                                                        scale=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = \"Clustering/\" + \"KMeans/\"\n",
    "utl.check_folder(temp_folder)\n",
    "save_dir = os.getcwd() + temp_folder\n",
    "limit = 5000\n",
    "idx = [i for i in range(2, 15, 2)]\n",
    "cols = [limit]\n",
    "\n",
    "\n",
    "inertia_results_scaled = pd.DataFrame(columns=[\"Scaled\"],\n",
    "                               index=idx,\n",
    "                               data=np.zeros(shape=(len(idx), len(cols))))\n",
    "inertia_results_not_scaled = pd.DataFrame(columns=[\"Not Scaled\"],\n",
    "                               index=idx,\n",
    "                               data=np.zeros(shape=(len(idx), len(cols))))\n",
    "\n",
    "silhouette_average_results_scaled = pd.DataFrame(columns=[\"Scaled\"], index=idx,\n",
    "                                          data=np.zeros(shape=(len(idx), len(cols))))\n",
    "silhouette_average_results_not_scaled = pd.DataFrame(columns=[\"Not Scaled\"], index=idx,\n",
    "                                          data=np.zeros(shape=(len(idx), len(cols))))\n",
    "silhouette_sample_results_scaled = {}\n",
    "silhouette_sample_results_not_scaled = {}\n",
    "best_inertia = -1e12\n",
    "best_inertia_num_cluster = 0\n",
    "best_silhouette = 0\n",
    "best_silhouette_num_cluster = 0\n",
    "print(\"Starting K-Means Clustering\")\n",
    "\n",
    "for _df in [\"Scaled\", \"Not Scaled\"]:\n",
    "    for k in idx:\n",
    "        print(f\"\\t\\t{_df} Number of Clusters: {k}\")\n",
    "        if _df == \"Scaled\":\n",
    "            temp_train_X = mnist_scaled[\"train_X\"].iloc[:limit, :]\n",
    "            k_means = KMeans(n_clusters=k, verbose=VERBOSE, random_state=42).fit(temp_train_X)\n",
    "            inertia = k_means.inertia_\n",
    "            inertia_results_scaled.loc[k, \"Scaled\"] = inertia\n",
    "            silhouette_average = silhouette_score(temp_train_X, k_means.labels_)\n",
    "            silhouette_average_results_scaled.loc[k, \"Scaled\"] = silhouette_average\n",
    "            temp_silhouette_sample_results = silhouette_samples(temp_train_X, k_means.labels_)\n",
    "            silhouette_sample_results_scaled[f\"NumClusters_{k} DataSize_{limit}\"] = temp_silhouette_sample_results\n",
    "            print(f\"\\t{_df} Current Intertia: {inertia}, Silhouette: {silhouette_average}\")\n",
    "            if inertia > best_inertia:\n",
    "                best_inertia = inertia\n",
    "                best_inertia_num_cluster = k\n",
    "                print(f\"\\t{_df} New Best Inertia: {best_inertia}\")\n",
    "                print(f\"\\t\\t{_df} Inertia Best Number of Clusters: {best_inertia_num_cluster}\")\n",
    "            if silhouette_average > best_silhouette:\n",
    "                best_silhouette = silhouette_average\n",
    "                best_silhouette_num_cluster = k\n",
    "                print(f\"\\t{_df} New Best Silhouette: {best_silhouette}\")\n",
    "                print(f\"\\t\\t{_df} Silhouette Best Number of Clusters: {best_silhouette_num_cluster}\")\n",
    "        elif _df == \"Not Scaled\":\n",
    "            temp_train_X = mnist_not_scaled[\"train_X\"].iloc[:limit, :]\n",
    "            k_means = KMeans(n_clusters=k, verbose=VERBOSE, random_state=42).fit(temp_train_X)\n",
    "            inertia = k_means.inertia_\n",
    "            inertia_results_not_scaled.loc[k, \"Not Scaled\"] = inertia\n",
    "            silhouette_average = silhouette_score(temp_train_X, k_means.labels_)\n",
    "            silhouette_average_results_not_scaled.loc[k, \"Not Scaled\"] = silhouette_average\n",
    "            temp_silhouette_sample_results = silhouette_samples(temp_train_X, k_means.labels_)\n",
    "            silhouette_sample_results_not_scaled[f\"NumClusters_{k} DataSize_{limit}\"] = temp_silhouette_sample_results\n",
    "            print(f\"\\t{_df} Current Intertia: {inertia}, Silhouette: {silhouette_average}\")\n",
    "            if inertia > best_inertia:\n",
    "                best_inertia = inertia\n",
    "                best_inertia_num_cluster = k\n",
    "                print(f\"\\t{_df} New Best Inertia: {best_inertia}\")\n",
    "                print(f\"\\t\\t{_df} Inertia Best Number of Clusters: {best_inertia_num_cluster}\")\n",
    "            if silhouette_average > best_silhouette:\n",
    "                best_silhouette = silhouette_average\n",
    "                best_silhouette_num_cluster = k\n",
    "                print(f\"\\t{_df} New Best Silhouette: {best_silhouette}\")\n",
    "                print(f\"\\t\\t{_df} Silhouette Best Number of Clusters: {best_silhouette_num_cluster}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "inertia_results_scaled.plot(ax=ax1, label=\"Scaled\")\n",
    "inertia_results_not_scaled.plot(ax=ax1, label=\"Not Scaled\")\n",
    "ax1.set_title(f\"K Means Clustering\\nInertia\", fontsize=15, weight='bold')\n",
    "ax1.grid(which='major', linestyle='-', linewidth='0.5', color='white')\n",
    "ax1.set_xlabel(\"K Clusters\", fontsize=15, weight='heavy')\n",
    "ax1.set_ylabel(\"Inertia\", fontsize=15, weight='heavy')\n",
    "ax1.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "silhouette_average_results_scaled.plot(ax=ax2, label=\"Scale\")\n",
    "silhouette_average_results_not_scaled.plot(ax=ax2, label=\"Not Scaled\")\n",
    "ax2.set_title(f\"K Means Clusters\\nSilhouette\", fontsize=15, weight='bold')\n",
    "ax2.grid(which='major', linestyle='-', linewidth='0.5', color='white')\n",
    "ax2.set_xlabel(\"K Clusters\", fontsize=15, weight='heavy')\n",
    "ax2.set_ylabel(\"Average Silhouette Score\", fontsize=15, weight='heavy')\n",
    "ax2.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{os.getcwd()}/{temp_folder}KMEans_Combined_Scaled_Vs_NotScaled.png\", bbox_inches='tight')\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gathered_data = utl.setup([\"MNIST\"])\n",
    "gathered_data_fashion = utl.setup([\"Fashion-MNIST\"])\n",
    "mnist = {}\n",
    "fashion_mnist = {}\n",
    "mnist['train_X'], mnist['train_y'], \\\n",
    "mnist['valid_X'], mnist['valid_y'], \\\n",
    "mnist['test_X'], mnist['test_y'] = utl.split_data(gathered_data[\"MNIST\"][\"X\"], gathered_data[\"MNIST\"][\"y\"], scale=True)\n",
    "\n",
    "fashion_mnist['train_X'], fashion_mnist['train_y'], \\\n",
    "fashion_mnist['valid_X'], fashion_mnist['valid_y'], \\\n",
    "fashion_mnist['test_X'], fashion_mnist['test_y'] = utl.split_data(gathered_data_fashion[\"Fashion-MNIST\"][\"X\"],\n",
    "                                                                  gathered_data_fashion[\"Fashion-MNIST\"][\"y\"], scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = \"Clustering/\" + \"KMeans/\"\n",
    "utl.check_folder(temp_folder)\n",
    "save_dir = os.getcwd() + temp_folder\n",
    "limit = 5000\n",
    "idx = [i for i in range(2, 31, 1)]\n",
    "cols = [\"Inertia\", \"Silhouette\", \"Homogeneity\", \"Completeness\", \"Harmonic_Mean\", \"Calinski_Harabasz\", \"Davies_Bouldin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_results = pd.DataFrame(columns=cols, index=idx,\n",
    "                               data=np.zeros(shape=(len(idx), len(cols))))\n",
    "\n",
    "fashion_results = pd.DataFrame(columns=cols, index=idx,\n",
    "                                          data=np.zeros(shape=(len(idx), len(cols))))\n",
    "\n",
    "print(\"Starting K-Means Clustering\")\n",
    "for _df in [\"MNIST\", \"Fashion-MNIST\"]:\n",
    "    for k in idx:\n",
    "        if _df == \"MNIST\":\n",
    "            temp_train_X = mnist[\"train_X\"].iloc[:limit, :]\n",
    "            temp_train_y = mnist[\"train_y\"].iloc[:limit]\n",
    "            k_means = KMeans(n_clusters=k, verbose=VERBOSE).fit(temp_train_X)\n",
    "            inertia = k_means.inertia_\n",
    "            silhouette_average = silhouette_score(temp_train_X, k_means.labels_, sample_size=limit)\n",
    "            homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(temp_train_y, k_means.labels_)\n",
    "            mnist_results.loc[k, \"Inertia\"] = inertia\n",
    "            mnist_results.loc[k, \"Silhouette\"] = silhouette_average\n",
    "            mnist_results.loc[k, \"Calinski_Harabasz\"] = calinski_harabasz_score(temp_train_X, k_means.labels_)\n",
    "            mnist_results.loc[k, \"Davies_Bouldin\"] = davies_bouldin_score(temp_train_X, k_means.labels_)\n",
    "            mnist_results.loc[k, \"Homogeneity\"] = homogeneity\n",
    "            mnist_results.loc[k, \"Completeness\"] = completeness\n",
    "            mnist_results.loc[k, \"Harmonic_Mean\"] = v_measure\n",
    "            print(f\"\\n\\t{_df} - k={k} \\n{mnist_results.loc[k]}\")\n",
    "\n",
    "        elif _df == \"Fashion-MNIST\":\n",
    "            temp_train_X = fashion_mnist[\"train_X\"].iloc[:limit, :]\n",
    "            temp_train_y = fashion_mnist[\"train_y\"].iloc[:limit]\n",
    "            k_means = KMeans(n_clusters=k, verbose=VERBOSE).fit(temp_train_X)\n",
    "            inertia = k_means.inertia_\n",
    "            silhouette_average = silhouette_score(temp_train_X, k_means.labels_, sample_size=limit)\n",
    "            homogeneity, completeness, v_measure = homogeneity_completeness_v_measure(temp_train_y, k_means.labels_)\n",
    "            fashion_results.loc[k, \"Inertia\"] = inertia\n",
    "            fashion_results.loc[k, \"Silhouette\"] = silhouette_average\n",
    "            fashion_results.loc[k, \"Calinski_Harabasz\"] = calinski_harabasz_score(temp_train_X, k_means.labels_)\n",
    "            fashion_results.loc[k, \"Davies_Bouldin\"] = davies_bouldin_score(temp_train_X, k_means.labels_)\n",
    "            fashion_results.loc[k, \"Homogeneity\"] = homogeneity\n",
    "            fashion_results.loc[k, \"Completeness\"] = completeness\n",
    "            fashion_results.loc[k, \"Harmonic_Mean\"] = v_measure\n",
    "            print(f\"\\n\\t{_df} - k={k} \\n{fashion_results.loc[k]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/MNIST_Results.pkl\", \"rb\") as in_file:\n",
    "    mnist_results = pickle.load(in_file)\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/Fashion_Results.pkl\", \"rb\") as in_file:\n",
    "    fashion_results = pickle.load(in_file)\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = fashion_results / fashion_results.iloc[0]\n",
    "temp2 = mnist_results / mnist_results.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_results[[\"Silhouette\", \"Homogeneity\", \"Completeness\", \"Harmonic_Mean\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_results[[\"Silhouette\", \"Homogeneity\", \"Completeness\", \"Harmonic_Mean\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[[\"Silhouette\", \"Completeness\", \"Davies_Bouldin\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2[[\"Silhouette\", \"Completeness\", \"Davies_Bouldin\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[[\"Silhouette\", \"Calinski_Harabasz\", \"Inertia\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2[[\"Silhouette\", \"Calinski_Harabasz\", \"Inertia\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/MNIST_Results.pkl\", \"wb\") as out_file:\n",
    "    pickle.dump(mnist_results, out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/Fashion_Results.pkl\", \"wb\") as out_file:\n",
    "    pickle.dump(fashion_results, out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "end = 31\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# ax1_secondary = ax1.twinx()\n",
    "# ax2_secondary = ax2.twinx()\n",
    "\n",
    "mnist_model = KMeans()\n",
    "mnist_visualizer = KElbowVisualizer(mnist_model, k=(2, end), ax=ax1, timings=False)\n",
    "mnist_visualizer.fit(mnist[\"train_X\"].iloc[:limit, :])\n",
    "\n",
    "fashion_model = KMeans()\n",
    "fashion_visualizer = KElbowVisualizer(fashion_model, k=(2, end), ax=ax2, timings=False)\n",
    "fashion_visualizer.fit(fashion_mnist[\"train_X\"].iloc[:limit, :])\n",
    "\n",
    "# mnist_results[[\"Silhouette\", \"Homogeneity\", \"Completeness\", \"Harmonic_Mean\"]].iloc[:end].plot(ax=ax1_secondary, linestyle=\"--\")\n",
    "ax1.set_title(f\"K Means Clustering\\nDistortion MNIST\", fontsize=15, weight='bold')\n",
    "# ax1.grid(which='major', linestyle='-', linewidth='0.5', color='white')\n",
    "ax1.set_xlabel(\"K Clusters\", fontsize=15, weight='heavy')\n",
    "ax1.set_ylabel(\"Distortion\", fontsize=15, weight='heavy')\n",
    "ax1.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "\n",
    "# fashion_results[[\"Silhouette\", \"Homogeneity\", \"Completeness\", \"Harmonic_Mean\"]].iloc[:end].plot(ax=ax2_secondary, linestyle=\"--\")\n",
    "ax2.set_title(f\"K Means Clustering\\nDistortion Fashion MNIST\", fontsize=15, weight='bold')\n",
    "# ax2.grid(which='major', linestyle='-', linewidth='0.5', color='white')\n",
    "ax2.set_xlabel(\"K Clusters\", fontsize=15, weight='heavy')\n",
    "ax2.set_ylabel(\"Distortion\", fontsize=15, weight='heavy')\n",
    "ax2.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "\n",
    "plt.savefig(f\"{os.getcwd()}/{temp_folder}KMEans_Elbow_Method_Combined.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Silhouette Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "mnist_cluster_count = 10\n",
    "fashion_cluster_count = 9\n",
    "\n",
    "mnist_model = KMeans(n_clusters=mnist_cluster_count, random_state=42)\n",
    "fashion_model = KMeans(n_clusters=fashion_cluster_count, random_state=42)\n",
    "\n",
    "mnist_vis = SilhouetteVisualizer(mnist_model, ax=ax1, \n",
    "                                 colors='yellowbrick').fit(mnist[\"train_X\"].iloc[:limit, :]).finalize()\n",
    "fashion_mnist_vis = SilhouetteVisualizer(fashion_model, ax=ax2, \n",
    "                                         colors='yellowbrick').fit(fashion_mnist[\"train_X\"].iloc[:limit, :]).finalize()\n",
    "\n",
    "ax1.set_title(f\"Silhouette Plot of KMEans Clustering\\non MNIST with {mnist_cluster_count} Clusters\", fontsize=15, weight='bold')\n",
    "ax1.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "ax1.set_xlabel(\"Silhouette Coefficient Values\", fontsize=15, weight='heavy')\n",
    "ax1.set_ylabel(\"Cluster Label\", fontsize=15, weight='heavy')\n",
    "\n",
    "ax2.set_title(f\"Silhouette Plot of KMEans Clustering\\non Fashion MNIST with {fashion_cluster_count} Clusters\", fontsize=15, weight='bold')\n",
    "ax2.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "ax2.set_xlabel(\"Silhouette Coefficient Values\", fontsize=15, weight='heavy')\n",
    "ax2.set_ylabel(\"Cluster Label\", fontsize=15, weight='heavy')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{os.getcwd()}/{temp_folder}KMEans_Silhouette_Combined.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expectation Maximization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.arange(1, 10, 1).astype(np.int)\n",
    "types = [\"Full\"]\n",
    "columns = [\"AIC_Full\", \"BIC_Full\"]\n",
    "em_mnist_results = pd.DataFrame(columns=columns, index=index, data=np.zeros(shape=(index.shape[0], len(columns))))\n",
    "em_fashion_results = pd.DataFrame(columns=columns, index=index, data=np.zeros(shape=(index.shape[0], len(columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"train_X\"].iloc[:limit, :]\n",
    "for idx in index:\n",
    "    print(f\"N_Components: {idx}\")\n",
    "    for _type in types:\n",
    "        temp_gmm = GaussianMixture(n_components=idx, n_init=10, covariance_type=_type.lower(), warm_start=True, max_iter=500).fit(X)\n",
    "        em_mnist_results.loc[idx, f\"AIC_{_type}\"] = temp_gmm.aic(X)\n",
    "        em_mnist_results.loc[idx, f\"BIC_{_type}\"] = temp_gmm.bic(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/MNIST_EM_Results.pkl\", \"wb\") as out_file:\n",
    "    pickle.dump(em_mnist_results, out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fashion_mnist[\"train_X\"].iloc[:limit, :]\n",
    "for idx in index:\n",
    "    print(f\"N_Components: {idx}\")\n",
    "    for _type in types:\n",
    "        temp_gmm = GaussianMixture(n_components=idx, n_init=10, covariance_type=_type.lower(), warm_start=True, max_iter=500).fit(X)\n",
    "        em_fashion_results.loc[idx, f\"AIC_{_type}\"] = temp_gmm.aic(X)\n",
    "        em_fashion_results.loc[idx, f\"BIC_{_type}\"] = temp_gmm.bic(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/Fashion_EM_Results.pkl\", \"wb\") as out_file:\n",
    "    pickle.dump(em_fashion_results, out_file)\n",
    "    out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/MNIST_EM_Results.pkl\", \"rb\") as in_file:\n",
    "    em_mnist_results = pickle.load(in_file)\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{os.getcwd()}/{temp_folder}/Fashion_EM_Results.pkl\", \"rb\") as in_file:\n",
    "    em_fashion_results = pickle.load(in_file)\n",
    "    in_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "em_mnist_results[[\"AIC_Full\", \"BIC_Full\"]].plot(ax=ax1)\n",
    "ax1.set_title(f\"AIC / BIC Comparison\\n MNIST\", fontsize=15, weight='bold')\n",
    "ax1.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "ax1.set_xlabel(\"N Components\", fontsize=15, weight='heavy')\n",
    "ax1.set_ylabel(\"Information Criterion\", fontsize=15, weight='heavy')\n",
    "\n",
    "em_fashion_results[[\"AIC_Full\", \"BIC_Full\"]].plot(ax=ax2)\n",
    "ax2.set_title(f\"AIC / BIC Comparison\\n Fashion-MNIST\", fontsize=15, weight='bold')\n",
    "ax2.legend(loc=\"best\", markerscale=1.1, frameon=True,\n",
    "                   edgecolor=\"black\", fancybox=True, shadow=True)\n",
    "ax2.set_xlabel(\"N Components\", fontsize=15, weight='heavy')\n",
    "ax2.set_ylabel(\"Information Criterion\", fontsize=15, weight='heavy')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{os.getcwd()}/{temp_folder}EM_AicBic_Combined.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_mnist_results[[\"AIC_Full\", \"BIC_Full\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fashion_mnist[\"train_X\"].iloc[:2000, :]\n",
    "for idx in index:\n",
    "    print(f\"N_Components: {idx}\")\n",
    "    for _type in types:\n",
    "        temp_gmm = GaussianMixture(n_components=idx, n_init=10, covariance_type=_type.lower()).fit(X)\n",
    "        em_fashion_results.loc[idx, f\"AIC_{_type}\"] = temp_gmm.aic(X)\n",
    "        em_fashion_results.loc[idx, f\"BIC_{_type}\"] = temp_gmm.bic(X)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "559px",
    "left": "-1px",
    "right": "20px",
    "top": "393px",
    "width": "381px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
