{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Attempting to load: mnist-train-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 2000 \n",
      "   Shape of Entry: (785,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from sklearn import mixture\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itertools import cycle, islice\n",
    "from LoadData import LoadData\n",
    "\n",
    "color_iter = cycle(['navy', 'c', 'cornflowerblue', 'gold',\n",
    "                              'darkorange'])\n",
    "\n",
    "np.random.seed(0)\n",
    "# mnist_data = pd.read_csv(\"mnist-train-data.csv\", nrows=2000)\n",
    "cwd = pathlib.Path().absolute()\n",
    "training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "training_labels, training_data, training_combined = LoadData(training_data_path, normalize=False, size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(X, Y, means, covariances, index, title):\n",
    "    splot = plt.subplot(5, 1, 1 + index)\n",
    "    for i, (mean, covar, color) in enumerate(zip(\n",
    "            means, covariances, color_iter)):\n",
    "        v, w = linalg.eigh(covar)\n",
    "        v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "        u = w[0] / linalg.norm(w[0])\n",
    "        # as the DP will not use every component it has access to\n",
    "        # unless it needs it, we shouldn't plot the redundant\n",
    "        # components.\n",
    "        if not np.any(Y == i):\n",
    "            continue\n",
    "        plt.scatter(X[Y == i, 0], X[Y == i, 1], .8, color=color)\n",
    "\n",
    "        # Plot an ellipse to show the Gaussian component\n",
    "        angle = np.arctan(u[1] / u[0])\n",
    "        angle = 180. * angle / np.pi  # convert to degrees\n",
    "        ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "        ell.set_clip_box(splot.bbox)\n",
    "        ell.set_alpha(0.5)\n",
    "        splot.add_artist(ell)\n",
    "\n",
    "    plt.xlim(-6., 4. * np.pi - 6.)\n",
    "    plt.ylim(-5., 5.)\n",
    "    plt.title(title)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\envs\\cs7641\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gmm = mixture.GaussianMixture(n_components=10, covariance_type='full', max_iter=100).fit(training_data)\n",
    "plot_results(training_data, gmm.predict(training_data), gmm.means_, gmm.covariances_, 0, 'Expectation-maximization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# Generate datasets. We choose the size big enough to see the scalability\n",
    "# of the algorithms, but not too big to avoid too long running times\n",
    "# ============\n",
    "n_samples = 1500\n",
    "blobs = datasets.make_blobs(n_samples=n_samples, random_state=8)\n",
    "no_structure = np.random.rand(n_samples, 2), None\n",
    "print(no_structure)\n",
    "\n",
    "# Anisotropicly distributed data\n",
    "random_state = 170\n",
    "X, y = datasets.make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_aniso = np.dot(X, transformation)\n",
    "aniso = (X_aniso, y)\n",
    "\n",
    "# blobs with varied variances\n",
    "varied = datasets.make_blobs(n_samples=n_samples,\n",
    "                             cluster_std=[1.0, 2.5, 0.5],\n",
    "                             random_state=random_state)\n",
    "\n",
    "# ============\n",
    "# Set up cluster parameters\n",
    "# ============\n",
    "plt.figure(figsize=(9 * 2 + 3, 12.5))\n",
    "plt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n",
    "                    hspace=.01)\n",
    "\n",
    "plot_num = 1\n",
    "\n",
    "default_base = {'quantile': .3,\n",
    "                'eps': .3,\n",
    "                'damping': .9,\n",
    "                'preference': -200,\n",
    "                'n_neighbors': 10,\n",
    "                'n_clusters': 3,\n",
    "                'min_samples': 20,\n",
    "                'xi': 0.05,\n",
    "                'min_cluster_size': 0.1}\n",
    "\n",
    "datasets = [(blobs, {}), (no_structure, {})]\n",
    "\n",
    "for i_dataset, (dataset, algo_params) in enumerate(datasets):\n",
    "    # update parameters with dataset-specific values\n",
    "    params = default_base.copy()\n",
    "    params.update(algo_params)\n",
    "\n",
    "    X, y = dataset\n",
    "\n",
    "    # normalize dataset for easier parameter selection\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # estimate bandwidth for mean shift\n",
    "    bandwidth = cluster.estimate_bandwidth(X, quantile=params['quantile'])\n",
    "\n",
    "    # connectivity matrix for structured Ward\n",
    "    connectivity = kneighbors_graph(\n",
    "        X, n_neighbors=params['n_neighbors'], include_self=False)\n",
    "    # make connectivity symmetric\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "\n",
    "    # ============\n",
    "    # Create cluster objects\n",
    "    # ============\n",
    "\n",
    "    gmm = mixture.GaussianMixture(\n",
    "        n_components=params['n_clusters'], covariance_type='full')\n",
    "\n",
    "    clustering_algorithms = (\n",
    "        ('GaussianMixture', gmm)\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # catch warnings related to kneighbors_graph\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"the number of connected components of the \" +\n",
    "            \"connectivity matrix is [0-9]{1,2}\" +\n",
    "            \" > 1. Completing it to avoid stopping the tree early.\",\n",
    "            category=UserWarning)\n",
    "        warnings.filterwarnings(\n",
    "            \"ignore\",\n",
    "            message=\"Graph is not fully connected, spectral embedding\" +\n",
    "            \" may not work as expected.\",\n",
    "            category=UserWarning)\n",
    "        algorithm.fit(X)\n",
    "\n",
    "    t1 = time.time()\n",
    "    if hasattr(algorithm, 'labels_'):\n",
    "        y_pred = algorithm.labels_.astype(np.int)\n",
    "    else:\n",
    "        y_pred = algorithm.predict(X)\n",
    "\n",
    "    plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n",
    "    if i_dataset == 0:\n",
    "        plt.title(name, size=18)\n",
    "\n",
    "    colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n",
    "                                         '#f781bf', '#a65628', '#984ea3',\n",
    "                                         '#999999', '#e41a1c', '#dede00']),\n",
    "                                  int(max(y_pred) + 1))))\n",
    "    # add black color for outliers (if any)\n",
    "    colors = np.append(colors, [\"#000000\"])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n",
    "\n",
    "    plt.xlim(-2.5, 2.5)\n",
    "    plt.ylim(-2.5, 2.5)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num += 1\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
