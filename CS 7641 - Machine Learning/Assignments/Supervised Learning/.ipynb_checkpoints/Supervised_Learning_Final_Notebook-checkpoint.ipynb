{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from LoadData import LoadData\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import learning_curve, validation_curve, ShuffleSplit\n",
    "\n",
    "\n",
    "TESTING = True\n",
    "DECISION_TREE = False\n",
    "SUPPORT_VECTOR = True\n",
    "NEURAL_NET = False\n",
    "K_NEAREST = False\n",
    "BOOSTING = False\n",
    "NORMALIZE_DATA = False\n",
    "USE_PCA = True\n",
    "DataSetName = \"MNIST\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    with plt.style.context('ggplot'):\n",
    "        if axes is None:\n",
    "            _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "        axes[0].set_title(title)\n",
    "        if ylim is not None:\n",
    "            axes[0].set_ylim(*ylim)\n",
    "        axes[0].set_xlabel(\"Training examples\")\n",
    "        axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "        train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "            learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                           train_sizes=train_sizes,\n",
    "                           return_times=True)\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "        fit_times_mean = np.mean(fit_times, axis=1)\n",
    "        fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "        # Plot learning curve\n",
    "        axes[0].grid()\n",
    "        axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                             train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                             color=\"r\")\n",
    "        axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                             test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                             color=\"g\")\n",
    "        axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                     label=\"Training score\")\n",
    "        axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                     label=\"Cross-validation score\")\n",
    "        axes[0].legend(loc=\"best\")\n",
    "\n",
    "        # Plot n_samples vs fit_times\n",
    "        axes[1].grid()\n",
    "        axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "        axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                             fit_times_mean + fit_times_std, alpha=0.1)\n",
    "        axes[1].set_xlabel(\"Training examples\")\n",
    "        axes[1].set_ylabel(\"fit_times\")\n",
    "        axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "        # Plot fit_time vs score\n",
    "        axes[2].grid()\n",
    "        axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "        axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                             test_scores_mean + test_scores_std, alpha=0.1)\n",
    "        axes[2].set_xlabel(\"fit_times\")\n",
    "        axes[2].set_ylabel(\"Score\")\n",
    "        axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "        return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "1. Call train_test_split to get the training data and test data (x_train, x_test, y_train, and y_test respectively.\n",
    "2. Save the test data (x_test, y_test) until the end.\n",
    "3. Repeat the following for each algorithm: SVM, Decision Tree, Boosting, NN, and KNN:\n",
    "4. Select a set of hyperparameters to optimize.\n",
    "5. Pass these and the classifier object (DecisionTree for example) into GridSearchCV.\n",
    "6. This returns a clf object that you then call clf.fit(x_train, y_train) to get the best hyperparameters.\n",
    "7. Get the Learning Curve by taking the clf.best_estimator_ and passing it into learning_curve function of scikit learn.\n",
    "8. Plot the learning curve results\n",
    "9. Get the Model Complexity data by taking the clf.best_estimator_ and passing it into the validation_curve function. Pass in one hyperparameter to tune that was not tuned in your GridSearchCV process in number 5 above.\n",
    "10. Plot the results of validation_curve.\n",
    "11. Run the x_test and y_test through clf.best_estimator_ predict to see how the model performs.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 1.\n",
    "\n",
    "\"\"\"\n",
    "classifiers = [\"SVM\", \"Decision Tree\", \"Neural Network\", \"K-Nearest Neighbors\", \"Boosting\"]\n",
    "n_jobs = -1\n",
    "cross_validation = 5\n",
    "verbose_int = 3\n",
    "\n",
    "cwd = pathlib.Path().absolute()\n",
    "\n",
    "if DataSetName == \"MNIST\":\n",
    "    training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/mnist-test-data.csv\".format(cwd)\n",
    "else:\n",
    "    training_data_path = \"{}/fashion-mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/fashion-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "training_labels, training_data, _ = LoadData(training_data_path)\n",
    "testing_labels, testing_data, _ = LoadData(testing_data_path)\n",
    "\n",
    "Scaler = StandardScaler().fit(training_data)\n",
    "\n",
    "training_data = Scaler.transform(training_data)\n",
    "testing_data = Scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 3.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "svm_params = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'gamma': [1e-4, 1e-3, 1e-2, 1e-1],\n",
    "             'max_iter': [1000]}\n",
    "\n",
    "decision_tree_params = {'criterion': ['gini', 'entropy'],\n",
    "                       'max_depth': [50],\n",
    "                       'ccp_alpha': [0.0, 0.1, 0.2, 0.3]}\n",
    "\n",
    "neural_network_params = {'activations': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "                        'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "                        'max_iter': [1000],\n",
    "                        'alpha': [1e-4, 1e-3, 1e-2, 1e-1]}\n",
    "\n",
    "knn_params = {'n_neighbors': [3, 5, 7, 9, 11],\n",
    "             'algorithm': ['ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "boosting_params = {'n_estimators': [50, 100, 150],\n",
    "                  'max_depth': [1, 2, 3],\n",
    "                  'learning_rate': [1e-1, 1e-2, 1e-3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "X = training_data[:2000]\n",
    "Validation_X = X[:400]\n",
    "y = training_labels[:2000]\n",
    "validation_y = y[:400]\n",
    "container = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "train_sizes = np.linspace(.1, 1.0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=svm.SVC()\n",
    "grid_search = GridSearchCV(estimator, param_grid=svm_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "svm_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "svm_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "with parallel_backend('threading'):\n",
    "    grid_search.fit(X,y)\n",
    "\n",
    "    svm_learning_curve_results[\"train_sizes\"], \\\n",
    "    svm_learning_curve_results[\"train_scores\"], \\\n",
    "    svm_learning_curve_results[\"test_scores\"], \\\n",
    "    svm_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "                                                                  X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "                                                                  train_sizes=train_sizes, \n",
    "                                                                  return_times=True)\n",
    "    svm_validation_curve_results[\"train_scores\"], \\\n",
    "    svm_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "                                                                   y=validation_y, n_jobs=n_jobs, \n",
    "                                                                   cv=cross_validation, param_name=\"C\",\n",
    "                                                                   param_range=np.linspace(0.5, 2.5, num=5))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator, param_grid=decision_tree_params,  n_jobs=n_jobs, verbose=verbose_int)\n",
    "dt_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "dt_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid_search.fit(X,y)\n",
    "    dt_learning_curve_results[\"train_sizes\"], \\\n",
    "    dt_learning_curve_results[\"train_scores\"], \\\n",
    "    dt_learning_curve_results[\"test_scores\"], \\\n",
    "    dt_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "                                                                  X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "                                                                  train_sizes=train_sizes, \n",
    "                                                                  return_times=True)\n",
    "    dt_validation_curve_results[\"train_scores\"], \\\n",
    "    dt_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "                                                                  y=validation_y, n_jobs=n_jobs, \n",
    "                                                                  cv=cross_validation, \n",
    "                                                                  param_name='min_samples_leaf',\n",
    "                                                                  param_range=[2, 4, 6, 8])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator, param_grid=neural_network_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "nn_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "nn_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid_search.fit(X,y)\n",
    "    nn_learning_curve_results[\"train_sizes\"], \\\n",
    "    nn_learning_curve_results[\"train_scores\"], \\\n",
    "    nn_learning_curve_results[\"test_scores\"],\\\n",
    "    nn_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "                                                                  X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "                                                                  train_sizes=train_sizes, \n",
    "                                                                  return_times=True) \n",
    "    nn_validation_curve_results[\"train_scores\"], \\\n",
    "    nn_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "                                                                  y=validation_y, n_jobs=n_jobs, \n",
    "                                                                  cv=cross_validation, param_name=\"batch_size\",\n",
    "                                                                  param_range=[i for i in range(100, 400, 100)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(estimator, param_grid=knn_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "knn_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \n",
    "                              \"fit_times\": None}\n",
    "knn_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid_search.fit(X,y)\n",
    "    knn_learning_curve_results[\"train_sizes\"], \\\n",
    "    knn_learning_curve_results[\"train_scores\"], \\\n",
    "    knn_learning_curve_results[\"test_scores\"],\\\n",
    "    knn_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "                                                                  X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "                                                                  train_sizes=train_sizes, \n",
    "                                                                  return_times=True)\n",
    "    knn_validation_curve_results[\"train_scores\"], \\\n",
    "    knn_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "                                                                   y=validation_y, n_jobs=n_jobs, \n",
    "                                                                   cv=cross_validation, param_name=\"leaf_size\",\n",
    "                                                                   param_range=[i for i in range(5, 31, 5)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = GradientBoostingClassifier()\n",
    "grid_search = GridSearchCV(estimator, param_grid=boosting_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "boost_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \n",
    "                                \"fit_times\": None}\n",
    "boost_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    grid_search.fit(X,y)\n",
    "    boost_learning_curve_results[\"train_sizes\"], \\\n",
    "    boost_learning_curve_results[\"train_scores\"], \\\n",
    "    boost_learning_curve_results[\"test_scores\"],\\\n",
    "    boost_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "                                                                  X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "                                                                  train_sizes=train_sizes, \n",
    "                                                                  return_times=True)\n",
    "    boost_validation_curve_results[\"train_scores\"], \\\n",
    "    boost_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "                                                                     y=validation_y, n_jobs=n_jobs, \n",
    "                                                                     cv=cross_validation, \n",
    "                                                                     param_name=\"max_leaf_nodes\",\n",
    "                                                                     param_range=[i for i in range(1, 5, 1)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# STEP 4.\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# for i in range(len(classifiers)):\n",
    "#     if i == \"SVM\":\n",
    "#         estimator=svm.SVC()\n",
    "#         grid_search = GridSearchCV(estimator, param_grid=svm_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "#         svm_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "#         svm_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "        \n",
    "#         svm_learning_curve_results[\"train_sizes\"], \\\n",
    "#         svm_learning_curve_results[\"train_scores\"], \\\n",
    "#         svm_learning_curve_results[\"test_scores\"], \\\n",
    "#         svm_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "#                                                                       X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "#                                                                       train_sizes=train_sizes, \n",
    "#                                                                       return_times=True)\n",
    "#         svm_validation_curve_results[\"train_scores\"], \\\n",
    "#         svm_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "#                                                                        y=validation_y, n_jobs=n_jobs, \n",
    "#                                                                        cv=cross_validation, param_name=\"C\",\n",
    "#                                                                        param_range=np.linspace(0.5, 2.5, num=5))\n",
    "        \n",
    "#     elif i == \"Decision Tree\":\n",
    "#         estimator = DecisionTreeClassifier()\n",
    "#         grid_search = GridSearchCV(estimator, param_grid=decision_tree_params,  n_jobs=n_jobs, verbose=verbose_int)\n",
    "#         dt_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "#         dt_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "        \n",
    "#         dt_learning_curve_results[\"train_sizes\"], \\\n",
    "#         dt_learning_curve_results[\"train_scores\"], \\\n",
    "#         dt_learning_curve_results[\"test_scores\"], \\\n",
    "#         dt_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "#                                                                       X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "#                                                                       train_sizes=train_sizes, \n",
    "#                                                                       return_times=True)\n",
    "#         dt_validation_curve_results[\"train_scores\"], \\\n",
    "#         dt_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "#                                                                       y=validation_y, n_jobs=n_jobs, \n",
    "#                                                                       cv=cross_validation, \n",
    "#                                                                       param_name='min_samples_leaf',\n",
    "#                                                                       param_range=[2, 4, 6, 8])\n",
    "        \n",
    "#     elif i == \"Neural Network\":\n",
    "#         estimator = MLPClassifier()\n",
    "#         grid_search = GridSearchCV(estimator, param_grid=neural_network_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "#         nn_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \"fit_times\": None}\n",
    "#         nn_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "        \n",
    "#         nn_learning_curve_results[\"train_sizes\"], \\\n",
    "#         nn_learning_curve_results[\"train_scores\"], \\\n",
    "#         nn_learning_curve_results[\"test_scores\"],\\\n",
    "#         nn_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "#                                                                       X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "#                                                                       train_sizes=train_sizes, \n",
    "#                                                                       return_times=True) \n",
    "#         nn_validation_curve_results[\"train_scores\"], \\\n",
    "#         nn_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "#                                                                       y=validation_y, n_jobs=n_jobs, \n",
    "#                                                                       cv=cross_validation, param_name=\"batch_size\",\n",
    "#                                                                       param_range=[i for i in range(100, 400, 100)])\n",
    "        \n",
    "#     elif i == \"K-Nearest Neighbors\":\n",
    "#         estimator = KNeighborsClassifier()\n",
    "#         grid_search = GridSearchCV(estimator, param_grid=knn_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "#         knn_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \n",
    "#                                       \"fit_times\": None}\n",
    "#         knn_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "        \n",
    "#         knn_learning_curve_results[\"train_sizes\"], \\\n",
    "#         knn_learning_curve_results[\"train_scores\"], \\\n",
    "#         knn_learning_curve_results[\"test_scores\"],\\\n",
    "#         knn_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "#                                                                       X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "#                                                                       train_sizes=train_sizes, \n",
    "#                                                                       return_times=True)\n",
    "#         knn_validation_curve_results[\"train_scores\"], \\\n",
    "#         knn_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "#                                                                        y=validation_y, n_jobs=n_jobs, \n",
    "#                                                                        cv=cross_validation, param_name=\"leaf_size\",\n",
    "#                                                                        param_range=[i for i in range(5, 31, 5)])\n",
    "        \n",
    "#     elif i == \"Boosting\":\n",
    "#         estimator = GradientBoostingClassifier()\n",
    "#         grid_search = GridSearchCV(estimator, param_grid=boosting_params, n_jobs=n_jobs, verbose=verbose_int)\n",
    "#         boost_learning_curve_results = {\"train_sizes\": None, \"train_scores\": None, \"test_scores\": None, \n",
    "#                                         \"fit_times\": None}\n",
    "#         boost_validation_curve_results = {\"train_scores\": None, \"test_scores\": None}\n",
    "        \n",
    "#         boost_learning_curve_results[\"train_sizes\"], \\\n",
    "#         boost_learning_curve_results[\"train_scores\"], \\\n",
    "#         boost_learning_curve_results[\"test_scores\"],\\\n",
    "#         boost_learning_curve_results[\"fit_times\"], _ = learning_curve(grid_search.best_estimator_, \n",
    "#                                                                       X, y, cv=cross_validation, n_jobs=n_jobs, \n",
    "#                                                                       train_sizes=train_sizes, \n",
    "#                                                                       return_times=True)\n",
    "#         boost_validation_curve_results[\"train_scores\"], \\\n",
    "#         boost_validation_curve_results[\"test_scores\"] = validation_curve(grid_search.best_estimator_, X=Validation_X,\n",
    "#                                                                          y=validation_y, n_jobs=n_jobs, \n",
    "#                                                                          cv=cross_validation, \n",
    "#                                                                          param_name=\"max_leaf_nodes\",\n",
    "#                                                                          param_range=[i for i in range(1, 5, 1)])\n",
    "#     else:\n",
    "#         continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 5.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 6.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 7.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 8.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "STEP 9.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
