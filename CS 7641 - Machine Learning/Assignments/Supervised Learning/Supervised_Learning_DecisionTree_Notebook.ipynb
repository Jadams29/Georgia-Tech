{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from LoadData import LoadData\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import parallel_backend\n",
    "\n",
    "TESTING = True\n",
    "DECISION_TREE = False\n",
    "SUPPORT_VECTOR = True\n",
    "NEURAL_NET = False\n",
    "K_NEAREST = False\n",
    "BOOSTING = False\n",
    "NORMALIZE_DATA = False\n",
    "USE_PCA = True\n",
    "DataSetName = \"MNIST\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i != 999999999999999:\n",
    "    print(\"Here is i: \".format(i))\n",
    "    i += 1\n",
    "print(\"DONE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "if DataSetName == \"MNIST\":\n",
    "    training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/mnist-test-data.csv\".format(cwd)\n",
    "else:\n",
    "    training_data_path = \"{}/fashion-mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/fashion-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    training_labels, training_data, _ = LoadData(training_data_path, normalize=NORMALIZE_DATA)\n",
    "    testing_labels, testing_data, _ = LoadData(testing_data_path, normalize=NORMALIZE_DATA)\n",
    "\n",
    "Scaler = StandardScaler().fit(training_data)\n",
    "        \n",
    "training_data = Scaler.transform(training_data)\n",
    "testing_data = Scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "if DataSetName == \"MNIST\":\n",
    "    training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/mnist-test-data.csv\".format(cwd)\n",
    "else:\n",
    "    training_data_path = \"{}/fashion-mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/fashion-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    training_labels, training_data, _ = LoadData(training_data_path, normalize=NORMALIZE_DATA)\n",
    "    testing_labels, testing_data, _ = LoadData(testing_data_path, normalize=NORMALIZE_DATA)\n",
    "\n",
    "Scaler = StandardScaler().fit(training_data)\n",
    "        \n",
    "training_data = Scaler.transform(training_data)\n",
    "testing_data = Scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TRAINING TIME\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "solvers = [\"Entropy\", \"Gini\"]\n",
    "classifier_list = []\n",
    "entropy_runtime = [0.0]\n",
    "entropy_accuracy = [0.0]\n",
    "\n",
    "gini_runtime = [0.0]\n",
    "gini_accuracy = [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with parallel_backend('threading'):\n",
    "    for solver in solvers:\n",
    "        clf = DecisionTreeClassifier(criterion=solver.lower(), max_depth=100)\n",
    "        for i in range(1, 11, 1):\n",
    "            print(\"{} - Training Size: {}%\".format(solver, (i * 10)))\n",
    "            start_time = timer()\n",
    "            with parallel_backend('threading'):\n",
    "                clf.fit(training_data[:int((60000 * (0.1 * i))), :], training_labels[:int((60000 * (0.1 * i)))])\n",
    "            end_time = timer()\n",
    "            elapsed_time = end_time - start_time\n",
    "            if i == 10:\n",
    "                classifier_list.append(clf)\n",
    "            print(elapsed_time)\n",
    "            if solver == \"Entropy\":\n",
    "                entropy_accuracy.append(clf.score(testing_data, testing_labels))\n",
    "                entropy_runtime.append(elapsed_time)\n",
    "            else:\n",
    "                gini_accuracy.append(clf.score(testing_data, testing_labels))\n",
    "                gini_runtime.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_accuracy = np.asarray(entropy_accuracy)\n",
    "entropy_runtime = np.asarray(entropy_runtime)\n",
    "gini_accuracy = np.asarray(gini_accuracy)\n",
    "gini_runtime = np.asarray(gini_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_accuracy.tofile('entropy_accuracy_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "entropy_runtime.tofile('entropy_runtime_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "gini_accuracy.tofile('gini_accuracy_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "gini_runtime.tofile('gini_runtime_{}.csv'.format(DataSetName),sep=',',format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"tab:orange\", \"tab:blue\", \"tab:green\", \"tab:red\"]\n",
    "solvers = [\"Entropy\", \"Gini\"]\n",
    "\n",
    "run = [entropy_runtime, gini_runtime]\n",
    "acc = [entropy_accuracy, gini_accuracy]\n",
    "\n",
    "for solver in range(len(solvers)):\n",
    "    with plt.style.context('ggplot'):\n",
    "        fig0, ax0 = plt.subplots()\n",
    "        ax0.set_xlabel(\"Percent of Training Set\")\n",
    "        ax0.set_ylabel(\"Accuracy (%)\", color='tab:orange')\n",
    "        ax0.set_title(\"Accuracy vs Training Set Size vs Training Time {} \\n {}\".format(solvers[solver], DataSetName))\n",
    "        ax0.tick_params(axis='y', labelcolor=\"black\")\n",
    "        ax0.set_ylim(0, 1.1)\n",
    "        ax3 = ax0.twinx()\n",
    "        ax3.set_ylabel(\"Training Time (s)\", color=\"tab:blue\")\n",
    "        ax3.set_ylim(0, max(max(entropy_runtime), max(gini_runtime)) + 10)\n",
    "        ax3.tick_params(axis='y', labelcolor=\"black\")\n",
    "        for i in range(1):        \n",
    "            ax0.plot([i for i in range(11)], acc[solver], colors[i], marker='o', label=solvers[solver])\n",
    "            ax3.plot([i for i in range(11)], run[solver], colors[i+1], marker=\"1\", label=\"{} training-time\".format(solvers[solver]))\n",
    "        fig0.tight_layout()\n",
    "        directory = \"{}/Training_{}_{}_Set_Size_Impact_vs_Training_Time.png\".format(cwd, solvers[solver], DataSetName)\n",
    "        plt.savefig(directory)\n",
    "#         plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}