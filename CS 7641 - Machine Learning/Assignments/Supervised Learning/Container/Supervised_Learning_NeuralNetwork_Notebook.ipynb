{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from LoadData import LoadData\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import parallel_backend\n",
    "\n",
    "\n",
    "TESTING = True\n",
    "DECISION_TREE = False\n",
    "SUPPORT_VECTOR = True\n",
    "NEURAL_NET = False\n",
    "K_NEAREST = False\n",
    "BOOSTING = False\n",
    "NORMALIZE_DATA = False\n",
    "USE_PCA = True\n",
    "DataSetName = \"Fashion-MNIST\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load: fashion-mnist-train-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 60000 \n",
      "   Shape of Entry: (785,)\n",
      "\n",
      "Attempting to load: fashion-mnist-test-data.csv\n",
      "\n",
      "Loading Complete\n",
      "Data Statistics: \n",
      "   Number of Entries: 10000 \n",
      "   Shape of Entry: (785,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cwd = pathlib.Path().absolute()\n",
    "if DataSetName == \"MNIST\":\n",
    "    training_data_path = \"{}/mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/mnist-test-data.csv\".format(cwd)\n",
    "else:\n",
    "    training_data_path = \"{}/fashion-mnist-train-data.csv\".format(cwd)\n",
    "    testing_data_path = \"{}/fashion-mnist-test-data.csv\".format(cwd)\n",
    "\n",
    "with parallel_backend('threading'):\n",
    "    training_labels, training_data, _ = LoadData(training_data_path, normalize=NORMALIZE_DATA)\n",
    "    testing_labels, testing_data, _ = LoadData(testing_data_path, normalize=NORMALIZE_DATA)\n",
    "\n",
    "Scaler = StandardScaler().fit(training_data)\n",
    "        \n",
    "training_data = Scaler.transform(training_data)\n",
    "testing_data = Scaler.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAINING TIME\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAINING TIME\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\"Adam\", \"SGD\"]\n",
    "\n",
    "adam_runtime = [0.0]\n",
    "adam_accuracy = [0.0]\n",
    "classifier_list = []\n",
    "sgd_runtime = [0.0]\n",
    "sgd_accuracy = [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam - Training Size: 10%\n",
      "Iteration 1, loss = 0.94039924\n",
      "Iteration 2, loss = 0.48636252\n",
      "Iteration 3, loss = 0.39617357\n",
      "Iteration 4, loss = 0.34771279\n",
      "Iteration 5, loss = 0.30954500\n",
      "Iteration 6, loss = 0.28045704\n",
      "Iteration 7, loss = 0.25365614\n",
      "Iteration 8, loss = 0.22973912\n",
      "Iteration 9, loss = 0.21145787\n",
      "Iteration 10, loss = 0.19929433\n",
      "Iteration 11, loss = 0.19010901\n",
      "Iteration 12, loss = 0.17402643\n",
      "Iteration 13, loss = 0.15727662\n",
      "Iteration 14, loss = 0.14718997\n",
      "Iteration 15, loss = 0.13515464\n",
      "Iteration 16, loss = 0.12549216\n",
      "Iteration 17, loss = 0.11700868\n",
      "Iteration 18, loss = 0.10850945\n",
      "Iteration 19, loss = 0.10335712\n",
      "Iteration 20, loss = 0.10037282\n",
      "Iteration 21, loss = 0.08728491\n",
      "Iteration 22, loss = 0.08529068\n",
      "Iteration 23, loss = 0.07710579\n",
      "Iteration 24, loss = 0.06915218\n",
      "Iteration 25, loss = 0.06657365\n",
      "Iteration 26, loss = 0.06305856\n",
      "Iteration 27, loss = 0.05999002\n",
      "Iteration 28, loss = 0.05819029\n",
      "Iteration 29, loss = 0.05404467\n",
      "Iteration 30, loss = 0.04686618\n",
      "Iteration 31, loss = 0.04377067\n",
      "Iteration 32, loss = 0.04186912\n",
      "Iteration 33, loss = 0.03841960\n",
      "Iteration 34, loss = 0.03434109\n",
      "Iteration 35, loss = 0.03652066\n",
      "Iteration 36, loss = 0.03084338\n",
      "Iteration 37, loss = 0.02776993\n",
      "Iteration 38, loss = 0.02579189\n",
      "Iteration 39, loss = 0.02493220\n",
      "Iteration 40, loss = 0.02422799\n",
      "Iteration 41, loss = 0.02341902\n",
      "Iteration 42, loss = 0.02072703\n",
      "Iteration 43, loss = 0.01982819\n",
      "Iteration 44, loss = 0.01928550\n",
      "Iteration 45, loss = 0.01861465\n",
      "Iteration 46, loss = 0.01673489\n",
      "Iteration 47, loss = 0.01537932\n",
      "Iteration 48, loss = 0.01437970\n",
      "Iteration 49, loss = 0.01385190\n",
      "Iteration 50, loss = 0.01287447\n",
      "Iteration 51, loss = 0.01223450\n",
      "Iteration 52, loss = 0.01164050\n",
      "Iteration 53, loss = 0.01093287\n",
      "Iteration 54, loss = 0.01026498\n",
      "Iteration 55, loss = 0.00981063\n",
      "Iteration 56, loss = 0.00967937\n",
      "Iteration 57, loss = 0.00905891\n",
      "Iteration 58, loss = 0.00822345\n",
      "Iteration 59, loss = 0.00783309\n",
      "Iteration 60, loss = 0.00751959\n",
      "Iteration 61, loss = 0.00714970\n",
      "Iteration 62, loss = 0.00727349\n",
      "Iteration 63, loss = 0.00680211\n",
      "Iteration 64, loss = 0.00658475\n",
      "Iteration 65, loss = 0.00622893\n",
      "Iteration 66, loss = 0.00615651\n",
      "Iteration 67, loss = 0.00595253\n",
      "Iteration 68, loss = 0.00558255\n",
      "Iteration 69, loss = 0.00541810\n",
      "Iteration 70, loss = 0.00523902\n",
      "Iteration 71, loss = 0.00505336\n",
      "Iteration 72, loss = 0.00474971\n",
      "Iteration 73, loss = 0.00459241\n",
      "Iteration 74, loss = 0.00445839\n",
      "Iteration 75, loss = 0.00423907\n",
      "Iteration 76, loss = 0.00404012\n",
      "Iteration 77, loss = 0.00390933\n",
      "Iteration 78, loss = 0.00379317\n",
      "Iteration 79, loss = 0.00367723\n",
      "Iteration 80, loss = 0.00354005\n",
      "Iteration 81, loss = 0.00337985\n",
      "Iteration 82, loss = 0.00331131\n",
      "Iteration 83, loss = 0.00326358\n",
      "Iteration 84, loss = 0.00325417\n",
      "Iteration 85, loss = 0.00309298\n",
      "Iteration 86, loss = 0.00289799\n",
      "Iteration 87, loss = 0.00282341\n",
      "Iteration 88, loss = 0.00269523\n",
      "Iteration 89, loss = 0.00264357\n",
      "Iteration 90, loss = 0.00256079\n",
      "Iteration 91, loss = 0.00253274\n",
      "Iteration 92, loss = 0.00246926\n",
      "Iteration 93, loss = 0.00236535\n",
      "Iteration 94, loss = 0.00229770\n",
      "Iteration 95, loss = 0.00224361\n",
      "Iteration 96, loss = 0.00222983\n",
      "Iteration 97, loss = 0.00217173\n",
      "Iteration 98, loss = 0.00207574\n",
      "Iteration 99, loss = 0.00201395\n",
      "Iteration 100, loss = 0.00195205\n",
      "Iteration 101, loss = 0.00190529\n",
      "Iteration 102, loss = 0.00186721\n",
      "Iteration 103, loss = 0.00183418\n",
      "Iteration 104, loss = 0.00187231\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "11.481896199999994\n",
      "Adam - Training Size: 20%\n",
      "Iteration 1, loss = 0.73520896\n",
      "Iteration 2, loss = 0.42618312\n",
      "Iteration 3, loss = 0.36324247\n",
      "Iteration 4, loss = 0.32530583\n",
      "Iteration 5, loss = 0.29488948\n",
      "Iteration 6, loss = 0.26712905\n",
      "Iteration 7, loss = 0.24284107\n",
      "Iteration 8, loss = 0.23464660\n",
      "Iteration 9, loss = 0.21222848\n",
      "Iteration 10, loss = 0.19865376\n",
      "Iteration 11, loss = 0.18340656\n",
      "Iteration 12, loss = 0.17168872\n",
      "Iteration 13, loss = 0.15929484\n",
      "Iteration 14, loss = 0.14570264\n",
      "Iteration 15, loss = 0.13592280\n",
      "Iteration 16, loss = 0.13110326\n",
      "Iteration 17, loss = 0.12287431\n",
      "Iteration 18, loss = 0.11202287\n",
      "Iteration 19, loss = 0.10761823\n",
      "Iteration 20, loss = 0.09978182\n",
      "Iteration 21, loss = 0.09808220\n",
      "Iteration 22, loss = 0.08490947\n",
      "Iteration 23, loss = 0.07953124\n",
      "Iteration 24, loss = 0.07329015\n",
      "Iteration 25, loss = 0.07529969\n",
      "Iteration 26, loss = 0.06778521\n",
      "Iteration 27, loss = 0.06155481\n",
      "Iteration 28, loss = 0.05806120\n",
      "Iteration 29, loss = 0.05123482\n",
      "Iteration 30, loss = 0.04972523\n",
      "Iteration 31, loss = 0.04529875\n",
      "Iteration 32, loss = 0.04369794\n",
      "Iteration 33, loss = 0.03920176\n",
      "Iteration 34, loss = 0.03539334\n",
      "Iteration 35, loss = 0.03518101\n",
      "Iteration 36, loss = 0.03090879\n",
      "Iteration 37, loss = 0.02802659\n",
      "Iteration 38, loss = 0.02695641\n",
      "Iteration 39, loss = 0.02715534\n",
      "Iteration 40, loss = 0.02666061\n",
      "Iteration 41, loss = 0.02299235\n",
      "Iteration 42, loss = 0.02375313\n",
      "Iteration 43, loss = 0.02211310\n",
      "Iteration 44, loss = 0.01969936\n",
      "Iteration 45, loss = 0.02100850\n",
      "Iteration 46, loss = 0.02613086\n",
      "Iteration 47, loss = 0.01796418\n",
      "Iteration 48, loss = 0.01476065\n",
      "Iteration 49, loss = 0.01370427\n",
      "Iteration 50, loss = 0.01276180\n",
      "Iteration 51, loss = 0.01140036\n",
      "Iteration 52, loss = 0.01001292\n",
      "Iteration 53, loss = 0.00977339\n",
      "Iteration 54, loss = 0.00907174\n",
      "Iteration 55, loss = 0.00918970\n",
      "Iteration 56, loss = 0.00812414\n",
      "Iteration 57, loss = 0.00741202\n",
      "Iteration 58, loss = 0.00676863\n",
      "Iteration 59, loss = 0.00690904\n",
      "Iteration 60, loss = 0.00620906\n",
      "Iteration 61, loss = 0.00615935\n",
      "Iteration 62, loss = 0.00594703\n",
      "Iteration 63, loss = 0.00519545\n",
      "Iteration 64, loss = 0.00480992\n",
      "Iteration 65, loss = 0.00463097\n",
      "Iteration 66, loss = 0.00509821\n",
      "Iteration 67, loss = 0.00459920\n",
      "Iteration 68, loss = 0.00452948\n",
      "Iteration 69, loss = 0.00405711\n",
      "Iteration 70, loss = 0.00357564\n",
      "Iteration 71, loss = 0.00345469\n",
      "Iteration 72, loss = 0.00327961\n",
      "Iteration 73, loss = 0.00310343\n",
      "Iteration 74, loss = 0.00312855\n",
      "Iteration 75, loss = 0.00315048\n",
      "Iteration 76, loss = 0.00283975\n",
      "Iteration 77, loss = 0.00276845\n",
      "Iteration 78, loss = 0.00273533\n",
      "Iteration 79, loss = 0.00250370\n",
      "Iteration 80, loss = 0.00233399\n",
      "Iteration 81, loss = 0.00222051\n",
      "Iteration 82, loss = 0.00217557\n",
      "Iteration 83, loss = 0.00212265\n",
      "Iteration 84, loss = 0.00214077\n",
      "Iteration 85, loss = 0.00291922\n",
      "Iteration 86, loss = 0.10239628\n",
      "Iteration 87, loss = 0.15951105\n",
      "Iteration 88, loss = 0.06693724\n",
      "Iteration 89, loss = 0.02245062\n",
      "Iteration 90, loss = 0.00766330\n",
      "Iteration 91, loss = 0.00359230\n",
      "Iteration 92, loss = 0.00269507\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "18.389360600000003\n",
      "Adam - Training Size: 30%\n",
      "Iteration 1, loss = 0.65578246\n",
      "Iteration 2, loss = 0.40305847\n",
      "Iteration 3, loss = 0.35248680\n",
      "Iteration 4, loss = 0.31589926\n",
      "Iteration 5, loss = 0.28887931\n",
      "Iteration 6, loss = 0.26388864\n",
      "Iteration 7, loss = 0.24537687\n",
      "Iteration 8, loss = 0.22947403\n",
      "Iteration 9, loss = 0.21333096\n",
      "Iteration 10, loss = 0.19725356\n",
      "Iteration 11, loss = 0.18790828\n",
      "Iteration 12, loss = 0.17151670\n",
      "Iteration 13, loss = 0.16193296\n",
      "Iteration 14, loss = 0.15091277\n",
      "Iteration 15, loss = 0.14191250\n",
      "Iteration 16, loss = 0.13286896\n",
      "Iteration 17, loss = 0.12705584\n",
      "Iteration 18, loss = 0.11747178\n",
      "Iteration 19, loss = 0.10943173\n",
      "Iteration 20, loss = 0.09909729\n",
      "Iteration 21, loss = 0.09650077\n",
      "Iteration 22, loss = 0.09207006\n",
      "Iteration 23, loss = 0.08817997\n",
      "Iteration 24, loss = 0.07703113\n",
      "Iteration 25, loss = 0.07397997\n",
      "Iteration 26, loss = 0.07166445\n",
      "Iteration 27, loss = 0.06718255\n",
      "Iteration 28, loss = 0.05848794\n",
      "Iteration 29, loss = 0.05614349\n",
      "Iteration 30, loss = 0.05282726\n",
      "Iteration 31, loss = 0.05003218\n",
      "Iteration 32, loss = 0.04695370\n",
      "Iteration 33, loss = 0.04666877\n",
      "Iteration 34, loss = 0.03996887\n",
      "Iteration 35, loss = 0.04068158\n",
      "Iteration 36, loss = 0.03852178\n",
      "Iteration 37, loss = 0.03355185\n",
      "Iteration 38, loss = 0.03073274\n",
      "Iteration 39, loss = 0.02698617\n",
      "Iteration 40, loss = 0.03105192\n",
      "Iteration 41, loss = 0.03231182\n",
      "Iteration 42, loss = 0.02624196\n",
      "Iteration 43, loss = 0.02324124\n",
      "Iteration 44, loss = 0.02435306\n",
      "Iteration 45, loss = 0.03312086\n",
      "Iteration 46, loss = 0.04421498\n",
      "Iteration 47, loss = 0.03508243\n",
      "Iteration 48, loss = 0.02101637\n",
      "Iteration 49, loss = 0.01453859\n",
      "Iteration 50, loss = 0.01292071\n",
      "Iteration 51, loss = 0.01286336\n",
      "Iteration 52, loss = 0.01126258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53, loss = 0.01016796\n",
      "Iteration 54, loss = 0.01248765\n",
      "Iteration 55, loss = 0.04010624\n",
      "Iteration 56, loss = 0.01974556\n",
      "Iteration 57, loss = 0.03055691\n",
      "Iteration 58, loss = 0.02406151\n",
      "Iteration 59, loss = 0.01185145\n",
      "Iteration 60, loss = 0.00746108\n",
      "Iteration 61, loss = 0.00658302\n",
      "Iteration 62, loss = 0.00603014\n",
      "Iteration 63, loss = 0.00607505\n",
      "Iteration 64, loss = 0.00503064\n",
      "Iteration 65, loss = 0.00473752\n",
      "Iteration 66, loss = 0.00463013\n",
      "Iteration 67, loss = 0.00487682\n",
      "Iteration 68, loss = 0.00419064\n",
      "Iteration 69, loss = 0.00437297\n",
      "Iteration 70, loss = 0.00459486\n",
      "Iteration 71, loss = 0.00358480\n",
      "Iteration 72, loss = 0.00320350\n",
      "Iteration 73, loss = 0.00316731\n",
      "Iteration 74, loss = 0.00310142\n",
      "Iteration 75, loss = 0.00311727\n",
      "Iteration 76, loss = 0.00272718\n",
      "Iteration 77, loss = 0.00304872\n",
      "Iteration 78, loss = 0.00310596\n",
      "Iteration 79, loss = 0.03754234\n",
      "Iteration 80, loss = 0.15746391\n",
      "Iteration 81, loss = 0.05422111\n",
      "Iteration 82, loss = 0.01432979\n",
      "Iteration 83, loss = 0.01634781\n",
      "Iteration 84, loss = 0.01176913\n",
      "Iteration 85, loss = 0.00489163\n",
      "Iteration 86, loss = 0.00299851\n",
      "Iteration 87, loss = 0.00241071\n",
      "Iteration 88, loss = 0.00217861\n",
      "Iteration 89, loss = 0.00205777\n",
      "Iteration 90, loss = 0.00198072\n",
      "Iteration 91, loss = 0.00192141\n",
      "Iteration 92, loss = 0.00191870\n",
      "Iteration 93, loss = 0.00179900\n",
      "Iteration 94, loss = 0.00173034\n",
      "Iteration 95, loss = 0.00171569\n",
      "Iteration 96, loss = 0.00162057\n",
      "Iteration 97, loss = 0.00157912\n",
      "Iteration 98, loss = 0.00151158\n",
      "Iteration 99, loss = 0.00148867\n",
      "Iteration 100, loss = 0.00151466\n",
      "Iteration 101, loss = 0.00142848\n",
      "Iteration 102, loss = 0.00139488\n",
      "Iteration 103, loss = 0.00134457\n",
      "Iteration 104, loss = 0.00128721\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "32.4765919\n",
      "Adam - Training Size: 40%\n",
      "Iteration 1, loss = 0.59898249\n",
      "Iteration 2, loss = 0.39036123\n",
      "Iteration 3, loss = 0.34396002\n",
      "Iteration 4, loss = 0.30824014\n",
      "Iteration 5, loss = 0.28830612\n",
      "Iteration 6, loss = 0.26188790\n",
      "Iteration 7, loss = 0.24367808\n",
      "Iteration 8, loss = 0.22784704\n",
      "Iteration 9, loss = 0.21427565\n",
      "Iteration 10, loss = 0.20028825\n",
      "Iteration 11, loss = 0.18804468\n",
      "Iteration 12, loss = 0.17983196\n",
      "Iteration 13, loss = 0.16957653\n",
      "Iteration 14, loss = 0.15712773\n",
      "Iteration 15, loss = 0.14735605\n",
      "Iteration 16, loss = 0.13750549\n",
      "Iteration 17, loss = 0.12967965\n",
      "Iteration 18, loss = 0.12604696\n",
      "Iteration 19, loss = 0.11577243\n",
      "Iteration 20, loss = 0.11248615\n",
      "Iteration 21, loss = 0.10655844\n",
      "Iteration 22, loss = 0.09894331\n",
      "Iteration 23, loss = 0.09324750\n",
      "Iteration 24, loss = 0.08736645\n",
      "Iteration 25, loss = 0.08288125\n",
      "Iteration 26, loss = 0.07430905\n",
      "Iteration 27, loss = 0.07102336\n",
      "Iteration 28, loss = 0.06884034\n",
      "Iteration 29, loss = 0.06747283\n",
      "Iteration 30, loss = 0.06027636\n",
      "Iteration 31, loss = 0.05916357\n",
      "Iteration 32, loss = 0.06237870\n",
      "Iteration 33, loss = 0.06725202\n",
      "Iteration 34, loss = 0.05819982\n",
      "Iteration 35, loss = 0.04895671\n",
      "Iteration 36, loss = 0.04589126\n",
      "Iteration 37, loss = 0.04355583\n",
      "Iteration 38, loss = 0.03930765\n",
      "Iteration 39, loss = 0.03743819\n",
      "Iteration 40, loss = 0.04065856\n",
      "Iteration 41, loss = 0.03180705\n",
      "Iteration 42, loss = 0.03279901\n",
      "Iteration 43, loss = 0.02866430\n",
      "Iteration 44, loss = 0.03124953\n",
      "Iteration 45, loss = 0.02777193\n",
      "Iteration 46, loss = 0.02499401\n",
      "Iteration 47, loss = 0.02382947\n",
      "Iteration 48, loss = 0.02601171\n",
      "Iteration 49, loss = 0.01899041\n",
      "Iteration 50, loss = 0.01731798\n",
      "Iteration 51, loss = 0.02234691\n",
      "Iteration 52, loss = 0.02013974\n",
      "Iteration 53, loss = 0.02078703\n",
      "Iteration 54, loss = 0.02575707\n",
      "Iteration 55, loss = 0.05486594\n",
      "Iteration 56, loss = 0.04674227\n",
      "Iteration 57, loss = 0.02369101\n",
      "Iteration 58, loss = 0.01325388\n",
      "Iteration 59, loss = 0.01038669\n",
      "Iteration 60, loss = 0.00898106\n",
      "Iteration 61, loss = 0.00876398\n",
      "Iteration 62, loss = 0.00943586\n",
      "Iteration 63, loss = 0.00795276\n",
      "Iteration 64, loss = 0.00834968\n",
      "Iteration 65, loss = 0.00779604\n",
      "Iteration 66, loss = 0.00999162\n",
      "Iteration 67, loss = 0.00749579\n",
      "Iteration 68, loss = 0.00916237\n",
      "Iteration 69, loss = 0.03644529\n",
      "Iteration 70, loss = 0.03029110\n",
      "Iteration 71, loss = 0.02525049\n",
      "Iteration 72, loss = 0.02907219\n",
      "Iteration 73, loss = 0.02425229\n",
      "Iteration 74, loss = 0.02004650\n",
      "Iteration 75, loss = 0.01111336\n",
      "Iteration 76, loss = 0.00495598\n",
      "Iteration 77, loss = 0.00341209\n",
      "Iteration 78, loss = 0.00307860\n",
      "Iteration 79, loss = 0.00312564\n",
      "Iteration 80, loss = 0.00315603\n",
      "Iteration 81, loss = 0.00271922\n",
      "Iteration 82, loss = 0.00240766\n",
      "Iteration 83, loss = 0.00246999\n",
      "Iteration 84, loss = 0.00237591\n",
      "Iteration 85, loss = 0.00258895\n",
      "Iteration 86, loss = 0.00237136\n",
      "Iteration 87, loss = 0.00230745\n",
      "Iteration 88, loss = 0.00224802\n",
      "Iteration 89, loss = 0.00208875\n",
      "Iteration 90, loss = 0.00220673\n",
      "Iteration 91, loss = 0.00238859\n",
      "Iteration 92, loss = 0.00207618\n",
      "Iteration 93, loss = 0.01754640\n",
      "Iteration 94, loss = 0.14620009\n",
      "Iteration 95, loss = 0.05285731\n",
      "Iteration 96, loss = 0.01672510\n",
      "Iteration 97, loss = 0.00773791\n",
      "Iteration 98, loss = 0.00379285\n",
      "Iteration 99, loss = 0.00237331\n",
      "Iteration 100, loss = 0.00203690\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "45.806509399999996\n",
      "Adam - Training Size: 50%\n",
      "Iteration 1, loss = 0.55783800\n",
      "Iteration 2, loss = 0.38091189\n",
      "Iteration 3, loss = 0.33267523\n",
      "Iteration 4, loss = 0.30341662\n",
      "Iteration 5, loss = 0.27623697\n",
      "Iteration 6, loss = 0.25849427\n",
      "Iteration 7, loss = 0.23672273\n",
      "Iteration 8, loss = 0.22581162\n",
      "Iteration 9, loss = 0.20833840\n",
      "Iteration 10, loss = 0.19801166\n",
      "Iteration 11, loss = 0.18649685\n",
      "Iteration 12, loss = 0.17537840\n",
      "Iteration 13, loss = 0.16401688\n",
      "Iteration 14, loss = 0.15872594\n",
      "Iteration 15, loss = 0.14709897\n",
      "Iteration 16, loss = 0.13901403\n",
      "Iteration 17, loss = 0.13390645\n",
      "Iteration 18, loss = 0.12633163\n",
      "Iteration 19, loss = 0.11728609\n",
      "Iteration 20, loss = 0.10923677\n",
      "Iteration 21, loss = 0.10615385\n",
      "Iteration 22, loss = 0.10149323\n",
      "Iteration 23, loss = 0.09610867\n",
      "Iteration 24, loss = 0.08757441\n",
      "Iteration 25, loss = 0.08329609\n",
      "Iteration 26, loss = 0.07822064\n",
      "Iteration 27, loss = 0.08004275\n",
      "Iteration 28, loss = 0.07169372\n",
      "Iteration 29, loss = 0.06749111\n",
      "Iteration 30, loss = 0.06400567\n",
      "Iteration 31, loss = 0.05712479\n",
      "Iteration 32, loss = 0.05452218\n",
      "Iteration 33, loss = 0.06096571\n",
      "Iteration 34, loss = 0.05878376\n",
      "Iteration 35, loss = 0.05674870\n",
      "Iteration 36, loss = 0.05589567\n",
      "Iteration 37, loss = 0.04407567\n",
      "Iteration 38, loss = 0.03765953\n",
      "Iteration 39, loss = 0.03661512\n",
      "Iteration 40, loss = 0.03536972\n",
      "Iteration 41, loss = 0.03602675\n",
      "Iteration 42, loss = 0.03477014\n",
      "Iteration 43, loss = 0.03437426\n",
      "Iteration 44, loss = 0.04347251\n",
      "Iteration 45, loss = 0.03196880\n",
      "Iteration 46, loss = 0.02727877\n",
      "Iteration 47, loss = 0.02472902\n",
      "Iteration 48, loss = 0.02457723\n",
      "Iteration 49, loss = 0.02685888\n",
      "Iteration 50, loss = 0.03134309\n",
      "Iteration 51, loss = 0.02666912\n",
      "Iteration 52, loss = 0.02544955\n",
      "Iteration 53, loss = 0.02240473\n",
      "Iteration 54, loss = 0.01600997\n",
      "Iteration 55, loss = 0.01652769\n",
      "Iteration 56, loss = 0.01621208\n",
      "Iteration 57, loss = 0.01529384\n",
      "Iteration 58, loss = 0.01317258\n",
      "Iteration 59, loss = 0.01273829\n",
      "Iteration 60, loss = 0.01244039\n",
      "Iteration 61, loss = 0.04699011\n",
      "Iteration 62, loss = 0.06384701\n",
      "Iteration 63, loss = 0.03276752\n",
      "Iteration 64, loss = 0.01793117\n",
      "Iteration 65, loss = 0.01361176\n",
      "Iteration 66, loss = 0.00802994\n",
      "Iteration 67, loss = 0.00830606\n",
      "Iteration 68, loss = 0.00705965\n",
      "Iteration 69, loss = 0.00535802\n",
      "Iteration 70, loss = 0.00441283\n",
      "Iteration 71, loss = 0.01270555\n",
      "Iteration 72, loss = 0.03124727\n",
      "Iteration 73, loss = 0.02389769\n",
      "Iteration 74, loss = 0.02529674\n",
      "Iteration 75, loss = 0.01085479\n",
      "Iteration 76, loss = 0.00498871\n",
      "Iteration 77, loss = 0.00410696\n",
      "Iteration 78, loss = 0.00952301\n",
      "Iteration 79, loss = 0.00490598\n",
      "Iteration 80, loss = 0.00358333\n",
      "Iteration 81, loss = 0.00298065\n",
      "Iteration 82, loss = 0.00263976\n",
      "Iteration 83, loss = 0.00241045\n",
      "Iteration 84, loss = 0.00237524\n",
      "Iteration 85, loss = 0.07834512\n",
      "Iteration 86, loss = 0.06475513\n",
      "Iteration 87, loss = 0.02093847\n",
      "Iteration 88, loss = 0.00949441\n",
      "Iteration 89, loss = 0.00676738\n",
      "Iteration 90, loss = 0.00284817\n",
      "Iteration 91, loss = 0.00232091\n",
      "Iteration 92, loss = 0.00215638\n",
      "Iteration 93, loss = 0.00206751\n",
      "Iteration 94, loss = 0.00193863\n",
      "Iteration 95, loss = 0.00185654\n",
      "Iteration 96, loss = 0.00182231\n",
      "Iteration 97, loss = 0.00177184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 98, loss = 0.00170973\n",
      "Iteration 99, loss = 0.00163673\n",
      "Iteration 100, loss = 0.00168876\n",
      "Iteration 101, loss = 0.00174220\n",
      "Iteration 102, loss = 0.00153840\n",
      "Iteration 103, loss = 0.00144763\n",
      "Iteration 104, loss = 0.02062240\n",
      "Iteration 105, loss = 0.14504970\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "58.16114519999999\n",
      "Adam - Training Size: 60%\n",
      "Iteration 1, loss = 0.55495578\n",
      "Iteration 2, loss = 0.37087896\n",
      "Iteration 3, loss = 0.32707010\n",
      "Iteration 4, loss = 0.30024937\n",
      "Iteration 5, loss = 0.27518893\n",
      "Iteration 6, loss = 0.25753611\n",
      "Iteration 7, loss = 0.23947158\n",
      "Iteration 8, loss = 0.22354344\n",
      "Iteration 9, loss = 0.20716594\n",
      "Iteration 10, loss = 0.19665457\n",
      "Iteration 11, loss = 0.18780368\n",
      "Iteration 12, loss = 0.17718418\n",
      "Iteration 13, loss = 0.16531554\n",
      "Iteration 14, loss = 0.15463482\n",
      "Iteration 15, loss = 0.14584105\n",
      "Iteration 16, loss = 0.13794473\n",
      "Iteration 17, loss = 0.13213904\n",
      "Iteration 18, loss = 0.12756847\n",
      "Iteration 19, loss = 0.11702196\n",
      "Iteration 20, loss = 0.11265193\n",
      "Iteration 21, loss = 0.10472537\n",
      "Iteration 22, loss = 0.10458748\n",
      "Iteration 23, loss = 0.09427048\n",
      "Iteration 24, loss = 0.09881281\n",
      "Iteration 25, loss = 0.08882828\n",
      "Iteration 26, loss = 0.08087721\n",
      "Iteration 27, loss = 0.07692015\n",
      "Iteration 28, loss = 0.08196004\n",
      "Iteration 29, loss = 0.07831878\n",
      "Iteration 30, loss = 0.06767367\n",
      "Iteration 31, loss = 0.06461997\n",
      "Iteration 32, loss = 0.06186816\n",
      "Iteration 33, loss = 0.06210585\n",
      "Iteration 34, loss = 0.05477251\n",
      "Iteration 35, loss = 0.05605132\n",
      "Iteration 36, loss = 0.04548646\n",
      "Iteration 37, loss = 0.04860665\n",
      "Iteration 38, loss = 0.05630221\n",
      "Iteration 39, loss = 0.04247162\n",
      "Iteration 40, loss = 0.04167367\n",
      "Iteration 41, loss = 0.04553774\n",
      "Iteration 42, loss = 0.04291113\n",
      "Iteration 43, loss = 0.04038946\n",
      "Iteration 44, loss = 0.03454470\n",
      "Iteration 45, loss = 0.02775573\n",
      "Iteration 46, loss = 0.02985067\n",
      "Iteration 47, loss = 0.03464844\n",
      "Iteration 48, loss = 0.02874459\n",
      "Iteration 49, loss = 0.03064843\n",
      "Iteration 50, loss = 0.02539007\n",
      "Iteration 51, loss = 0.02506200\n",
      "Iteration 52, loss = 0.02967237\n",
      "Iteration 53, loss = 0.04311153\n",
      "Iteration 54, loss = 0.03499082\n",
      "Iteration 55, loss = 0.02286925\n",
      "Iteration 56, loss = 0.01873524\n",
      "Iteration 57, loss = 0.01513734\n",
      "Iteration 58, loss = 0.01430797\n",
      "Iteration 59, loss = 0.01390313\n",
      "Iteration 60, loss = 0.02150520\n",
      "Iteration 61, loss = 0.02272566\n",
      "Iteration 62, loss = 0.01861527\n",
      "Iteration 63, loss = 0.02749335\n",
      "Iteration 64, loss = 0.02822175\n",
      "Iteration 65, loss = 0.02485716\n",
      "Iteration 66, loss = 0.03705034\n",
      "Iteration 67, loss = 0.02518720\n",
      "Iteration 68, loss = 0.01229673\n",
      "Iteration 69, loss = 0.00774447\n",
      "Iteration 70, loss = 0.01096361\n",
      "Iteration 71, loss = 0.00961624\n",
      "Iteration 72, loss = 0.01463929\n",
      "Iteration 73, loss = 0.01810957\n",
      "Iteration 74, loss = 0.02342533\n",
      "Iteration 75, loss = 0.04132820\n",
      "Iteration 76, loss = 0.01814026\n",
      "Iteration 77, loss = 0.00901500\n",
      "Iteration 78, loss = 0.00511373\n",
      "Iteration 79, loss = 0.01030366\n",
      "Iteration 80, loss = 0.02245471\n",
      "Iteration 81, loss = 0.00785284\n",
      "Iteration 82, loss = 0.00393849\n",
      "Iteration 83, loss = 0.00385251\n",
      "Iteration 84, loss = 0.00293944\n",
      "Iteration 85, loss = 0.00533067\n",
      "Iteration 86, loss = 0.05289028\n",
      "Iteration 87, loss = 0.03466559\n",
      "Iteration 88, loss = 0.01554020\n",
      "Iteration 89, loss = 0.01611642\n",
      "Iteration 90, loss = 0.01253408\n",
      "Iteration 91, loss = 0.00567039\n",
      "Iteration 92, loss = 0.00437844\n",
      "Iteration 93, loss = 0.00242369\n",
      "Iteration 94, loss = 0.00202210\n",
      "Iteration 95, loss = 0.00188682\n",
      "Iteration 96, loss = 0.00200327\n",
      "Iteration 97, loss = 0.00175764\n",
      "Iteration 98, loss = 0.00170853\n",
      "Iteration 99, loss = 0.00183342\n",
      "Iteration 100, loss = 0.00170267\n",
      "Iteration 101, loss = 0.00161238\n",
      "Iteration 102, loss = 0.05809035\n",
      "Iteration 103, loss = 0.08718655\n",
      "Iteration 104, loss = 0.01837751\n",
      "Iteration 105, loss = 0.00604603\n",
      "Iteration 106, loss = 0.00372031\n",
      "Iteration 107, loss = 0.00277185\n",
      "Iteration 108, loss = 0.00255023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "78.36378310000003\n",
      "Adam - Training Size: 70%\n",
      "Iteration 1, loss = 0.53197293\n",
      "Iteration 2, loss = 0.36434417\n",
      "Iteration 3, loss = 0.31983527\n",
      "Iteration 4, loss = 0.29132269\n",
      "Iteration 5, loss = 0.27055374\n",
      "Iteration 6, loss = 0.24939633\n",
      "Iteration 7, loss = 0.23498515\n",
      "Iteration 8, loss = 0.21942038\n",
      "Iteration 9, loss = 0.20870909\n",
      "Iteration 10, loss = 0.19522048\n",
      "Iteration 11, loss = 0.18550840\n",
      "Iteration 12, loss = 0.17344211\n",
      "Iteration 13, loss = 0.16816108\n",
      "Iteration 14, loss = 0.16170256\n",
      "Iteration 15, loss = 0.15533811\n",
      "Iteration 16, loss = 0.14559551\n",
      "Iteration 17, loss = 0.13934546\n",
      "Iteration 18, loss = 0.13079637\n",
      "Iteration 19, loss = 0.12394000\n",
      "Iteration 20, loss = 0.11992733\n",
      "Iteration 21, loss = 0.11383360\n",
      "Iteration 22, loss = 0.11090157\n",
      "Iteration 23, loss = 0.10698570\n",
      "Iteration 24, loss = 0.10101498\n",
      "Iteration 25, loss = 0.09595537\n",
      "Iteration 26, loss = 0.08843202\n",
      "Iteration 27, loss = 0.08651831\n",
      "Iteration 28, loss = 0.08348917\n",
      "Iteration 29, loss = 0.08306667\n",
      "Iteration 30, loss = 0.07418073\n",
      "Iteration 31, loss = 0.07309134\n",
      "Iteration 32, loss = 0.06933001\n",
      "Iteration 33, loss = 0.06961768\n",
      "Iteration 34, loss = 0.06818184\n",
      "Iteration 35, loss = 0.05937676\n",
      "Iteration 36, loss = 0.05707876\n",
      "Iteration 37, loss = 0.05350727\n",
      "Iteration 38, loss = 0.05561287\n",
      "Iteration 39, loss = 0.05233190\n",
      "Iteration 40, loss = 0.04805593\n",
      "Iteration 41, loss = 0.04803026\n",
      "Iteration 42, loss = 0.04560616\n",
      "Iteration 43, loss = 0.04282091\n",
      "Iteration 44, loss = 0.05081830\n",
      "Iteration 45, loss = 0.04634467\n",
      "Iteration 46, loss = 0.04214787\n",
      "Iteration 47, loss = 0.03930820\n",
      "Iteration 48, loss = 0.03849335\n",
      "Iteration 49, loss = 0.03344714\n",
      "Iteration 50, loss = 0.02634876\n",
      "Iteration 51, loss = 0.03417244\n",
      "Iteration 52, loss = 0.03926084\n",
      "Iteration 53, loss = 0.04009332\n",
      "Iteration 54, loss = 0.03125306\n",
      "Iteration 55, loss = 0.02686247\n",
      "Iteration 56, loss = 0.02222962\n",
      "Iteration 57, loss = 0.02763268\n",
      "Iteration 58, loss = 0.02746322\n",
      "Iteration 59, loss = 0.03106147\n",
      "Iteration 60, loss = 0.02326559\n",
      "Iteration 61, loss = 0.02302848\n",
      "Iteration 62, loss = 0.03218954\n",
      "Iteration 63, loss = 0.02442079\n",
      "Iteration 64, loss = 0.01653650\n",
      "Iteration 65, loss = 0.02273766\n",
      "Iteration 66, loss = 0.03835586\n",
      "Iteration 67, loss = 0.02981677\n",
      "Iteration 68, loss = 0.01736985\n",
      "Iteration 69, loss = 0.01362751\n",
      "Iteration 70, loss = 0.01357645\n",
      "Iteration 71, loss = 0.03180854\n",
      "Iteration 72, loss = 0.01802819\n",
      "Iteration 73, loss = 0.00935769\n",
      "Iteration 74, loss = 0.01054732\n",
      "Iteration 75, loss = 0.01455524\n",
      "Iteration 76, loss = 0.02695742\n",
      "Iteration 77, loss = 0.03318772\n",
      "Iteration 78, loss = 0.03383629\n",
      "Iteration 79, loss = 0.01584672\n",
      "Iteration 80, loss = 0.00776030\n",
      "Iteration 81, loss = 0.00647895\n",
      "Iteration 82, loss = 0.01375872\n",
      "Iteration 83, loss = 0.01685945\n",
      "Iteration 84, loss = 0.01328548\n",
      "Iteration 85, loss = 0.01494616\n",
      "Iteration 86, loss = 0.02128358\n",
      "Iteration 87, loss = 0.01868107\n",
      "Iteration 88, loss = 0.02783855\n",
      "Iteration 89, loss = 0.03709251\n",
      "Iteration 90, loss = 0.01068241\n",
      "Iteration 91, loss = 0.01050680\n",
      "Iteration 92, loss = 0.00429133\n",
      "Iteration 93, loss = 0.00531615\n",
      "Iteration 94, loss = 0.00483247\n",
      "Iteration 95, loss = 0.00404486\n",
      "Iteration 96, loss = 0.00387365\n",
      "Iteration 97, loss = 0.01856073\n",
      "Iteration 98, loss = 0.06717486\n",
      "Iteration 99, loss = 0.01629672\n",
      "Iteration 100, loss = 0.00535922\n",
      "Iteration 101, loss = 0.00288996\n",
      "Iteration 102, loss = 0.00243670\n",
      "Iteration 103, loss = 0.00223940\n",
      "Iteration 104, loss = 0.00239997\n",
      "Iteration 105, loss = 0.00197924\n",
      "Iteration 106, loss = 0.00190196\n",
      "Iteration 107, loss = 0.00200281\n",
      "Iteration 108, loss = 0.00263214\n",
      "Iteration 109, loss = 0.09012620\n",
      "Iteration 110, loss = 0.05718152\n",
      "Iteration 111, loss = 0.01418899\n",
      "Iteration 112, loss = 0.00448872\n",
      "Iteration 113, loss = 0.00239397\n",
      "Iteration 114, loss = 0.00225022\n",
      "Iteration 115, loss = 0.00199375\n",
      "Iteration 116, loss = 0.00185357\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "90.91292659999999\n",
      "Adam - Training Size: 80%\n",
      "Iteration 1, loss = 0.50906426\n",
      "Iteration 2, loss = 0.35561543\n",
      "Iteration 3, loss = 0.31692849\n",
      "Iteration 4, loss = 0.28895082\n",
      "Iteration 5, loss = 0.26664660\n",
      "Iteration 6, loss = 0.24848185\n",
      "Iteration 7, loss = 0.23466104\n",
      "Iteration 8, loss = 0.22145131\n",
      "Iteration 9, loss = 0.20745356\n",
      "Iteration 10, loss = 0.19520732\n",
      "Iteration 11, loss = 0.18268029\n",
      "Iteration 12, loss = 0.17428222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13, loss = 0.16479699\n",
      "Iteration 14, loss = 0.15837881\n",
      "Iteration 15, loss = 0.15076606\n",
      "Iteration 16, loss = 0.14253741\n",
      "Iteration 17, loss = 0.13841691\n",
      "Iteration 18, loss = 0.13137303\n",
      "Iteration 19, loss = 0.12578732\n",
      "Iteration 20, loss = 0.12094136\n",
      "Iteration 21, loss = 0.11290109\n",
      "Iteration 22, loss = 0.11174452\n",
      "Iteration 23, loss = 0.10381660\n",
      "Iteration 24, loss = 0.09843863\n",
      "Iteration 25, loss = 0.09951197\n",
      "Iteration 26, loss = 0.08880576\n",
      "Iteration 27, loss = 0.08864302\n",
      "Iteration 28, loss = 0.08486461\n",
      "Iteration 29, loss = 0.08159485\n",
      "Iteration 30, loss = 0.07833103\n",
      "Iteration 31, loss = 0.07723646\n",
      "Iteration 32, loss = 0.07126193\n",
      "Iteration 33, loss = 0.06576404\n",
      "Iteration 34, loss = 0.06497767\n",
      "Iteration 35, loss = 0.06284932\n",
      "Iteration 36, loss = 0.06044854\n",
      "Iteration 37, loss = 0.06307355\n",
      "Iteration 38, loss = 0.05707691\n",
      "Iteration 39, loss = 0.05391712\n",
      "Iteration 40, loss = 0.05143851\n",
      "Iteration 41, loss = 0.05761653\n",
      "Iteration 42, loss = 0.05564079\n",
      "Iteration 43, loss = 0.04660665\n",
      "Iteration 44, loss = 0.04644121\n",
      "Iteration 45, loss = 0.04383637\n",
      "Iteration 46, loss = 0.04316212\n",
      "Iteration 47, loss = 0.04387246\n",
      "Iteration 48, loss = 0.04210469\n",
      "Iteration 49, loss = 0.03608794\n",
      "Iteration 50, loss = 0.03713908\n",
      "Iteration 51, loss = 0.03464675\n",
      "Iteration 52, loss = 0.03293136\n",
      "Iteration 53, loss = 0.03319667\n",
      "Iteration 54, loss = 0.02919389\n",
      "Iteration 55, loss = 0.03011194\n",
      "Iteration 56, loss = 0.03741690\n",
      "Iteration 57, loss = 0.03535823\n",
      "Iteration 58, loss = 0.03047596\n",
      "Iteration 59, loss = 0.03191853\n",
      "Iteration 60, loss = 0.03351257\n",
      "Iteration 61, loss = 0.03082324\n",
      "Iteration 62, loss = 0.02188260\n",
      "Iteration 63, loss = 0.01905316\n",
      "Iteration 64, loss = 0.02953154\n",
      "Iteration 65, loss = 0.02176416\n",
      "Iteration 66, loss = 0.02305712\n",
      "Iteration 67, loss = 0.03338585\n",
      "Iteration 68, loss = 0.03158026\n",
      "Iteration 69, loss = 0.02276682\n",
      "Iteration 70, loss = 0.01703257\n",
      "Iteration 71, loss = 0.01993769\n",
      "Iteration 72, loss = 0.01910310\n",
      "Iteration 73, loss = 0.02327023\n",
      "Iteration 74, loss = 0.02127871\n",
      "Iteration 75, loss = 0.03243142\n",
      "Iteration 76, loss = 0.01643087\n",
      "Iteration 77, loss = 0.01356131\n",
      "Iteration 78, loss = 0.02185054\n",
      "Iteration 79, loss = 0.02397025\n",
      "Iteration 80, loss = 0.03086673\n",
      "Iteration 81, loss = 0.01969992\n",
      "Iteration 82, loss = 0.01381263\n",
      "Iteration 83, loss = 0.00861405\n",
      "Iteration 84, loss = 0.01149410\n",
      "Iteration 85, loss = 0.02098567\n",
      "Iteration 86, loss = 0.02626612\n",
      "Iteration 87, loss = 0.02513299\n",
      "Iteration 88, loss = 0.01994553\n",
      "Iteration 89, loss = 0.01990620\n",
      "Iteration 90, loss = 0.00977711\n",
      "Iteration 91, loss = 0.01148315\n",
      "Iteration 92, loss = 0.01375574\n",
      "Iteration 93, loss = 0.02233938\n",
      "Iteration 94, loss = 0.02807792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "81.2490358\n",
      "Adam - Training Size: 90%\n",
      "Iteration 1, loss = 0.50235402\n",
      "Iteration 2, loss = 0.35840513\n",
      "Iteration 3, loss = 0.31817885\n",
      "Iteration 4, loss = 0.28926359\n",
      "Iteration 5, loss = 0.26965784\n",
      "Iteration 6, loss = 0.25119473\n",
      "Iteration 7, loss = 0.23892353\n",
      "Iteration 8, loss = 0.22396580\n",
      "Iteration 9, loss = 0.21027920\n",
      "Iteration 10, loss = 0.20031197\n",
      "Iteration 11, loss = 0.19021844\n",
      "Iteration 12, loss = 0.18011417\n",
      "Iteration 13, loss = 0.17261056\n",
      "Iteration 14, loss = 0.16394520\n",
      "Iteration 15, loss = 0.15709568\n",
      "Iteration 16, loss = 0.15019940\n",
      "Iteration 17, loss = 0.14776078\n",
      "Iteration 18, loss = 0.13798862\n",
      "Iteration 19, loss = 0.13032109\n",
      "Iteration 20, loss = 0.12902811\n",
      "Iteration 21, loss = 0.12030232\n",
      "Iteration 22, loss = 0.11440847\n",
      "Iteration 23, loss = 0.11206185\n",
      "Iteration 24, loss = 0.10890695\n",
      "Iteration 25, loss = 0.10076051\n",
      "Iteration 26, loss = 0.10009919\n",
      "Iteration 27, loss = 0.09288775\n",
      "Iteration 28, loss = 0.09098030\n",
      "Iteration 29, loss = 0.08951326\n",
      "Iteration 30, loss = 0.08724380\n",
      "Iteration 31, loss = 0.08987505\n",
      "Iteration 32, loss = 0.07941020\n",
      "Iteration 33, loss = 0.07213935\n",
      "Iteration 34, loss = 0.07175746\n",
      "Iteration 35, loss = 0.06871562\n",
      "Iteration 36, loss = 0.06691242\n",
      "Iteration 37, loss = 0.06673321\n",
      "Iteration 38, loss = 0.06427730\n",
      "Iteration 39, loss = 0.05878531\n",
      "Iteration 40, loss = 0.05957619\n",
      "Iteration 41, loss = 0.05724274\n",
      "Iteration 42, loss = 0.05503859\n",
      "Iteration 43, loss = 0.05665151\n",
      "Iteration 44, loss = 0.05032130\n",
      "Iteration 45, loss = 0.05365176\n",
      "Iteration 46, loss = 0.04818448\n",
      "Iteration 47, loss = 0.05016986\n",
      "Iteration 48, loss = 0.04264827\n",
      "Iteration 49, loss = 0.04244615\n",
      "Iteration 50, loss = 0.04196638\n",
      "Iteration 51, loss = 0.04880243\n",
      "Iteration 52, loss = 0.04188250\n",
      "Iteration 53, loss = 0.03519952\n",
      "Iteration 54, loss = 0.03787216\n",
      "Iteration 55, loss = 0.04404148\n",
      "Iteration 56, loss = 0.03593835\n",
      "Iteration 57, loss = 0.03372986\n",
      "Iteration 58, loss = 0.03636285\n",
      "Iteration 59, loss = 0.03146845\n",
      "Iteration 60, loss = 0.02574659\n",
      "Iteration 61, loss = 0.03344420\n",
      "Iteration 62, loss = 0.03154371\n",
      "Iteration 63, loss = 0.03420103\n",
      "Iteration 64, loss = 0.02794451\n",
      "Iteration 65, loss = 0.03484064\n",
      "Iteration 66, loss = 0.02076091\n",
      "Iteration 67, loss = 0.02426363\n",
      "Iteration 68, loss = 0.02313906\n",
      "Iteration 69, loss = 0.02758544\n",
      "Iteration 70, loss = 0.04206816\n",
      "Iteration 71, loss = 0.02328098\n",
      "Iteration 72, loss = 0.02189776\n",
      "Iteration 73, loss = 0.02041047\n",
      "Iteration 74, loss = 0.02300793\n",
      "Iteration 75, loss = 0.03847070\n",
      "Iteration 76, loss = 0.02332730\n",
      "Iteration 77, loss = 0.01410964\n",
      "Iteration 78, loss = 0.01783418\n",
      "Iteration 79, loss = 0.02001658\n",
      "Iteration 80, loss = 0.02141495\n",
      "Iteration 81, loss = 0.02148282\n",
      "Iteration 82, loss = 0.02409895\n",
      "Iteration 83, loss = 0.01447872\n",
      "Iteration 84, loss = 0.01537080\n",
      "Iteration 85, loss = 0.02474729\n",
      "Iteration 86, loss = 0.02303409\n",
      "Iteration 87, loss = 0.03093691\n",
      "Iteration 88, loss = 0.02220499\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "92.62612910000001\n",
      "Adam - Training Size: 100%\n",
      "Iteration 1, loss = 0.48649006\n",
      "Iteration 2, loss = 0.35030134\n",
      "Iteration 3, loss = 0.31068229\n",
      "Iteration 4, loss = 0.28158248\n",
      "Iteration 5, loss = 0.25965031\n",
      "Iteration 6, loss = 0.24703365\n",
      "Iteration 7, loss = 0.23360759\n",
      "Iteration 8, loss = 0.21992549\n",
      "Iteration 9, loss = 0.20593903\n",
      "Iteration 10, loss = 0.19422038\n",
      "Iteration 11, loss = 0.18675417\n",
      "Iteration 12, loss = 0.17692519\n",
      "Iteration 13, loss = 0.17122170\n",
      "Iteration 14, loss = 0.16146808\n",
      "Iteration 15, loss = 0.15358976\n",
      "Iteration 16, loss = 0.14771838\n",
      "Iteration 17, loss = 0.14171903\n",
      "Iteration 18, loss = 0.13564501\n",
      "Iteration 19, loss = 0.12888890\n",
      "Iteration 20, loss = 0.12686521\n",
      "Iteration 21, loss = 0.12065561\n",
      "Iteration 22, loss = 0.11485173\n",
      "Iteration 23, loss = 0.11058807\n",
      "Iteration 24, loss = 0.10575962\n",
      "Iteration 25, loss = 0.10320392\n",
      "Iteration 26, loss = 0.09904898\n",
      "Iteration 27, loss = 0.09492326\n",
      "Iteration 28, loss = 0.08971461\n",
      "Iteration 29, loss = 0.08532355\n",
      "Iteration 30, loss = 0.08550420\n",
      "Iteration 31, loss = 0.08453197\n",
      "Iteration 32, loss = 0.07952056\n",
      "Iteration 33, loss = 0.07571989\n",
      "Iteration 34, loss = 0.07061598\n",
      "Iteration 35, loss = 0.06824831\n",
      "Iteration 36, loss = 0.07110679\n",
      "Iteration 37, loss = 0.06665176\n",
      "Iteration 38, loss = 0.06066912\n",
      "Iteration 39, loss = 0.06113568\n",
      "Iteration 40, loss = 0.06155986\n",
      "Iteration 41, loss = 0.05968104\n",
      "Iteration 42, loss = 0.05643360\n",
      "Iteration 43, loss = 0.05556866\n",
      "Iteration 44, loss = 0.05103171\n",
      "Iteration 45, loss = 0.05341066\n",
      "Iteration 46, loss = 0.05199848\n",
      "Iteration 47, loss = 0.05054374\n",
      "Iteration 48, loss = 0.04438503\n",
      "Iteration 49, loss = 0.04631338\n",
      "Iteration 50, loss = 0.04329220\n",
      "Iteration 51, loss = 0.04161478\n",
      "Iteration 52, loss = 0.04081735\n",
      "Iteration 53, loss = 0.04590953\n",
      "Iteration 54, loss = 0.03811598\n",
      "Iteration 55, loss = 0.03810035\n",
      "Iteration 56, loss = 0.03431190\n",
      "Iteration 57, loss = 0.03667156\n",
      "Iteration 58, loss = 0.03816518\n",
      "Iteration 59, loss = 0.04385389\n",
      "Iteration 60, loss = 0.03903718\n",
      "Iteration 61, loss = 0.03180861\n",
      "Iteration 62, loss = 0.02817813\n",
      "Iteration 63, loss = 0.02788537\n",
      "Iteration 64, loss = 0.02822781\n",
      "Iteration 65, loss = 0.02481576\n",
      "Iteration 66, loss = 0.03238966\n",
      "Iteration 67, loss = 0.03598520\n",
      "Iteration 68, loss = 0.03002874\n",
      "Iteration 69, loss = 0.02416034\n",
      "Iteration 70, loss = 0.02383609\n",
      "Iteration 71, loss = 0.03430356\n",
      "Iteration 72, loss = 0.02590727\n",
      "Iteration 73, loss = 0.02875552\n",
      "Iteration 74, loss = 0.02601185\n",
      "Iteration 75, loss = 0.02706262\n",
      "Iteration 76, loss = 0.01814132\n",
      "Iteration 77, loss = 0.01955101\n",
      "Iteration 78, loss = 0.01959217\n",
      "Iteration 79, loss = 0.02485627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80, loss = 0.02217085\n",
      "Iteration 81, loss = 0.02859035\n",
      "Iteration 82, loss = 0.02851969\n",
      "Iteration 83, loss = 0.02436647\n",
      "Iteration 84, loss = 0.01590702\n",
      "Iteration 85, loss = 0.01577841\n",
      "Iteration 86, loss = 0.03625283\n",
      "Iteration 87, loss = 0.01741290\n",
      "Iteration 88, loss = 0.01751305\n",
      "Iteration 89, loss = 0.02408626\n",
      "Iteration 90, loss = 0.02250823\n",
      "Iteration 91, loss = 0.01435873\n",
      "Iteration 92, loss = 0.01121374\n",
      "Iteration 93, loss = 0.02481741\n",
      "Iteration 94, loss = 0.03894030\n",
      "Iteration 95, loss = 0.02132095\n",
      "Iteration 96, loss = 0.01072225\n",
      "Iteration 97, loss = 0.01061850\n",
      "Iteration 98, loss = 0.01878637\n",
      "Iteration 99, loss = 0.01593145\n",
      "Iteration 100, loss = 0.01493650\n",
      "Iteration 101, loss = 0.01830564\n",
      "Iteration 102, loss = 0.02918356\n",
      "Iteration 103, loss = 0.02185051\n",
      "Iteration 104, loss = 0.01519306\n",
      "Iteration 105, loss = 0.01512075\n",
      "Iteration 106, loss = 0.01579887\n",
      "Iteration 107, loss = 0.01846119\n",
      "Iteration 108, loss = 0.01456082\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "135.9369544000001\n",
      "SGD - Training Size: 10%\n",
      "Iteration 1, loss = 1.83505120\n",
      "Iteration 2, loss = 1.01759354\n",
      "Iteration 3, loss = 0.82257517\n",
      "Iteration 4, loss = 0.73360975\n",
      "Iteration 5, loss = 0.67750158\n",
      "Iteration 6, loss = 0.63835485\n",
      "Iteration 7, loss = 0.60698933\n",
      "Iteration 8, loss = 0.58200797\n",
      "Iteration 9, loss = 0.56113999\n",
      "Iteration 10, loss = 0.54311338\n",
      "Iteration 11, loss = 0.52759693\n",
      "Iteration 12, loss = 0.51387592\n",
      "Iteration 13, loss = 0.50126165\n",
      "Iteration 14, loss = 0.48995610\n",
      "Iteration 15, loss = 0.47988612\n",
      "Iteration 16, loss = 0.47016336\n",
      "Iteration 17, loss = 0.46165816\n",
      "Iteration 18, loss = 0.45377282\n",
      "Iteration 19, loss = 0.44589217\n",
      "Iteration 20, loss = 0.43894209\n",
      "Iteration 21, loss = 0.43248217\n",
      "Iteration 22, loss = 0.42607534\n",
      "Iteration 23, loss = 0.41973589\n",
      "Iteration 24, loss = 0.41440729\n",
      "Iteration 25, loss = 0.40907007\n",
      "Iteration 26, loss = 0.40380687\n",
      "Iteration 27, loss = 0.39902325\n",
      "Iteration 28, loss = 0.39416304\n",
      "Iteration 29, loss = 0.38982993\n",
      "Iteration 30, loss = 0.38540035\n",
      "Iteration 31, loss = 0.38098448\n",
      "Iteration 32, loss = 0.37722042\n",
      "Iteration 33, loss = 0.37292785\n",
      "Iteration 34, loss = 0.36946454\n",
      "Iteration 35, loss = 0.36567628\n",
      "Iteration 36, loss = 0.36210636\n",
      "Iteration 37, loss = 0.35866738\n",
      "Iteration 38, loss = 0.35523965\n",
      "Iteration 39, loss = 0.35203215\n",
      "Iteration 40, loss = 0.34874969\n",
      "Iteration 41, loss = 0.34581346\n",
      "Iteration 42, loss = 0.34264797\n",
      "Iteration 43, loss = 0.33985158\n",
      "Iteration 44, loss = 0.33703852\n",
      "Iteration 45, loss = 0.33371412\n",
      "Iteration 46, loss = 0.33134282\n",
      "Iteration 47, loss = 0.32864134\n",
      "Iteration 48, loss = 0.32590881\n",
      "Iteration 49, loss = 0.32333810\n",
      "Iteration 50, loss = 0.32118684\n",
      "Iteration 51, loss = 0.31864511\n",
      "Iteration 52, loss = 0.31600655\n",
      "Iteration 53, loss = 0.31373146\n",
      "Iteration 54, loss = 0.31131283\n",
      "Iteration 55, loss = 0.30892113\n",
      "Iteration 56, loss = 0.30669546\n",
      "Iteration 57, loss = 0.30451847\n",
      "Iteration 58, loss = 0.30230365\n",
      "Iteration 59, loss = 0.30024091\n",
      "Iteration 60, loss = 0.29825724\n",
      "Iteration 61, loss = 0.29603788\n",
      "Iteration 62, loss = 0.29430809\n",
      "Iteration 63, loss = 0.29192337\n",
      "Iteration 64, loss = 0.29020102\n",
      "Iteration 65, loss = 0.28791142\n",
      "Iteration 66, loss = 0.28590027\n",
      "Iteration 67, loss = 0.28409768\n",
      "Iteration 68, loss = 0.28209675\n",
      "Iteration 69, loss = 0.28026018\n",
      "Iteration 70, loss = 0.27843933\n",
      "Iteration 71, loss = 0.27676353\n",
      "Iteration 72, loss = 0.27506406\n",
      "Iteration 73, loss = 0.27312564\n",
      "Iteration 74, loss = 0.27140871\n",
      "Iteration 75, loss = 0.26957329\n",
      "Iteration 76, loss = 0.26807773\n",
      "Iteration 77, loss = 0.26639554\n",
      "Iteration 78, loss = 0.26467268\n",
      "Iteration 79, loss = 0.26303474\n",
      "Iteration 80, loss = 0.26141839\n",
      "Iteration 81, loss = 0.25969657\n",
      "Iteration 82, loss = 0.25814938\n",
      "Iteration 83, loss = 0.25650641\n",
      "Iteration 84, loss = 0.25515670\n",
      "Iteration 85, loss = 0.25341033\n",
      "Iteration 86, loss = 0.25209012\n",
      "Iteration 87, loss = 0.25062543\n",
      "Iteration 88, loss = 0.24903008\n",
      "Iteration 89, loss = 0.24743977\n",
      "Iteration 90, loss = 0.24594806\n",
      "Iteration 91, loss = 0.24455241\n",
      "Iteration 92, loss = 0.24328778\n",
      "Iteration 93, loss = 0.24198268\n",
      "Iteration 94, loss = 0.24029044\n",
      "Iteration 95, loss = 0.23918690\n",
      "Iteration 96, loss = 0.23770594\n",
      "Iteration 97, loss = 0.23634974\n",
      "Iteration 98, loss = 0.23495016\n",
      "Iteration 99, loss = 0.23338837\n",
      "Iteration 100, loss = 0.23235971\n",
      "Iteration 101, loss = 0.23116764\n",
      "Iteration 102, loss = 0.22981449\n",
      "Iteration 103, loss = 0.22838482\n",
      "Iteration 104, loss = 0.22708174\n",
      "Iteration 105, loss = 0.22593783\n",
      "Iteration 106, loss = 0.22452416\n",
      "Iteration 107, loss = 0.22332909\n",
      "Iteration 108, loss = 0.22212878\n",
      "Iteration 109, loss = 0.22069873\n",
      "Iteration 110, loss = 0.21946937\n",
      "Iteration 111, loss = 0.21846443\n",
      "Iteration 112, loss = 0.21721536\n",
      "Iteration 113, loss = 0.21583233\n",
      "Iteration 114, loss = 0.21503354\n",
      "Iteration 115, loss = 0.21377159\n",
      "Iteration 116, loss = 0.21240909\n",
      "Iteration 117, loss = 0.21138896\n",
      "Iteration 118, loss = 0.21032580\n",
      "Iteration 119, loss = 0.20887117\n",
      "Iteration 120, loss = 0.20786335\n",
      "Iteration 121, loss = 0.20676231\n",
      "Iteration 122, loss = 0.20575002\n",
      "Iteration 123, loss = 0.20471044\n",
      "Iteration 124, loss = 0.20338857\n",
      "Iteration 125, loss = 0.20261723\n",
      "Iteration 126, loss = 0.20162568\n",
      "Iteration 127, loss = 0.20039966\n",
      "Iteration 128, loss = 0.19934523\n",
      "Iteration 129, loss = 0.19803409\n",
      "Iteration 130, loss = 0.19729471\n",
      "Iteration 131, loss = 0.19604801\n",
      "Iteration 132, loss = 0.19494202\n",
      "Iteration 133, loss = 0.19394250\n",
      "Iteration 134, loss = 0.19291153\n",
      "Iteration 135, loss = 0.19184956\n",
      "Iteration 136, loss = 0.19097629\n",
      "Iteration 137, loss = 0.19007953\n",
      "Iteration 138, loss = 0.18918400\n",
      "Iteration 139, loss = 0.18795665\n",
      "Iteration 140, loss = 0.18697073\n",
      "Iteration 141, loss = 0.18608621\n",
      "Iteration 142, loss = 0.18517985\n",
      "Iteration 143, loss = 0.18427185\n",
      "Iteration 144, loss = 0.18324897\n",
      "Iteration 145, loss = 0.18241916\n",
      "Iteration 146, loss = 0.18135682\n",
      "Iteration 147, loss = 0.18050138\n",
      "Iteration 148, loss = 0.17965274\n",
      "Iteration 149, loss = 0.17854870\n",
      "Iteration 150, loss = 0.17771665\n",
      "Iteration 151, loss = 0.17751502\n",
      "Iteration 152, loss = 0.17591569\n",
      "Iteration 153, loss = 0.17500080\n",
      "Iteration 154, loss = 0.17419637\n",
      "Iteration 155, loss = 0.17333521\n",
      "Iteration 156, loss = 0.17265811\n",
      "Iteration 157, loss = 0.17147070\n",
      "Iteration 158, loss = 0.17087768\n",
      "Iteration 159, loss = 0.16999516\n",
      "Iteration 160, loss = 0.16916989\n",
      "Iteration 161, loss = 0.16830256\n",
      "Iteration 162, loss = 0.16751646\n",
      "Iteration 163, loss = 0.16676206\n",
      "Iteration 164, loss = 0.16568716\n",
      "Iteration 165, loss = 0.16501062\n",
      "Iteration 166, loss = 0.16407280\n",
      "Iteration 167, loss = 0.16331241\n",
      "Iteration 168, loss = 0.16248566\n",
      "Iteration 169, loss = 0.16156807\n",
      "Iteration 170, loss = 0.16086664\n",
      "Iteration 171, loss = 0.16020420\n",
      "Iteration 172, loss = 0.15932329\n",
      "Iteration 173, loss = 0.15851957\n",
      "Iteration 174, loss = 0.15785505\n",
      "Iteration 175, loss = 0.15703061\n",
      "Iteration 176, loss = 0.15648537\n",
      "Iteration 177, loss = 0.15526554\n",
      "Iteration 178, loss = 0.15479529\n",
      "Iteration 179, loss = 0.15402465\n",
      "Iteration 180, loss = 0.15321245\n",
      "Iteration 181, loss = 0.15264882\n",
      "Iteration 182, loss = 0.15175696\n",
      "Iteration 183, loss = 0.15117172\n",
      "Iteration 184, loss = 0.15023920\n",
      "Iteration 185, loss = 0.14955157\n",
      "Iteration 186, loss = 0.14894642\n",
      "Iteration 187, loss = 0.14816226\n",
      "Iteration 188, loss = 0.14771554\n",
      "Iteration 189, loss = 0.14658708\n",
      "Iteration 190, loss = 0.14602388\n",
      "Iteration 191, loss = 0.14536743\n",
      "Iteration 192, loss = 0.14455401\n",
      "Iteration 193, loss = 0.14393571\n",
      "Iteration 194, loss = 0.14317652\n",
      "Iteration 195, loss = 0.14255130\n",
      "Iteration 196, loss = 0.14185925\n",
      "Iteration 197, loss = 0.14123010\n",
      "Iteration 198, loss = 0.14043184\n",
      "Iteration 199, loss = 0.14004752\n",
      "Iteration 200, loss = 0.13959487\n",
      "22.18000100000006\n",
      "SGD - Training Size: 20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.51618560\n",
      "Iteration 2, loss = 0.78107557\n",
      "Iteration 3, loss = 0.67026628\n",
      "Iteration 4, loss = 0.61189531\n",
      "Iteration 5, loss = 0.57253683\n",
      "Iteration 6, loss = 0.54400724\n",
      "Iteration 7, loss = 0.52128601\n",
      "Iteration 8, loss = 0.50323337\n",
      "Iteration 9, loss = 0.48799547\n",
      "Iteration 10, loss = 0.47503815\n",
      "Iteration 11, loss = 0.46371545\n",
      "Iteration 12, loss = 0.45327803\n",
      "Iteration 13, loss = 0.44405783\n",
      "Iteration 14, loss = 0.43547132\n",
      "Iteration 15, loss = 0.42795314\n",
      "Iteration 16, loss = 0.42069304\n",
      "Iteration 17, loss = 0.41438335\n",
      "Iteration 18, loss = 0.40836348\n",
      "Iteration 19, loss = 0.40264252\n",
      "Iteration 20, loss = 0.39682028\n",
      "Iteration 21, loss = 0.39153936\n",
      "Iteration 22, loss = 0.38686076\n",
      "Iteration 23, loss = 0.38222250\n",
      "Iteration 24, loss = 0.37791201\n",
      "Iteration 25, loss = 0.37367934\n",
      "Iteration 26, loss = 0.36887569\n",
      "Iteration 27, loss = 0.36513449\n",
      "Iteration 28, loss = 0.36197251\n",
      "Iteration 29, loss = 0.35800513\n",
      "Iteration 30, loss = 0.35453923\n",
      "Iteration 31, loss = 0.35089954\n",
      "Iteration 32, loss = 0.34793884\n",
      "Iteration 33, loss = 0.34438557\n",
      "Iteration 34, loss = 0.34192155\n",
      "Iteration 35, loss = 0.33843167\n",
      "Iteration 36, loss = 0.33556797\n",
      "Iteration 37, loss = 0.33296600\n",
      "Iteration 38, loss = 0.32995010\n",
      "Iteration 39, loss = 0.32689884\n",
      "Iteration 40, loss = 0.32492681\n",
      "Iteration 41, loss = 0.32229676\n",
      "Iteration 42, loss = 0.31968671\n",
      "Iteration 43, loss = 0.31716625\n",
      "Iteration 44, loss = 0.31485986\n",
      "Iteration 45, loss = 0.31269965\n",
      "Iteration 46, loss = 0.31021412\n",
      "Iteration 47, loss = 0.30817959\n",
      "Iteration 48, loss = 0.30584024\n",
      "Iteration 49, loss = 0.30366213\n",
      "Iteration 50, loss = 0.30144569\n",
      "Iteration 51, loss = 0.29959692\n",
      "Iteration 52, loss = 0.29757598\n",
      "Iteration 53, loss = 0.29557898\n",
      "Iteration 54, loss = 0.29376309\n",
      "Iteration 55, loss = 0.29135024\n",
      "Iteration 56, loss = 0.28956165\n",
      "Iteration 57, loss = 0.28760934\n",
      "Iteration 58, loss = 0.28592657\n",
      "Iteration 59, loss = 0.28393875\n",
      "Iteration 60, loss = 0.28203124\n",
      "Iteration 61, loss = 0.28011668\n",
      "Iteration 62, loss = 0.27865174\n",
      "Iteration 63, loss = 0.27673160\n",
      "Iteration 64, loss = 0.27505319\n",
      "Iteration 65, loss = 0.27344299\n",
      "Iteration 66, loss = 0.27187893\n",
      "Iteration 67, loss = 0.27011729\n",
      "Iteration 68, loss = 0.26824941\n",
      "Iteration 69, loss = 0.26678632\n",
      "Iteration 70, loss = 0.26528294\n",
      "Iteration 71, loss = 0.26362905\n",
      "Iteration 72, loss = 0.26203819\n",
      "Iteration 73, loss = 0.26029151\n",
      "Iteration 74, loss = 0.25920181\n",
      "Iteration 75, loss = 0.25785627\n",
      "Iteration 76, loss = 0.25604928\n",
      "Iteration 77, loss = 0.25457336\n",
      "Iteration 78, loss = 0.25308210\n",
      "Iteration 79, loss = 0.25159312\n",
      "Iteration 80, loss = 0.25010186\n",
      "Iteration 81, loss = 0.24884608\n",
      "Iteration 82, loss = 0.24757202\n",
      "Iteration 83, loss = 0.24591006\n",
      "Iteration 84, loss = 0.24473024\n",
      "Iteration 85, loss = 0.24292832\n",
      "Iteration 86, loss = 0.24218835\n",
      "Iteration 87, loss = 0.24086096\n",
      "Iteration 88, loss = 0.23945123\n",
      "Iteration 89, loss = 0.23793380\n",
      "Iteration 90, loss = 0.23705811\n",
      "Iteration 91, loss = 0.23556125\n",
      "Iteration 92, loss = 0.23429532\n",
      "Iteration 93, loss = 0.23326565\n",
      "Iteration 94, loss = 0.23191650\n",
      "Iteration 95, loss = 0.23056487\n",
      "Iteration 96, loss = 0.22920221\n",
      "Iteration 97, loss = 0.22801207\n",
      "Iteration 98, loss = 0.22666760\n",
      "Iteration 99, loss = 0.22573304\n",
      "Iteration 100, loss = 0.22446968\n",
      "Iteration 101, loss = 0.22328523\n",
      "Iteration 102, loss = 0.22220926\n",
      "Iteration 103, loss = 0.22103534\n",
      "Iteration 104, loss = 0.21990588\n",
      "Iteration 105, loss = 0.21874213\n",
      "Iteration 106, loss = 0.21748795\n",
      "Iteration 107, loss = 0.21632706\n",
      "Iteration 108, loss = 0.21515496\n",
      "Iteration 109, loss = 0.21413505\n",
      "Iteration 110, loss = 0.21286378\n",
      "Iteration 111, loss = 0.21205098\n",
      "Iteration 112, loss = 0.21079798\n",
      "Iteration 113, loss = 0.21015518\n",
      "Iteration 114, loss = 0.20904169\n",
      "Iteration 115, loss = 0.20760237\n",
      "Iteration 116, loss = 0.20660740\n",
      "Iteration 117, loss = 0.20579063\n",
      "Iteration 118, loss = 0.20448829\n",
      "Iteration 119, loss = 0.20332447\n",
      "Iteration 120, loss = 0.20225579\n",
      "Iteration 121, loss = 0.20132998\n",
      "Iteration 122, loss = 0.20066656\n",
      "Iteration 123, loss = 0.19943835\n",
      "Iteration 124, loss = 0.19857130\n",
      "Iteration 125, loss = 0.19751156\n",
      "Iteration 126, loss = 0.19671481\n",
      "Iteration 127, loss = 0.19553043\n",
      "Iteration 128, loss = 0.19442426\n",
      "Iteration 129, loss = 0.19383310\n",
      "Iteration 130, loss = 0.19283781\n",
      "Iteration 131, loss = 0.19175848\n",
      "Iteration 132, loss = 0.19076157\n",
      "Iteration 133, loss = 0.19029724\n",
      "Iteration 134, loss = 0.18895912\n",
      "Iteration 135, loss = 0.18779252\n",
      "Iteration 136, loss = 0.18696740\n",
      "Iteration 137, loss = 0.18629605\n",
      "Iteration 138, loss = 0.18542880\n",
      "Iteration 139, loss = 0.18435107\n",
      "Iteration 140, loss = 0.18367840\n",
      "Iteration 141, loss = 0.18278498\n",
      "Iteration 142, loss = 0.18194678\n",
      "Iteration 143, loss = 0.18078233\n",
      "Iteration 144, loss = 0.18010691\n",
      "Iteration 145, loss = 0.17908080\n",
      "Iteration 146, loss = 0.17841533\n",
      "Iteration 147, loss = 0.17756756\n",
      "Iteration 148, loss = 0.17657494\n",
      "Iteration 149, loss = 0.17574065\n",
      "Iteration 150, loss = 0.17493108\n",
      "Iteration 151, loss = 0.17420679\n",
      "Iteration 152, loss = 0.17336657\n",
      "Iteration 153, loss = 0.17241712\n",
      "Iteration 154, loss = 0.17165568\n",
      "Iteration 155, loss = 0.17111448\n",
      "Iteration 156, loss = 0.17018204\n",
      "Iteration 157, loss = 0.16934656\n",
      "Iteration 158, loss = 0.16870733\n",
      "Iteration 159, loss = 0.16785751\n",
      "Iteration 160, loss = 0.16687097\n",
      "Iteration 161, loss = 0.16611362\n",
      "Iteration 162, loss = 0.16522734\n",
      "Iteration 163, loss = 0.16470165\n",
      "Iteration 164, loss = 0.16370885\n",
      "Iteration 165, loss = 0.16299456\n",
      "Iteration 166, loss = 0.16224399\n",
      "Iteration 167, loss = 0.16162537\n",
      "Iteration 168, loss = 0.16054053\n",
      "Iteration 169, loss = 0.16028691\n",
      "Iteration 170, loss = 0.15930901\n",
      "Iteration 171, loss = 0.15848759\n",
      "Iteration 172, loss = 0.15782295\n",
      "Iteration 173, loss = 0.15706289\n",
      "Iteration 174, loss = 0.15628063\n",
      "Iteration 175, loss = 0.15589084\n",
      "Iteration 176, loss = 0.15498289\n",
      "Iteration 177, loss = 0.15435892\n",
      "Iteration 178, loss = 0.15348795\n",
      "Iteration 179, loss = 0.15266967\n",
      "Iteration 180, loss = 0.15228197\n",
      "Iteration 181, loss = 0.15138644\n",
      "Iteration 182, loss = 0.15066751\n",
      "Iteration 183, loss = 0.15017348\n",
      "Iteration 184, loss = 0.14939200\n",
      "Iteration 185, loss = 0.14894739\n",
      "Iteration 186, loss = 0.14813780\n",
      "Iteration 187, loss = 0.14739720\n",
      "Iteration 188, loss = 0.14658496\n",
      "Iteration 189, loss = 0.14592384\n",
      "Iteration 190, loss = 0.14538147\n",
      "Iteration 191, loss = 0.14473466\n",
      "Iteration 192, loss = 0.14408435\n",
      "Iteration 193, loss = 0.14343487\n",
      "Iteration 194, loss = 0.14280211\n",
      "Iteration 195, loss = 0.14249638\n",
      "Iteration 196, loss = 0.14128469\n",
      "Iteration 197, loss = 0.14088482\n",
      "Iteration 198, loss = 0.13996592\n",
      "Iteration 199, loss = 0.13937187\n",
      "Iteration 200, loss = 0.13886347\n",
      "47.85749769999995\n",
      "SGD - Training Size: 30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.26847252\n",
      "Iteration 2, loss = 0.70167071\n",
      "Iteration 3, loss = 0.60743089\n",
      "Iteration 4, loss = 0.55669794\n",
      "Iteration 5, loss = 0.52276412\n",
      "Iteration 6, loss = 0.49788445\n",
      "Iteration 7, loss = 0.47889165\n",
      "Iteration 8, loss = 0.46359685\n",
      "Iteration 9, loss = 0.45041942\n",
      "Iteration 10, loss = 0.43932391\n",
      "Iteration 11, loss = 0.42978767\n",
      "Iteration 12, loss = 0.42130466\n",
      "Iteration 13, loss = 0.41344452\n",
      "Iteration 14, loss = 0.40635348\n",
      "Iteration 15, loss = 0.40029661\n",
      "Iteration 16, loss = 0.39420544\n",
      "Iteration 17, loss = 0.38879984\n",
      "Iteration 18, loss = 0.38327570\n",
      "Iteration 19, loss = 0.37857871\n",
      "Iteration 20, loss = 0.37391163\n",
      "Iteration 21, loss = 0.36988210\n",
      "Iteration 22, loss = 0.36587222\n",
      "Iteration 23, loss = 0.36172370\n",
      "Iteration 24, loss = 0.35796563\n",
      "Iteration 25, loss = 0.35419159\n",
      "Iteration 26, loss = 0.35089813\n",
      "Iteration 27, loss = 0.34748074\n",
      "Iteration 28, loss = 0.34450875\n",
      "Iteration 29, loss = 0.34123874\n",
      "Iteration 30, loss = 0.33872519\n",
      "Iteration 31, loss = 0.33539358\n",
      "Iteration 32, loss = 0.33251074\n",
      "Iteration 33, loss = 0.32981794\n",
      "Iteration 34, loss = 0.32731677\n",
      "Iteration 35, loss = 0.32468353\n",
      "Iteration 36, loss = 0.32238288\n",
      "Iteration 37, loss = 0.31953915\n",
      "Iteration 38, loss = 0.31743052\n",
      "Iteration 39, loss = 0.31483412\n",
      "Iteration 40, loss = 0.31259636\n",
      "Iteration 41, loss = 0.31047891\n",
      "Iteration 42, loss = 0.30820943\n",
      "Iteration 43, loss = 0.30635183\n",
      "Iteration 44, loss = 0.30398701\n",
      "Iteration 45, loss = 0.30188064\n",
      "Iteration 46, loss = 0.29998016\n",
      "Iteration 47, loss = 0.29774869\n",
      "Iteration 48, loss = 0.29576063\n",
      "Iteration 49, loss = 0.29398343\n",
      "Iteration 50, loss = 0.29208012\n",
      "Iteration 51, loss = 0.29031753\n",
      "Iteration 52, loss = 0.28880506\n",
      "Iteration 53, loss = 0.28654582\n",
      "Iteration 54, loss = 0.28480963\n",
      "Iteration 55, loss = 0.28298093\n",
      "Iteration 56, loss = 0.28115547\n",
      "Iteration 57, loss = 0.27962852\n",
      "Iteration 58, loss = 0.27778836\n",
      "Iteration 59, loss = 0.27638284\n",
      "Iteration 60, loss = 0.27493010\n",
      "Iteration 61, loss = 0.27339610\n",
      "Iteration 62, loss = 0.27130105\n",
      "Iteration 63, loss = 0.27001484\n",
      "Iteration 64, loss = 0.26824101\n",
      "Iteration 65, loss = 0.26678492\n",
      "Iteration 66, loss = 0.26527545\n",
      "Iteration 67, loss = 0.26374317\n",
      "Iteration 68, loss = 0.26241058\n",
      "Iteration 69, loss = 0.26076870\n",
      "Iteration 70, loss = 0.25925359\n",
      "Iteration 71, loss = 0.25784915\n",
      "Iteration 72, loss = 0.25644648\n",
      "Iteration 73, loss = 0.25515633\n",
      "Iteration 74, loss = 0.25385065\n",
      "Iteration 75, loss = 0.25235860\n",
      "Iteration 76, loss = 0.25098362\n",
      "Iteration 77, loss = 0.24938174\n",
      "Iteration 78, loss = 0.24808854\n",
      "Iteration 79, loss = 0.24694539\n",
      "Iteration 80, loss = 0.24544352\n",
      "Iteration 81, loss = 0.24407685\n",
      "Iteration 82, loss = 0.24278348\n",
      "Iteration 83, loss = 0.24147920\n",
      "Iteration 84, loss = 0.24026260\n",
      "Iteration 85, loss = 0.23904856\n",
      "Iteration 86, loss = 0.23770585\n",
      "Iteration 87, loss = 0.23648121\n",
      "Iteration 88, loss = 0.23527480\n",
      "Iteration 89, loss = 0.23393199\n",
      "Iteration 90, loss = 0.23280137\n",
      "Iteration 91, loss = 0.23161184\n",
      "Iteration 92, loss = 0.23053900\n",
      "Iteration 93, loss = 0.22933593\n",
      "Iteration 94, loss = 0.22791508\n",
      "Iteration 95, loss = 0.22709781\n",
      "Iteration 96, loss = 0.22545690\n",
      "Iteration 97, loss = 0.22468126\n",
      "Iteration 98, loss = 0.22344982\n",
      "Iteration 99, loss = 0.22241858\n",
      "Iteration 100, loss = 0.22121382\n",
      "Iteration 101, loss = 0.22022630\n",
      "Iteration 102, loss = 0.21897885\n",
      "Iteration 103, loss = 0.21769302\n",
      "Iteration 104, loss = 0.21677721\n",
      "Iteration 105, loss = 0.21573055\n",
      "Iteration 106, loss = 0.21470529\n",
      "Iteration 107, loss = 0.21352400\n",
      "Iteration 108, loss = 0.21227107\n",
      "Iteration 109, loss = 0.21169135\n",
      "Iteration 110, loss = 0.21031492\n",
      "Iteration 111, loss = 0.20912912\n",
      "Iteration 112, loss = 0.20829586\n",
      "Iteration 113, loss = 0.20717518\n",
      "Iteration 114, loss = 0.20655531\n",
      "Iteration 115, loss = 0.20540834\n",
      "Iteration 116, loss = 0.20432536\n",
      "Iteration 117, loss = 0.20328173\n",
      "Iteration 118, loss = 0.20237507\n",
      "Iteration 119, loss = 0.20122884\n",
      "Iteration 120, loss = 0.20031090\n",
      "Iteration 121, loss = 0.19953596\n",
      "Iteration 122, loss = 0.19837362\n",
      "Iteration 123, loss = 0.19763330\n",
      "Iteration 124, loss = 0.19680880\n",
      "Iteration 125, loss = 0.19562431\n",
      "Iteration 126, loss = 0.19451283\n",
      "Iteration 127, loss = 0.19380252\n",
      "Iteration 128, loss = 0.19292769\n",
      "Iteration 129, loss = 0.19171828\n",
      "Iteration 130, loss = 0.19099692\n",
      "Iteration 131, loss = 0.19008484\n",
      "Iteration 132, loss = 0.18914960\n",
      "Iteration 133, loss = 0.18830656\n",
      "Iteration 134, loss = 0.18712341\n",
      "Iteration 135, loss = 0.18641303\n",
      "Iteration 136, loss = 0.18577147\n",
      "Iteration 137, loss = 0.18482967\n",
      "Iteration 138, loss = 0.18407362\n",
      "Iteration 139, loss = 0.18300634\n",
      "Iteration 140, loss = 0.18193277\n",
      "Iteration 141, loss = 0.18117434\n",
      "Iteration 142, loss = 0.18008736\n",
      "Iteration 143, loss = 0.17940839\n",
      "Iteration 144, loss = 0.17896600\n",
      "Iteration 145, loss = 0.17767750\n",
      "Iteration 146, loss = 0.17706482\n",
      "Iteration 147, loss = 0.17625359\n",
      "Iteration 148, loss = 0.17503540\n",
      "Iteration 149, loss = 0.17452232\n",
      "Iteration 150, loss = 0.17356164\n",
      "Iteration 151, loss = 0.17260523\n",
      "Iteration 152, loss = 0.17209458\n",
      "Iteration 153, loss = 0.17105121\n",
      "Iteration 154, loss = 0.17038800\n",
      "Iteration 155, loss = 0.16960934\n",
      "Iteration 156, loss = 0.16869076\n",
      "Iteration 157, loss = 0.16792091\n",
      "Iteration 158, loss = 0.16723282\n",
      "Iteration 159, loss = 0.16637545\n",
      "Iteration 160, loss = 0.16558858\n",
      "Iteration 161, loss = 0.16498493\n",
      "Iteration 162, loss = 0.16401948\n",
      "Iteration 163, loss = 0.16325165\n",
      "Iteration 164, loss = 0.16254375\n",
      "Iteration 165, loss = 0.16239517\n",
      "Iteration 166, loss = 0.16124319\n",
      "Iteration 167, loss = 0.16015472\n",
      "Iteration 168, loss = 0.15964632\n",
      "Iteration 169, loss = 0.15887424\n",
      "Iteration 170, loss = 0.15808797\n",
      "Iteration 171, loss = 0.15752354\n",
      "Iteration 172, loss = 0.15687314\n",
      "Iteration 173, loss = 0.15625167\n",
      "Iteration 174, loss = 0.15523671\n",
      "Iteration 175, loss = 0.15438675\n",
      "Iteration 176, loss = 0.15351796\n",
      "Iteration 177, loss = 0.15321817\n",
      "Iteration 178, loss = 0.15227790\n",
      "Iteration 179, loss = 0.15170037\n",
      "Iteration 180, loss = 0.15061712\n",
      "Iteration 181, loss = 0.15027726\n",
      "Iteration 182, loss = 0.14941014\n",
      "Iteration 183, loss = 0.14887628\n",
      "Iteration 184, loss = 0.14874533\n",
      "Iteration 185, loss = 0.14756312\n",
      "Iteration 186, loss = 0.14697485\n",
      "Iteration 187, loss = 0.14592393\n",
      "Iteration 188, loss = 0.14550009\n",
      "Iteration 189, loss = 0.14497994\n",
      "Iteration 190, loss = 0.14446238\n",
      "Iteration 191, loss = 0.14371634\n",
      "Iteration 192, loss = 0.14287640\n",
      "Iteration 193, loss = 0.14253213\n",
      "Iteration 194, loss = 0.14173121\n",
      "Iteration 195, loss = 0.14098361\n",
      "Iteration 196, loss = 0.14005304\n",
      "Iteration 197, loss = 0.13973797\n",
      "Iteration 198, loss = 0.13899420\n",
      "Iteration 199, loss = 0.13854730\n",
      "Iteration 200, loss = 0.13778474\n",
      "64.76399730000003\n",
      "SGD - Training Size: 40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.12343502\n",
      "Iteration 2, loss = 0.63996600\n",
      "Iteration 3, loss = 0.56429345\n",
      "Iteration 4, loss = 0.52186690\n",
      "Iteration 5, loss = 0.49377055\n",
      "Iteration 6, loss = 0.47265862\n",
      "Iteration 7, loss = 0.45596527\n",
      "Iteration 8, loss = 0.44259412\n",
      "Iteration 9, loss = 0.43094502\n",
      "Iteration 10, loss = 0.42116444\n",
      "Iteration 11, loss = 0.41224600\n",
      "Iteration 12, loss = 0.40441390\n",
      "Iteration 13, loss = 0.39710834\n",
      "Iteration 14, loss = 0.39057397\n",
      "Iteration 15, loss = 0.38486376\n",
      "Iteration 16, loss = 0.37912813\n",
      "Iteration 17, loss = 0.37351164\n",
      "Iteration 18, loss = 0.36885272\n",
      "Iteration 19, loss = 0.36418632\n",
      "Iteration 20, loss = 0.35983779\n",
      "Iteration 21, loss = 0.35591859\n",
      "Iteration 22, loss = 0.35167555\n",
      "Iteration 23, loss = 0.34818971\n",
      "Iteration 24, loss = 0.34453551\n",
      "Iteration 25, loss = 0.34110626\n",
      "Iteration 26, loss = 0.33768287\n",
      "Iteration 27, loss = 0.33444484\n",
      "Iteration 28, loss = 0.33177060\n",
      "Iteration 29, loss = 0.32870068\n",
      "Iteration 30, loss = 0.32565836\n",
      "Iteration 31, loss = 0.32307932\n",
      "Iteration 32, loss = 0.32027856\n",
      "Iteration 33, loss = 0.31771326\n",
      "Iteration 34, loss = 0.31499286\n",
      "Iteration 35, loss = 0.31264163\n",
      "Iteration 36, loss = 0.31021999\n",
      "Iteration 37, loss = 0.30755275\n",
      "Iteration 38, loss = 0.30535607\n",
      "Iteration 39, loss = 0.30329378\n",
      "Iteration 40, loss = 0.30076030\n",
      "Iteration 41, loss = 0.29898262\n",
      "Iteration 42, loss = 0.29657192\n",
      "Iteration 43, loss = 0.29437700\n",
      "Iteration 44, loss = 0.29254906\n",
      "Iteration 45, loss = 0.29046611\n",
      "Iteration 46, loss = 0.28847073\n",
      "Iteration 47, loss = 0.28648262\n",
      "Iteration 48, loss = 0.28457700\n",
      "Iteration 49, loss = 0.28282641\n",
      "Iteration 50, loss = 0.28093181\n",
      "Iteration 51, loss = 0.27910026\n",
      "Iteration 52, loss = 0.27767739\n",
      "Iteration 53, loss = 0.27553419\n",
      "Iteration 54, loss = 0.27373357\n",
      "Iteration 55, loss = 0.27185256\n",
      "Iteration 56, loss = 0.27030447\n",
      "Iteration 57, loss = 0.26891408\n",
      "Iteration 58, loss = 0.26705835\n",
      "Iteration 59, loss = 0.26561951\n",
      "Iteration 60, loss = 0.26382430\n",
      "Iteration 61, loss = 0.26246986\n",
      "Iteration 62, loss = 0.26074606\n",
      "Iteration 63, loss = 0.25919040\n",
      "Iteration 64, loss = 0.25774649\n",
      "Iteration 65, loss = 0.25623003\n",
      "Iteration 66, loss = 0.25476777\n",
      "Iteration 67, loss = 0.25316648\n",
      "Iteration 68, loss = 0.25178787\n",
      "Iteration 69, loss = 0.25033517\n",
      "Iteration 70, loss = 0.24875785\n",
      "Iteration 71, loss = 0.24748687\n",
      "Iteration 72, loss = 0.24621467\n",
      "Iteration 73, loss = 0.24467260\n",
      "Iteration 74, loss = 0.24312951\n",
      "Iteration 75, loss = 0.24189364\n",
      "Iteration 76, loss = 0.24057966\n",
      "Iteration 77, loss = 0.23931997\n",
      "Iteration 78, loss = 0.23755792\n",
      "Iteration 79, loss = 0.23641470\n",
      "Iteration 80, loss = 0.23524981\n",
      "Iteration 81, loss = 0.23403325\n",
      "Iteration 82, loss = 0.23266282\n",
      "Iteration 83, loss = 0.23135252\n",
      "Iteration 84, loss = 0.23028363\n",
      "Iteration 85, loss = 0.22883895\n",
      "Iteration 86, loss = 0.22742946\n",
      "Iteration 87, loss = 0.22658616\n",
      "Iteration 88, loss = 0.22552394\n",
      "Iteration 89, loss = 0.22403949\n",
      "Iteration 90, loss = 0.22292598\n",
      "Iteration 91, loss = 0.22150622\n",
      "Iteration 92, loss = 0.22037567\n",
      "Iteration 93, loss = 0.21961197\n",
      "Iteration 94, loss = 0.21812483\n",
      "Iteration 95, loss = 0.21692155\n",
      "Iteration 96, loss = 0.21602180\n",
      "Iteration 97, loss = 0.21479289\n",
      "Iteration 98, loss = 0.21344580\n",
      "Iteration 99, loss = 0.21247586\n",
      "Iteration 100, loss = 0.21128272\n",
      "Iteration 101, loss = 0.21033175\n",
      "Iteration 102, loss = 0.20922526\n",
      "Iteration 103, loss = 0.20794008\n",
      "Iteration 104, loss = 0.20709681\n",
      "Iteration 105, loss = 0.20585507\n",
      "Iteration 106, loss = 0.20501451\n",
      "Iteration 107, loss = 0.20379990\n",
      "Iteration 108, loss = 0.20276178\n",
      "Iteration 109, loss = 0.20197357\n",
      "Iteration 110, loss = 0.20068917\n",
      "Iteration 111, loss = 0.19988083\n",
      "Iteration 112, loss = 0.19851108\n",
      "Iteration 113, loss = 0.19758727\n",
      "Iteration 114, loss = 0.19677543\n",
      "Iteration 115, loss = 0.19571648\n",
      "Iteration 116, loss = 0.19467172\n",
      "Iteration 117, loss = 0.19366735\n",
      "Iteration 118, loss = 0.19265936\n",
      "Iteration 119, loss = 0.19190584\n",
      "Iteration 120, loss = 0.19081187\n",
      "Iteration 121, loss = 0.18990504\n",
      "Iteration 122, loss = 0.18908539\n",
      "Iteration 123, loss = 0.18780790\n",
      "Iteration 124, loss = 0.18704773\n",
      "Iteration 125, loss = 0.18602568\n",
      "Iteration 126, loss = 0.18502885\n",
      "Iteration 127, loss = 0.18428744\n",
      "Iteration 128, loss = 0.18331838\n",
      "Iteration 129, loss = 0.18228256\n",
      "Iteration 130, loss = 0.18131048\n",
      "Iteration 131, loss = 0.18069957\n",
      "Iteration 132, loss = 0.17972602\n",
      "Iteration 133, loss = 0.17877429\n",
      "Iteration 134, loss = 0.17827483\n",
      "Iteration 135, loss = 0.17700190\n",
      "Iteration 136, loss = 0.17617247\n",
      "Iteration 137, loss = 0.17539544\n",
      "Iteration 138, loss = 0.17458833\n",
      "Iteration 139, loss = 0.17337114\n",
      "Iteration 140, loss = 0.17250054\n",
      "Iteration 141, loss = 0.17171826\n",
      "Iteration 142, loss = 0.17126658\n",
      "Iteration 143, loss = 0.17023091\n",
      "Iteration 144, loss = 0.16953429\n",
      "Iteration 145, loss = 0.16842960\n",
      "Iteration 146, loss = 0.16780380\n",
      "Iteration 147, loss = 0.16695569\n",
      "Iteration 148, loss = 0.16610532\n",
      "Iteration 149, loss = 0.16537320\n",
      "Iteration 150, loss = 0.16451917\n",
      "Iteration 151, loss = 0.16377759\n",
      "Iteration 152, loss = 0.16289496\n",
      "Iteration 153, loss = 0.16210353\n",
      "Iteration 154, loss = 0.16145658\n",
      "Iteration 155, loss = 0.16053381\n",
      "Iteration 156, loss = 0.15990866\n",
      "Iteration 157, loss = 0.15912352\n",
      "Iteration 158, loss = 0.15825748\n",
      "Iteration 159, loss = 0.15766981\n",
      "Iteration 160, loss = 0.15656366\n",
      "Iteration 161, loss = 0.15602455\n",
      "Iteration 162, loss = 0.15521934\n",
      "Iteration 163, loss = 0.15475792\n",
      "Iteration 164, loss = 0.15390654\n",
      "Iteration 165, loss = 0.15301211\n",
      "Iteration 166, loss = 0.15244651\n",
      "Iteration 167, loss = 0.15124696\n",
      "Iteration 168, loss = 0.15102916\n",
      "Iteration 169, loss = 0.15000000\n",
      "Iteration 170, loss = 0.14951713\n",
      "Iteration 171, loss = 0.14861058\n",
      "Iteration 172, loss = 0.14780237\n",
      "Iteration 173, loss = 0.14736871\n",
      "Iteration 174, loss = 0.14652430\n",
      "Iteration 175, loss = 0.14594638\n",
      "Iteration 176, loss = 0.14527332\n",
      "Iteration 177, loss = 0.14445442\n",
      "Iteration 178, loss = 0.14386527\n",
      "Iteration 179, loss = 0.14293803\n",
      "Iteration 180, loss = 0.14257217\n",
      "Iteration 181, loss = 0.14175023\n",
      "Iteration 182, loss = 0.14112634\n",
      "Iteration 183, loss = 0.14058655\n",
      "Iteration 184, loss = 0.13976715\n",
      "Iteration 185, loss = 0.13942774\n",
      "Iteration 186, loss = 0.13855335\n",
      "Iteration 187, loss = 0.13789658\n",
      "Iteration 188, loss = 0.13718873\n",
      "Iteration 189, loss = 0.13623968\n",
      "Iteration 190, loss = 0.13584751\n",
      "Iteration 191, loss = 0.13530856\n",
      "Iteration 192, loss = 0.13471286\n",
      "Iteration 193, loss = 0.13407149\n",
      "Iteration 194, loss = 0.13328045\n",
      "Iteration 195, loss = 0.13257857\n",
      "Iteration 196, loss = 0.13203303\n",
      "Iteration 197, loss = 0.13163639\n",
      "Iteration 198, loss = 0.13082464\n",
      "Iteration 199, loss = 0.13017494\n",
      "Iteration 200, loss = 0.12941587\n",
      "85.98935929999993\n",
      "SGD - Training Size: 50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.03528922\n",
      "Iteration 2, loss = 0.61789566\n",
      "Iteration 3, loss = 0.54539895\n",
      "Iteration 4, loss = 0.50489250\n",
      "Iteration 5, loss = 0.47751118\n",
      "Iteration 6, loss = 0.45696431\n",
      "Iteration 7, loss = 0.44155309\n",
      "Iteration 8, loss = 0.42864947\n",
      "Iteration 9, loss = 0.41776700\n",
      "Iteration 10, loss = 0.40821228\n",
      "Iteration 11, loss = 0.39998920\n",
      "Iteration 12, loss = 0.39243090\n",
      "Iteration 13, loss = 0.38579431\n",
      "Iteration 14, loss = 0.37946569\n",
      "Iteration 15, loss = 0.37394470\n",
      "Iteration 16, loss = 0.36841302\n",
      "Iteration 17, loss = 0.36340663\n",
      "Iteration 18, loss = 0.35908106\n",
      "Iteration 19, loss = 0.35448610\n",
      "Iteration 20, loss = 0.35057977\n",
      "Iteration 21, loss = 0.34662731\n",
      "Iteration 22, loss = 0.34264936\n",
      "Iteration 23, loss = 0.33911799\n",
      "Iteration 24, loss = 0.33566273\n",
      "Iteration 25, loss = 0.33232312\n",
      "Iteration 26, loss = 0.32934458\n",
      "Iteration 27, loss = 0.32598897\n",
      "Iteration 28, loss = 0.32314637\n",
      "Iteration 29, loss = 0.32024252\n",
      "Iteration 30, loss = 0.31739422\n",
      "Iteration 31, loss = 0.31485910\n",
      "Iteration 32, loss = 0.31237457\n",
      "Iteration 33, loss = 0.30975291\n",
      "Iteration 34, loss = 0.30736575\n",
      "Iteration 35, loss = 0.30518123\n",
      "Iteration 36, loss = 0.30265893\n",
      "Iteration 37, loss = 0.30068539\n",
      "Iteration 38, loss = 0.29851704\n",
      "Iteration 39, loss = 0.29616750\n",
      "Iteration 40, loss = 0.29407957\n",
      "Iteration 41, loss = 0.29167751\n",
      "Iteration 42, loss = 0.28996464\n",
      "Iteration 43, loss = 0.28796062\n",
      "Iteration 44, loss = 0.28620387\n",
      "Iteration 45, loss = 0.28399547\n",
      "Iteration 46, loss = 0.28210867\n",
      "Iteration 47, loss = 0.28042713\n",
      "Iteration 48, loss = 0.27844754\n",
      "Iteration 49, loss = 0.27650747\n",
      "Iteration 50, loss = 0.27495273\n",
      "Iteration 51, loss = 0.27305339\n",
      "Iteration 52, loss = 0.27154085\n",
      "Iteration 53, loss = 0.26954253\n",
      "Iteration 54, loss = 0.26791964\n",
      "Iteration 55, loss = 0.26658542\n",
      "Iteration 56, loss = 0.26480307\n",
      "Iteration 57, loss = 0.26302202\n",
      "Iteration 58, loss = 0.26158044\n",
      "Iteration 59, loss = 0.26011918\n",
      "Iteration 60, loss = 0.25830916\n",
      "Iteration 61, loss = 0.25696970\n",
      "Iteration 62, loss = 0.25520602\n",
      "Iteration 63, loss = 0.25375273\n",
      "Iteration 64, loss = 0.25236194\n",
      "Iteration 65, loss = 0.25077177\n",
      "Iteration 66, loss = 0.24942555\n",
      "Iteration 67, loss = 0.24794777\n",
      "Iteration 68, loss = 0.24650360\n",
      "Iteration 69, loss = 0.24518204\n",
      "Iteration 70, loss = 0.24366289\n",
      "Iteration 71, loss = 0.24264582\n",
      "Iteration 72, loss = 0.24099151\n",
      "Iteration 73, loss = 0.23973556\n",
      "Iteration 74, loss = 0.23844443\n",
      "Iteration 75, loss = 0.23714727\n",
      "Iteration 76, loss = 0.23561799\n",
      "Iteration 77, loss = 0.23438961\n",
      "Iteration 78, loss = 0.23328644\n",
      "Iteration 79, loss = 0.23206486\n",
      "Iteration 80, loss = 0.23072901\n",
      "Iteration 81, loss = 0.22949281\n",
      "Iteration 82, loss = 0.22815786\n",
      "Iteration 83, loss = 0.22708712\n",
      "Iteration 84, loss = 0.22571303\n",
      "Iteration 85, loss = 0.22461145\n",
      "Iteration 86, loss = 0.22346594\n",
      "Iteration 87, loss = 0.22249719\n",
      "Iteration 88, loss = 0.22091932\n",
      "Iteration 89, loss = 0.22016213\n",
      "Iteration 90, loss = 0.21863473\n",
      "Iteration 91, loss = 0.21754737\n",
      "Iteration 92, loss = 0.21654733\n",
      "Iteration 93, loss = 0.21563177\n",
      "Iteration 94, loss = 0.21435791\n",
      "Iteration 95, loss = 0.21325172\n",
      "Iteration 96, loss = 0.21216102\n",
      "Iteration 97, loss = 0.21110676\n",
      "Iteration 98, loss = 0.20988811\n",
      "Iteration 99, loss = 0.20876909\n",
      "Iteration 100, loss = 0.20755068\n",
      "Iteration 101, loss = 0.20675623\n",
      "Iteration 102, loss = 0.20557650\n",
      "Iteration 103, loss = 0.20462959\n",
      "Iteration 104, loss = 0.20365360\n",
      "Iteration 105, loss = 0.20237189\n",
      "Iteration 106, loss = 0.20160754\n",
      "Iteration 107, loss = 0.20047903\n",
      "Iteration 108, loss = 0.19938741\n",
      "Iteration 109, loss = 0.19867672\n",
      "Iteration 110, loss = 0.19748964\n",
      "Iteration 111, loss = 0.19687111\n",
      "Iteration 112, loss = 0.19558903\n",
      "Iteration 113, loss = 0.19469758\n",
      "Iteration 114, loss = 0.19351524\n",
      "Iteration 115, loss = 0.19268769\n",
      "Iteration 116, loss = 0.19166619\n",
      "Iteration 117, loss = 0.19082773\n",
      "Iteration 118, loss = 0.18990178\n",
      "Iteration 119, loss = 0.18873631\n",
      "Iteration 120, loss = 0.18794699\n",
      "Iteration 121, loss = 0.18708243\n",
      "Iteration 122, loss = 0.18622563\n",
      "Iteration 123, loss = 0.18502089\n",
      "Iteration 124, loss = 0.18467364\n",
      "Iteration 125, loss = 0.18343822\n",
      "Iteration 126, loss = 0.18279805\n",
      "Iteration 127, loss = 0.18179776\n",
      "Iteration 128, loss = 0.18088642\n",
      "Iteration 129, loss = 0.18006686\n",
      "Iteration 130, loss = 0.17900409\n",
      "Iteration 131, loss = 0.17803668\n",
      "Iteration 132, loss = 0.17754992\n",
      "Iteration 133, loss = 0.17652435\n",
      "Iteration 134, loss = 0.17548356\n",
      "Iteration 135, loss = 0.17480770\n",
      "Iteration 136, loss = 0.17418482\n",
      "Iteration 137, loss = 0.17330900\n",
      "Iteration 138, loss = 0.17243481\n",
      "Iteration 139, loss = 0.17151182\n",
      "Iteration 140, loss = 0.17077927\n",
      "Iteration 141, loss = 0.16983146\n",
      "Iteration 142, loss = 0.16901250\n",
      "Iteration 143, loss = 0.16829611\n",
      "Iteration 144, loss = 0.16752319\n",
      "Iteration 145, loss = 0.16677688\n",
      "Iteration 146, loss = 0.16595190\n",
      "Iteration 147, loss = 0.16523611\n",
      "Iteration 148, loss = 0.16425867\n",
      "Iteration 149, loss = 0.16362580\n",
      "Iteration 150, loss = 0.16321834\n",
      "Iteration 151, loss = 0.16214880\n",
      "Iteration 152, loss = 0.16129937\n",
      "Iteration 153, loss = 0.16053467\n",
      "Iteration 154, loss = 0.15974860\n",
      "Iteration 155, loss = 0.15905335\n",
      "Iteration 156, loss = 0.15844367\n",
      "Iteration 157, loss = 0.15748220\n",
      "Iteration 158, loss = 0.15681568\n",
      "Iteration 159, loss = 0.15608226\n",
      "Iteration 160, loss = 0.15550019\n",
      "Iteration 161, loss = 0.15464907\n",
      "Iteration 162, loss = 0.15380801\n",
      "Iteration 163, loss = 0.15331725\n",
      "Iteration 164, loss = 0.15237357\n",
      "Iteration 165, loss = 0.15198098\n",
      "Iteration 166, loss = 0.15104204\n",
      "Iteration 167, loss = 0.15050645\n",
      "Iteration 168, loss = 0.14970313\n",
      "Iteration 169, loss = 0.14911892\n",
      "Iteration 170, loss = 0.14825197\n",
      "Iteration 171, loss = 0.14769779\n",
      "Iteration 172, loss = 0.14697676\n",
      "Iteration 173, loss = 0.14637019\n",
      "Iteration 174, loss = 0.14562485\n",
      "Iteration 175, loss = 0.14482579\n",
      "Iteration 176, loss = 0.14419010\n",
      "Iteration 177, loss = 0.14363592\n",
      "Iteration 178, loss = 0.14305213\n",
      "Iteration 179, loss = 0.14225907\n",
      "Iteration 180, loss = 0.14163321\n",
      "Iteration 181, loss = 0.14102956\n",
      "Iteration 182, loss = 0.14047681\n",
      "Iteration 183, loss = 0.13975912\n",
      "Iteration 184, loss = 0.13911191\n",
      "Iteration 185, loss = 0.13850858\n",
      "Iteration 186, loss = 0.13768332\n",
      "Iteration 187, loss = 0.13724632\n",
      "Iteration 188, loss = 0.13672323\n",
      "Iteration 189, loss = 0.13609082\n",
      "Iteration 190, loss = 0.13554872\n",
      "Iteration 191, loss = 0.13471858\n",
      "Iteration 192, loss = 0.13393798\n",
      "Iteration 193, loss = 0.13362758\n",
      "Iteration 194, loss = 0.13285077\n",
      "Iteration 195, loss = 0.13246199\n",
      "Iteration 196, loss = 0.13187303\n",
      "Iteration 197, loss = 0.13121284\n",
      "Iteration 198, loss = 0.13047777\n",
      "Iteration 199, loss = 0.13028154\n",
      "Iteration 200, loss = 0.12936675\n",
      "107.2438684\n",
      "SGD - Training Size: 60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.96837653\n",
      "Iteration 2, loss = 0.59142215\n",
      "Iteration 3, loss = 0.52304564\n",
      "Iteration 4, loss = 0.48564120\n",
      "Iteration 5, loss = 0.46148271\n",
      "Iteration 6, loss = 0.44265712\n",
      "Iteration 7, loss = 0.42817278\n",
      "Iteration 8, loss = 0.41602499\n",
      "Iteration 9, loss = 0.40608145\n",
      "Iteration 10, loss = 0.39734203\n",
      "Iteration 11, loss = 0.38946199\n",
      "Iteration 12, loss = 0.38244220\n",
      "Iteration 13, loss = 0.37602336\n",
      "Iteration 14, loss = 0.37036855\n",
      "Iteration 15, loss = 0.36479082\n",
      "Iteration 16, loss = 0.35980542\n",
      "Iteration 17, loss = 0.35552061\n",
      "Iteration 18, loss = 0.35084732\n",
      "Iteration 19, loss = 0.34670616\n",
      "Iteration 20, loss = 0.34294336\n",
      "Iteration 21, loss = 0.33919401\n",
      "Iteration 22, loss = 0.33576356\n",
      "Iteration 23, loss = 0.33242291\n",
      "Iteration 24, loss = 0.32908056\n",
      "Iteration 25, loss = 0.32616738\n",
      "Iteration 26, loss = 0.32289758\n",
      "Iteration 27, loss = 0.31998832\n",
      "Iteration 28, loss = 0.31734605\n",
      "Iteration 29, loss = 0.31464937\n",
      "Iteration 30, loss = 0.31210320\n",
      "Iteration 31, loss = 0.30925863\n",
      "Iteration 32, loss = 0.30703105\n",
      "Iteration 33, loss = 0.30440330\n",
      "Iteration 34, loss = 0.30213693\n",
      "Iteration 35, loss = 0.29988442\n",
      "Iteration 36, loss = 0.29750309\n",
      "Iteration 37, loss = 0.29534392\n",
      "Iteration 38, loss = 0.29317696\n",
      "Iteration 39, loss = 0.29110148\n",
      "Iteration 40, loss = 0.28903625\n",
      "Iteration 41, loss = 0.28685363\n",
      "Iteration 42, loss = 0.28491803\n",
      "Iteration 43, loss = 0.28301491\n",
      "Iteration 44, loss = 0.28109711\n",
      "Iteration 45, loss = 0.27911125\n",
      "Iteration 46, loss = 0.27743945\n",
      "Iteration 47, loss = 0.27564547\n",
      "Iteration 48, loss = 0.27377099\n",
      "Iteration 49, loss = 0.27196962\n",
      "Iteration 50, loss = 0.27001406\n",
      "Iteration 51, loss = 0.26860960\n",
      "Iteration 52, loss = 0.26684095\n",
      "Iteration 53, loss = 0.26521351\n",
      "Iteration 54, loss = 0.26344659\n",
      "Iteration 55, loss = 0.26183577\n",
      "Iteration 56, loss = 0.26030402\n",
      "Iteration 57, loss = 0.25863206\n",
      "Iteration 58, loss = 0.25717466\n",
      "Iteration 59, loss = 0.25567989\n",
      "Iteration 60, loss = 0.25445409\n",
      "Iteration 61, loss = 0.25274288\n",
      "Iteration 62, loss = 0.25126561\n",
      "Iteration 63, loss = 0.24991049\n",
      "Iteration 64, loss = 0.24847137\n",
      "Iteration 65, loss = 0.24700712\n",
      "Iteration 66, loss = 0.24550274\n",
      "Iteration 67, loss = 0.24445848\n",
      "Iteration 68, loss = 0.24305018\n",
      "Iteration 69, loss = 0.24167910\n",
      "Iteration 70, loss = 0.24018877\n",
      "Iteration 71, loss = 0.23922710\n",
      "Iteration 72, loss = 0.23759411\n",
      "Iteration 73, loss = 0.23637104\n",
      "Iteration 74, loss = 0.23502980\n",
      "Iteration 75, loss = 0.23416039\n",
      "Iteration 76, loss = 0.23262809\n",
      "Iteration 77, loss = 0.23139437\n",
      "Iteration 78, loss = 0.23029348\n",
      "Iteration 79, loss = 0.22897099\n",
      "Iteration 80, loss = 0.22784623\n",
      "Iteration 81, loss = 0.22677934\n",
      "Iteration 82, loss = 0.22548187\n",
      "Iteration 83, loss = 0.22421377\n",
      "Iteration 84, loss = 0.22328914\n",
      "Iteration 85, loss = 0.22176449\n",
      "Iteration 86, loss = 0.22074833\n",
      "Iteration 87, loss = 0.21968279\n",
      "Iteration 88, loss = 0.21870238\n",
      "Iteration 89, loss = 0.21726874\n",
      "Iteration 90, loss = 0.21627007\n",
      "Iteration 91, loss = 0.21519865\n",
      "Iteration 92, loss = 0.21424639\n",
      "Iteration 93, loss = 0.21307005\n",
      "Iteration 94, loss = 0.21188054\n",
      "Iteration 95, loss = 0.21084979\n",
      "Iteration 96, loss = 0.20994749\n",
      "Iteration 97, loss = 0.20877884\n",
      "Iteration 98, loss = 0.20756012\n",
      "Iteration 99, loss = 0.20674974\n",
      "Iteration 100, loss = 0.20577553\n",
      "Iteration 101, loss = 0.20491177\n",
      "Iteration 102, loss = 0.20369339\n",
      "Iteration 103, loss = 0.20247444\n",
      "Iteration 104, loss = 0.20148130\n",
      "Iteration 105, loss = 0.20065212\n",
      "Iteration 106, loss = 0.19949486\n",
      "Iteration 107, loss = 0.19849809\n",
      "Iteration 108, loss = 0.19760121\n",
      "Iteration 109, loss = 0.19660749\n",
      "Iteration 110, loss = 0.19562475\n",
      "Iteration 111, loss = 0.19475060\n",
      "Iteration 112, loss = 0.19400872\n",
      "Iteration 113, loss = 0.19299946\n",
      "Iteration 114, loss = 0.19194876\n",
      "Iteration 115, loss = 0.19085531\n",
      "Iteration 116, loss = 0.19010923\n",
      "Iteration 117, loss = 0.18890546\n",
      "Iteration 118, loss = 0.18815772\n",
      "Iteration 119, loss = 0.18728555\n",
      "Iteration 120, loss = 0.18638488\n",
      "Iteration 121, loss = 0.18553107\n",
      "Iteration 122, loss = 0.18443820\n",
      "Iteration 123, loss = 0.18376859\n",
      "Iteration 124, loss = 0.18284983\n",
      "Iteration 125, loss = 0.18211273\n",
      "Iteration 126, loss = 0.18112882\n",
      "Iteration 127, loss = 0.18016622\n",
      "Iteration 128, loss = 0.17957317\n",
      "Iteration 129, loss = 0.17855045\n",
      "Iteration 130, loss = 0.17776618\n",
      "Iteration 131, loss = 0.17695826\n",
      "Iteration 132, loss = 0.17597381\n",
      "Iteration 133, loss = 0.17519013\n",
      "Iteration 134, loss = 0.17445409\n",
      "Iteration 135, loss = 0.17336522\n",
      "Iteration 136, loss = 0.17285601\n",
      "Iteration 137, loss = 0.17193238\n",
      "Iteration 138, loss = 0.17114731\n",
      "Iteration 139, loss = 0.17037280\n",
      "Iteration 140, loss = 0.16962129\n",
      "Iteration 141, loss = 0.16880181\n",
      "Iteration 142, loss = 0.16775378\n",
      "Iteration 143, loss = 0.16699330\n",
      "Iteration 144, loss = 0.16623203\n",
      "Iteration 145, loss = 0.16582123\n",
      "Iteration 146, loss = 0.16494894\n",
      "Iteration 147, loss = 0.16410518\n",
      "Iteration 148, loss = 0.16341641\n",
      "Iteration 149, loss = 0.16244480\n",
      "Iteration 150, loss = 0.16179942\n",
      "Iteration 151, loss = 0.16091424\n",
      "Iteration 152, loss = 0.16041371\n",
      "Iteration 153, loss = 0.15966692\n",
      "Iteration 154, loss = 0.15886018\n",
      "Iteration 155, loss = 0.15795361\n",
      "Iteration 156, loss = 0.15749458\n",
      "Iteration 157, loss = 0.15691647\n",
      "Iteration 158, loss = 0.15587175\n",
      "Iteration 159, loss = 0.15553876\n",
      "Iteration 160, loss = 0.15444206\n",
      "Iteration 161, loss = 0.15391171\n",
      "Iteration 162, loss = 0.15330312\n",
      "Iteration 163, loss = 0.15234877\n",
      "Iteration 164, loss = 0.15170738\n",
      "Iteration 165, loss = 0.15109383\n",
      "Iteration 166, loss = 0.15036768\n",
      "Iteration 167, loss = 0.14967168\n",
      "Iteration 168, loss = 0.14907178\n",
      "Iteration 169, loss = 0.14841335\n",
      "Iteration 170, loss = 0.14785831\n",
      "Iteration 171, loss = 0.14728492\n",
      "Iteration 172, loss = 0.14657464\n",
      "Iteration 173, loss = 0.14571521\n",
      "Iteration 174, loss = 0.14498762\n",
      "Iteration 175, loss = 0.14437376\n",
      "Iteration 176, loss = 0.14368958\n",
      "Iteration 177, loss = 0.14309883\n",
      "Iteration 178, loss = 0.14256357\n",
      "Iteration 179, loss = 0.14167408\n",
      "Iteration 180, loss = 0.14111670\n",
      "Iteration 181, loss = 0.14057767\n",
      "Iteration 182, loss = 0.14006628\n",
      "Iteration 183, loss = 0.13912775\n",
      "Iteration 184, loss = 0.13878987\n",
      "Iteration 185, loss = 0.13804988\n",
      "Iteration 186, loss = 0.13748066\n",
      "Iteration 187, loss = 0.13696905\n",
      "Iteration 188, loss = 0.13627342\n",
      "Iteration 189, loss = 0.13560342\n",
      "Iteration 190, loss = 0.13516497\n",
      "Iteration 191, loss = 0.13434682\n",
      "Iteration 192, loss = 0.13381901\n",
      "Iteration 193, loss = 0.13327886\n",
      "Iteration 194, loss = 0.13273665\n",
      "Iteration 195, loss = 0.13209402\n",
      "Iteration 196, loss = 0.13142455\n",
      "Iteration 197, loss = 0.13102826\n",
      "Iteration 198, loss = 0.13046187\n",
      "Iteration 199, loss = 0.12981922\n",
      "Iteration 200, loss = 0.12931558\n",
      "136.9360828\n",
      "SGD - Training Size: 70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.91779799\n",
      "Iteration 2, loss = 0.57830595\n",
      "Iteration 3, loss = 0.51135287\n",
      "Iteration 4, loss = 0.47490410\n",
      "Iteration 5, loss = 0.45138374\n",
      "Iteration 6, loss = 0.43423763\n",
      "Iteration 7, loss = 0.42034457\n",
      "Iteration 8, loss = 0.40953182\n",
      "Iteration 9, loss = 0.39995246\n",
      "Iteration 10, loss = 0.39172474\n",
      "Iteration 11, loss = 0.38411305\n",
      "Iteration 12, loss = 0.37757030\n",
      "Iteration 13, loss = 0.37132973\n",
      "Iteration 14, loss = 0.36578092\n",
      "Iteration 15, loss = 0.36074525\n",
      "Iteration 16, loss = 0.35599609\n",
      "Iteration 17, loss = 0.35163352\n",
      "Iteration 18, loss = 0.34730442\n",
      "Iteration 19, loss = 0.34341029\n",
      "Iteration 20, loss = 0.33955767\n",
      "Iteration 21, loss = 0.33611365\n",
      "Iteration 22, loss = 0.33255053\n",
      "Iteration 23, loss = 0.32931781\n",
      "Iteration 24, loss = 0.32634531\n",
      "Iteration 25, loss = 0.32303499\n",
      "Iteration 26, loss = 0.32017836\n",
      "Iteration 27, loss = 0.31758324\n",
      "Iteration 28, loss = 0.31468960\n",
      "Iteration 29, loss = 0.31211584\n",
      "Iteration 30, loss = 0.30961307\n",
      "Iteration 31, loss = 0.30705203\n",
      "Iteration 32, loss = 0.30464057\n",
      "Iteration 33, loss = 0.30237983\n",
      "Iteration 34, loss = 0.30006329\n",
      "Iteration 35, loss = 0.29790960\n",
      "Iteration 36, loss = 0.29582433\n",
      "Iteration 37, loss = 0.29331146\n",
      "Iteration 38, loss = 0.29148060\n",
      "Iteration 39, loss = 0.28929668\n",
      "Iteration 40, loss = 0.28727391\n",
      "Iteration 41, loss = 0.28523640\n",
      "Iteration 42, loss = 0.28350312\n",
      "Iteration 43, loss = 0.28152537\n",
      "Iteration 44, loss = 0.27992023\n",
      "Iteration 45, loss = 0.27802791\n",
      "Iteration 46, loss = 0.27617129\n",
      "Iteration 47, loss = 0.27465688\n",
      "Iteration 48, loss = 0.27265162\n",
      "Iteration 49, loss = 0.27110535\n",
      "Iteration 50, loss = 0.26927058\n",
      "Iteration 51, loss = 0.26775078\n",
      "Iteration 52, loss = 0.26619196\n",
      "Iteration 53, loss = 0.26453288\n",
      "Iteration 54, loss = 0.26307280\n",
      "Iteration 55, loss = 0.26161096\n",
      "Iteration 56, loss = 0.25987237\n",
      "Iteration 57, loss = 0.25828710\n",
      "Iteration 58, loss = 0.25694739\n",
      "Iteration 59, loss = 0.25511298\n",
      "Iteration 60, loss = 0.25394310\n",
      "Iteration 61, loss = 0.25266457\n",
      "Iteration 62, loss = 0.25109406\n",
      "Iteration 63, loss = 0.24989354\n",
      "Iteration 64, loss = 0.24827741\n",
      "Iteration 65, loss = 0.24706614\n",
      "Iteration 66, loss = 0.24552357\n",
      "Iteration 67, loss = 0.24407307\n",
      "Iteration 68, loss = 0.24283368\n",
      "Iteration 69, loss = 0.24166008\n",
      "Iteration 70, loss = 0.23998795\n",
      "Iteration 71, loss = 0.23890976\n",
      "Iteration 72, loss = 0.23770732\n",
      "Iteration 73, loss = 0.23624167\n",
      "Iteration 74, loss = 0.23499259\n",
      "Iteration 75, loss = 0.23373128\n",
      "Iteration 76, loss = 0.23265313\n",
      "Iteration 77, loss = 0.23134433\n",
      "Iteration 78, loss = 0.23036658\n",
      "Iteration 79, loss = 0.22876932\n",
      "Iteration 80, loss = 0.22780076\n",
      "Iteration 81, loss = 0.22655032\n",
      "Iteration 82, loss = 0.22540497\n",
      "Iteration 83, loss = 0.22418295\n",
      "Iteration 84, loss = 0.22305906\n",
      "Iteration 85, loss = 0.22185626\n",
      "Iteration 86, loss = 0.22078646\n",
      "Iteration 87, loss = 0.21970220\n",
      "Iteration 88, loss = 0.21866173\n",
      "Iteration 89, loss = 0.21740811\n",
      "Iteration 90, loss = 0.21632562\n",
      "Iteration 91, loss = 0.21524343\n",
      "Iteration 92, loss = 0.21420111\n",
      "Iteration 93, loss = 0.21312899\n",
      "Iteration 94, loss = 0.21222208\n",
      "Iteration 95, loss = 0.21099962\n",
      "Iteration 96, loss = 0.20998963\n",
      "Iteration 97, loss = 0.20870666\n",
      "Iteration 98, loss = 0.20767216\n",
      "Iteration 99, loss = 0.20666668\n",
      "Iteration 100, loss = 0.20585011\n",
      "Iteration 101, loss = 0.20462431\n",
      "Iteration 102, loss = 0.20355364\n",
      "Iteration 103, loss = 0.20269000\n",
      "Iteration 104, loss = 0.20153632\n",
      "Iteration 105, loss = 0.20042011\n",
      "Iteration 106, loss = 0.19961834\n",
      "Iteration 107, loss = 0.19887625\n",
      "Iteration 108, loss = 0.19795827\n",
      "Iteration 109, loss = 0.19687944\n",
      "Iteration 110, loss = 0.19593538\n",
      "Iteration 111, loss = 0.19482122\n",
      "Iteration 112, loss = 0.19396303\n",
      "Iteration 113, loss = 0.19310975\n",
      "Iteration 114, loss = 0.19220274\n",
      "Iteration 115, loss = 0.19112213\n",
      "Iteration 116, loss = 0.19020925\n",
      "Iteration 117, loss = 0.18929149\n",
      "Iteration 118, loss = 0.18843048\n",
      "Iteration 119, loss = 0.18768013\n",
      "Iteration 120, loss = 0.18667067\n",
      "Iteration 121, loss = 0.18567116\n",
      "Iteration 122, loss = 0.18477090\n",
      "Iteration 123, loss = 0.18401648\n",
      "Iteration 124, loss = 0.18308517\n",
      "Iteration 125, loss = 0.18217308\n",
      "Iteration 126, loss = 0.18114785\n",
      "Iteration 127, loss = 0.18016262\n",
      "Iteration 128, loss = 0.17938579\n",
      "Iteration 129, loss = 0.17867136\n",
      "Iteration 130, loss = 0.17765658\n",
      "Iteration 131, loss = 0.17680805\n",
      "Iteration 132, loss = 0.17626292\n",
      "Iteration 133, loss = 0.17513342\n",
      "Iteration 134, loss = 0.17446345\n",
      "Iteration 135, loss = 0.17370129\n",
      "Iteration 136, loss = 0.17295894\n",
      "Iteration 137, loss = 0.17188973\n",
      "Iteration 138, loss = 0.17148734\n",
      "Iteration 139, loss = 0.17051710\n",
      "Iteration 140, loss = 0.16970453\n",
      "Iteration 141, loss = 0.16892294\n",
      "Iteration 142, loss = 0.16822032\n",
      "Iteration 143, loss = 0.16744381\n",
      "Iteration 144, loss = 0.16664687\n",
      "Iteration 145, loss = 0.16572000\n",
      "Iteration 146, loss = 0.16506242\n",
      "Iteration 147, loss = 0.16426030\n",
      "Iteration 148, loss = 0.16340447\n",
      "Iteration 149, loss = 0.16269260\n",
      "Iteration 150, loss = 0.16185255\n",
      "Iteration 151, loss = 0.16133590\n",
      "Iteration 152, loss = 0.16047828\n",
      "Iteration 153, loss = 0.15980492\n",
      "Iteration 154, loss = 0.15933121\n",
      "Iteration 155, loss = 0.15826796\n",
      "Iteration 156, loss = 0.15746745\n",
      "Iteration 157, loss = 0.15682708\n",
      "Iteration 158, loss = 0.15600752\n",
      "Iteration 159, loss = 0.15541720\n",
      "Iteration 160, loss = 0.15486938\n",
      "Iteration 161, loss = 0.15405721\n",
      "Iteration 162, loss = 0.15323749\n",
      "Iteration 163, loss = 0.15257003\n",
      "Iteration 164, loss = 0.15191180\n",
      "Iteration 165, loss = 0.15128841\n",
      "Iteration 166, loss = 0.15040440\n",
      "Iteration 167, loss = 0.14997671\n",
      "Iteration 168, loss = 0.14912297\n",
      "Iteration 169, loss = 0.14854870\n",
      "Iteration 170, loss = 0.14766124\n",
      "Iteration 171, loss = 0.14732044\n",
      "Iteration 172, loss = 0.14637488\n",
      "Iteration 173, loss = 0.14578474\n",
      "Iteration 174, loss = 0.14507512\n",
      "Iteration 175, loss = 0.14454412\n",
      "Iteration 176, loss = 0.14384069\n",
      "Iteration 177, loss = 0.14321535\n",
      "Iteration 178, loss = 0.14258105\n",
      "Iteration 179, loss = 0.14197697\n",
      "Iteration 180, loss = 0.14128526\n",
      "Iteration 181, loss = 0.14050617\n",
      "Iteration 182, loss = 0.14016639\n",
      "Iteration 183, loss = 0.13916880\n",
      "Iteration 184, loss = 0.13852659\n",
      "Iteration 185, loss = 0.13802496\n",
      "Iteration 186, loss = 0.13727373\n",
      "Iteration 187, loss = 0.13672218\n",
      "Iteration 188, loss = 0.13603570\n",
      "Iteration 189, loss = 0.13543898\n",
      "Iteration 190, loss = 0.13509560\n",
      "Iteration 191, loss = 0.13432196\n",
      "Iteration 192, loss = 0.13391733\n",
      "Iteration 193, loss = 0.13305143\n",
      "Iteration 194, loss = 0.13268635\n",
      "Iteration 195, loss = 0.13166365\n",
      "Iteration 196, loss = 0.13141575\n",
      "Iteration 197, loss = 0.13072117\n",
      "Iteration 198, loss = 0.13035627\n",
      "Iteration 199, loss = 0.12968825\n",
      "Iteration 200, loss = 0.12905463\n",
      "151.3315608999999\n",
      "SGD - Training Size: 80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.92005926\n",
      "Iteration 2, loss = 0.56998661\n",
      "Iteration 3, loss = 0.50381386\n",
      "Iteration 4, loss = 0.46916712\n",
      "Iteration 5, loss = 0.44631013\n",
      "Iteration 6, loss = 0.42950905\n",
      "Iteration 7, loss = 0.41607430\n",
      "Iteration 8, loss = 0.40463959\n",
      "Iteration 9, loss = 0.39521351\n",
      "Iteration 10, loss = 0.38688458\n",
      "Iteration 11, loss = 0.37918273\n",
      "Iteration 12, loss = 0.37237744\n",
      "Iteration 13, loss = 0.36659190\n",
      "Iteration 14, loss = 0.36083106\n",
      "Iteration 15, loss = 0.35586282\n",
      "Iteration 16, loss = 0.35071892\n",
      "Iteration 17, loss = 0.34631651\n",
      "Iteration 18, loss = 0.34222276\n",
      "Iteration 19, loss = 0.33823146\n",
      "Iteration 20, loss = 0.33434610\n",
      "Iteration 21, loss = 0.33049596\n",
      "Iteration 22, loss = 0.32745541\n",
      "Iteration 23, loss = 0.32417887\n",
      "Iteration 24, loss = 0.32113982\n",
      "Iteration 25, loss = 0.31793343\n",
      "Iteration 26, loss = 0.31496716\n",
      "Iteration 27, loss = 0.31224663\n",
      "Iteration 28, loss = 0.30925912\n",
      "Iteration 29, loss = 0.30694757\n",
      "Iteration 30, loss = 0.30435393\n",
      "Iteration 31, loss = 0.30179342\n",
      "Iteration 32, loss = 0.29946689\n",
      "Iteration 33, loss = 0.29720257\n",
      "Iteration 34, loss = 0.29479705\n",
      "Iteration 35, loss = 0.29258929\n",
      "Iteration 36, loss = 0.29053197\n",
      "Iteration 37, loss = 0.28835221\n",
      "Iteration 38, loss = 0.28625488\n",
      "Iteration 39, loss = 0.28423436\n",
      "Iteration 40, loss = 0.28226833\n",
      "Iteration 41, loss = 0.28034228\n",
      "Iteration 42, loss = 0.27842573\n",
      "Iteration 43, loss = 0.27653456\n",
      "Iteration 44, loss = 0.27480456\n",
      "Iteration 45, loss = 0.27301287\n",
      "Iteration 46, loss = 0.27123819\n",
      "Iteration 47, loss = 0.26940658\n",
      "Iteration 48, loss = 0.26745142\n",
      "Iteration 49, loss = 0.26609170\n",
      "Iteration 50, loss = 0.26451489\n",
      "Iteration 51, loss = 0.26278345\n",
      "Iteration 52, loss = 0.26125015\n",
      "Iteration 53, loss = 0.26008044\n",
      "Iteration 54, loss = 0.25799962\n",
      "Iteration 55, loss = 0.25663826\n",
      "Iteration 56, loss = 0.25522777\n",
      "Iteration 57, loss = 0.25342048\n",
      "Iteration 58, loss = 0.25215751\n",
      "Iteration 59, loss = 0.25073497\n",
      "Iteration 60, loss = 0.24904284\n",
      "Iteration 61, loss = 0.24795138\n",
      "Iteration 62, loss = 0.24650453\n",
      "Iteration 63, loss = 0.24503217\n",
      "Iteration 64, loss = 0.24362615\n",
      "Iteration 65, loss = 0.24265379\n",
      "Iteration 66, loss = 0.24124931\n",
      "Iteration 67, loss = 0.23941092\n",
      "Iteration 68, loss = 0.23843613\n",
      "Iteration 69, loss = 0.23703079\n",
      "Iteration 70, loss = 0.23593950\n",
      "Iteration 71, loss = 0.23469045\n",
      "Iteration 72, loss = 0.23334897\n",
      "Iteration 73, loss = 0.23210176\n",
      "Iteration 74, loss = 0.23098760\n",
      "Iteration 75, loss = 0.22987035\n",
      "Iteration 76, loss = 0.22843130\n",
      "Iteration 77, loss = 0.22711107\n",
      "Iteration 78, loss = 0.22628413\n",
      "Iteration 79, loss = 0.22498374\n",
      "Iteration 80, loss = 0.22395410\n",
      "Iteration 81, loss = 0.22269941\n",
      "Iteration 82, loss = 0.22152025\n",
      "Iteration 83, loss = 0.22024780\n",
      "Iteration 84, loss = 0.21924804\n",
      "Iteration 85, loss = 0.21805098\n",
      "Iteration 86, loss = 0.21728280\n",
      "Iteration 87, loss = 0.21592338\n",
      "Iteration 88, loss = 0.21476872\n",
      "Iteration 89, loss = 0.21369027\n",
      "Iteration 90, loss = 0.21263441\n",
      "Iteration 91, loss = 0.21162039\n",
      "Iteration 92, loss = 0.21043951\n",
      "Iteration 93, loss = 0.20959175\n",
      "Iteration 94, loss = 0.20867861\n",
      "Iteration 95, loss = 0.20737864\n",
      "Iteration 96, loss = 0.20640751\n",
      "Iteration 97, loss = 0.20547385\n",
      "Iteration 98, loss = 0.20457690\n",
      "Iteration 99, loss = 0.20349443\n",
      "Iteration 100, loss = 0.20232056\n",
      "Iteration 101, loss = 0.20155735\n",
      "Iteration 102, loss = 0.20049980\n",
      "Iteration 103, loss = 0.19939689\n",
      "Iteration 104, loss = 0.19861029\n",
      "Iteration 105, loss = 0.19740983\n",
      "Iteration 106, loss = 0.19655480\n",
      "Iteration 107, loss = 0.19580029\n",
      "Iteration 108, loss = 0.19465547\n",
      "Iteration 109, loss = 0.19390453\n",
      "Iteration 110, loss = 0.19297222\n",
      "Iteration 111, loss = 0.19186855\n",
      "Iteration 112, loss = 0.19103519\n",
      "Iteration 113, loss = 0.19013397\n",
      "Iteration 114, loss = 0.18934385\n",
      "Iteration 115, loss = 0.18847121\n",
      "Iteration 116, loss = 0.18753037\n",
      "Iteration 117, loss = 0.18674959\n",
      "Iteration 118, loss = 0.18594654\n",
      "Iteration 119, loss = 0.18492936\n",
      "Iteration 120, loss = 0.18391328\n",
      "Iteration 121, loss = 0.18305517\n",
      "Iteration 122, loss = 0.18238221\n",
      "Iteration 123, loss = 0.18142024\n",
      "Iteration 124, loss = 0.18068942\n",
      "Iteration 125, loss = 0.17951523\n",
      "Iteration 126, loss = 0.17853664\n",
      "Iteration 127, loss = 0.17818289\n",
      "Iteration 128, loss = 0.17720876\n",
      "Iteration 129, loss = 0.17648666\n",
      "Iteration 130, loss = 0.17568220\n",
      "Iteration 131, loss = 0.17474460\n",
      "Iteration 132, loss = 0.17396306\n",
      "Iteration 133, loss = 0.17302330\n",
      "Iteration 134, loss = 0.17241846\n",
      "Iteration 135, loss = 0.17174464\n",
      "Iteration 136, loss = 0.17063967\n",
      "Iteration 137, loss = 0.17000555\n",
      "Iteration 138, loss = 0.16916603\n",
      "Iteration 139, loss = 0.16841804\n",
      "Iteration 140, loss = 0.16787589\n",
      "Iteration 141, loss = 0.16700042\n",
      "Iteration 142, loss = 0.16615814\n",
      "Iteration 143, loss = 0.16548960\n",
      "Iteration 144, loss = 0.16463729\n",
      "Iteration 145, loss = 0.16387971\n",
      "Iteration 146, loss = 0.16322541\n",
      "Iteration 147, loss = 0.16258122\n",
      "Iteration 148, loss = 0.16183351\n",
      "Iteration 149, loss = 0.16106088\n",
      "Iteration 150, loss = 0.16054449\n",
      "Iteration 151, loss = 0.15962974\n",
      "Iteration 152, loss = 0.15892143\n",
      "Iteration 153, loss = 0.15828194\n",
      "Iteration 154, loss = 0.15755032\n",
      "Iteration 155, loss = 0.15688079\n",
      "Iteration 156, loss = 0.15608425\n",
      "Iteration 157, loss = 0.15541679\n",
      "Iteration 158, loss = 0.15468730\n",
      "Iteration 159, loss = 0.15411059\n",
      "Iteration 160, loss = 0.15338789\n",
      "Iteration 161, loss = 0.15265260\n",
      "Iteration 162, loss = 0.15217887\n",
      "Iteration 163, loss = 0.15155761\n",
      "Iteration 164, loss = 0.15073673\n",
      "Iteration 165, loss = 0.15006339\n",
      "Iteration 166, loss = 0.14962664\n",
      "Iteration 167, loss = 0.14865427\n",
      "Iteration 168, loss = 0.14827114\n",
      "Iteration 169, loss = 0.14748394\n",
      "Iteration 170, loss = 0.14679204\n",
      "Iteration 171, loss = 0.14635387\n",
      "Iteration 172, loss = 0.14581076\n",
      "Iteration 173, loss = 0.14479387\n",
      "Iteration 174, loss = 0.14439314\n",
      "Iteration 175, loss = 0.14389250\n",
      "Iteration 176, loss = 0.14310125\n",
      "Iteration 177, loss = 0.14260790\n",
      "Iteration 178, loss = 0.14189950\n",
      "Iteration 179, loss = 0.14098901\n",
      "Iteration 180, loss = 0.14074272\n",
      "Iteration 181, loss = 0.14024986\n",
      "Iteration 182, loss = 0.13964720\n",
      "Iteration 183, loss = 0.13917926\n",
      "Iteration 184, loss = 0.13820332\n",
      "Iteration 185, loss = 0.13791340\n",
      "Iteration 186, loss = 0.13717173\n",
      "Iteration 187, loss = 0.13625332\n",
      "Iteration 188, loss = 0.13624890\n",
      "Iteration 189, loss = 0.13518799\n",
      "Iteration 190, loss = 0.13462417\n",
      "Iteration 191, loss = 0.13419776\n",
      "Iteration 192, loss = 0.13349472\n",
      "Iteration 193, loss = 0.13319847\n",
      "Iteration 194, loss = 0.13260053\n",
      "Iteration 195, loss = 0.13182428\n",
      "Iteration 196, loss = 0.13142038\n",
      "Iteration 197, loss = 0.13081531\n",
      "Iteration 198, loss = 0.13014376\n",
      "Iteration 199, loss = 0.12967388\n",
      "Iteration 200, loss = 0.12921647\n",
      "178.18217949999985\n",
      "SGD - Training Size: 90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.86337085\n",
      "Iteration 2, loss = 0.54075719\n",
      "Iteration 3, loss = 0.48372761\n",
      "Iteration 4, loss = 0.45274387\n",
      "Iteration 5, loss = 0.43201869\n",
      "Iteration 6, loss = 0.41628055\n",
      "Iteration 7, loss = 0.40383976\n",
      "Iteration 8, loss = 0.39370924\n",
      "Iteration 9, loss = 0.38487887\n",
      "Iteration 10, loss = 0.37695586\n",
      "Iteration 11, loss = 0.37003210\n",
      "Iteration 12, loss = 0.36369682\n",
      "Iteration 13, loss = 0.35817197\n",
      "Iteration 14, loss = 0.35282740\n",
      "Iteration 15, loss = 0.34791841\n",
      "Iteration 16, loss = 0.34336479\n",
      "Iteration 17, loss = 0.33900646\n",
      "Iteration 18, loss = 0.33535053\n",
      "Iteration 19, loss = 0.33146423\n",
      "Iteration 20, loss = 0.32769884\n",
      "Iteration 21, loss = 0.32441289\n",
      "Iteration 22, loss = 0.32118912\n",
      "Iteration 23, loss = 0.31803845\n",
      "Iteration 24, loss = 0.31509984\n",
      "Iteration 25, loss = 0.31228600\n",
      "Iteration 26, loss = 0.30948501\n",
      "Iteration 27, loss = 0.30677013\n",
      "Iteration 28, loss = 0.30425475\n",
      "Iteration 29, loss = 0.30163665\n",
      "Iteration 30, loss = 0.29952236\n",
      "Iteration 31, loss = 0.29693228\n",
      "Iteration 32, loss = 0.29470987\n",
      "Iteration 33, loss = 0.29238062\n",
      "Iteration 34, loss = 0.29046469\n",
      "Iteration 35, loss = 0.28812448\n",
      "Iteration 36, loss = 0.28625239\n",
      "Iteration 37, loss = 0.28399775\n",
      "Iteration 38, loss = 0.28206322\n",
      "Iteration 39, loss = 0.28003584\n",
      "Iteration 40, loss = 0.27806688\n",
      "Iteration 41, loss = 0.27631382\n",
      "Iteration 42, loss = 0.27448146\n",
      "Iteration 43, loss = 0.27269039\n",
      "Iteration 44, loss = 0.27081394\n",
      "Iteration 45, loss = 0.26904958\n",
      "Iteration 46, loss = 0.26751424\n",
      "Iteration 47, loss = 0.26566809\n",
      "Iteration 48, loss = 0.26412970\n",
      "Iteration 49, loss = 0.26247781\n",
      "Iteration 50, loss = 0.26107100\n",
      "Iteration 51, loss = 0.25910023\n",
      "Iteration 52, loss = 0.25767271\n",
      "Iteration 53, loss = 0.25615963\n",
      "Iteration 54, loss = 0.25472141\n",
      "Iteration 55, loss = 0.25291093\n",
      "Iteration 56, loss = 0.25145370\n",
      "Iteration 57, loss = 0.25017686\n",
      "Iteration 58, loss = 0.24870681\n",
      "Iteration 59, loss = 0.24705683\n",
      "Iteration 60, loss = 0.24561552\n",
      "Iteration 61, loss = 0.24431338\n",
      "Iteration 62, loss = 0.24310200\n",
      "Iteration 63, loss = 0.24189122\n",
      "Iteration 64, loss = 0.24022555\n",
      "Iteration 65, loss = 0.23886800\n",
      "Iteration 66, loss = 0.23734539\n",
      "Iteration 67, loss = 0.23645629\n",
      "Iteration 68, loss = 0.23496894\n",
      "Iteration 69, loss = 0.23369547\n",
      "Iteration 70, loss = 0.23255972\n",
      "Iteration 71, loss = 0.23116034\n",
      "Iteration 72, loss = 0.22987795\n",
      "Iteration 73, loss = 0.22865826\n",
      "Iteration 74, loss = 0.22738025\n",
      "Iteration 75, loss = 0.22611956\n",
      "Iteration 76, loss = 0.22486657\n",
      "Iteration 77, loss = 0.22381956\n",
      "Iteration 78, loss = 0.22262300\n",
      "Iteration 79, loss = 0.22130961\n",
      "Iteration 80, loss = 0.22015913\n",
      "Iteration 81, loss = 0.21886529\n",
      "Iteration 82, loss = 0.21817210\n",
      "Iteration 83, loss = 0.21665096\n",
      "Iteration 84, loss = 0.21528469\n",
      "Iteration 85, loss = 0.21458202\n",
      "Iteration 86, loss = 0.21343872\n",
      "Iteration 87, loss = 0.21243644\n",
      "Iteration 88, loss = 0.21099183\n",
      "Iteration 89, loss = 0.21007164\n",
      "Iteration 90, loss = 0.20893590\n",
      "Iteration 91, loss = 0.20779373\n",
      "Iteration 92, loss = 0.20675893\n",
      "Iteration 93, loss = 0.20567787\n",
      "Iteration 94, loss = 0.20463790\n",
      "Iteration 95, loss = 0.20341252\n",
      "Iteration 96, loss = 0.20264710\n",
      "Iteration 97, loss = 0.20150997\n",
      "Iteration 98, loss = 0.20041179\n",
      "Iteration 99, loss = 0.19935373\n",
      "Iteration 100, loss = 0.19858266\n",
      "Iteration 101, loss = 0.19742533\n",
      "Iteration 102, loss = 0.19637140\n",
      "Iteration 103, loss = 0.19543776\n",
      "Iteration 104, loss = 0.19465779\n",
      "Iteration 105, loss = 0.19357909\n",
      "Iteration 106, loss = 0.19255841\n",
      "Iteration 107, loss = 0.19170165\n",
      "Iteration 108, loss = 0.19083537\n",
      "Iteration 109, loss = 0.18954847\n",
      "Iteration 110, loss = 0.18886820\n",
      "Iteration 111, loss = 0.18809966\n",
      "Iteration 112, loss = 0.18723734\n",
      "Iteration 113, loss = 0.18591800\n",
      "Iteration 114, loss = 0.18500667\n",
      "Iteration 115, loss = 0.18404067\n",
      "Iteration 116, loss = 0.18336935\n",
      "Iteration 117, loss = 0.18269887\n",
      "Iteration 118, loss = 0.18128985\n",
      "Iteration 119, loss = 0.18080565\n",
      "Iteration 120, loss = 0.17962283\n",
      "Iteration 121, loss = 0.17884048\n",
      "Iteration 122, loss = 0.17796808\n",
      "Iteration 123, loss = 0.17720319\n",
      "Iteration 124, loss = 0.17623794\n",
      "Iteration 125, loss = 0.17534415\n",
      "Iteration 126, loss = 0.17448156\n",
      "Iteration 127, loss = 0.17374779\n",
      "Iteration 128, loss = 0.17302641\n",
      "Iteration 129, loss = 0.17212942\n",
      "Iteration 130, loss = 0.17108958\n",
      "Iteration 131, loss = 0.17028420\n",
      "Iteration 132, loss = 0.16943306\n",
      "Iteration 133, loss = 0.16879159\n",
      "Iteration 134, loss = 0.16794202\n",
      "Iteration 135, loss = 0.16723947\n",
      "Iteration 136, loss = 0.16628690\n",
      "Iteration 137, loss = 0.16560226\n",
      "Iteration 138, loss = 0.16474702\n",
      "Iteration 139, loss = 0.16380055\n",
      "Iteration 140, loss = 0.16339401\n",
      "Iteration 141, loss = 0.16253470\n",
      "Iteration 142, loss = 0.16169108\n",
      "Iteration 143, loss = 0.16094321\n",
      "Iteration 144, loss = 0.16020956\n",
      "Iteration 145, loss = 0.15946907\n",
      "Iteration 146, loss = 0.15869450\n",
      "Iteration 147, loss = 0.15779532\n",
      "Iteration 148, loss = 0.15736683\n",
      "Iteration 149, loss = 0.15642486\n",
      "Iteration 150, loss = 0.15575244\n",
      "Iteration 151, loss = 0.15524361\n",
      "Iteration 152, loss = 0.15427428\n",
      "Iteration 153, loss = 0.15382936\n",
      "Iteration 154, loss = 0.15280102\n",
      "Iteration 155, loss = 0.15219516\n",
      "Iteration 156, loss = 0.15153156\n",
      "Iteration 157, loss = 0.15066641\n",
      "Iteration 158, loss = 0.14992326\n",
      "Iteration 159, loss = 0.14946415\n",
      "Iteration 160, loss = 0.14860645\n",
      "Iteration 161, loss = 0.14798744\n",
      "Iteration 162, loss = 0.14728631\n",
      "Iteration 163, loss = 0.14647070\n",
      "Iteration 164, loss = 0.14598584\n",
      "Iteration 165, loss = 0.14521960\n",
      "Iteration 166, loss = 0.14468136\n",
      "Iteration 167, loss = 0.14395029\n",
      "Iteration 168, loss = 0.14312088\n",
      "Iteration 169, loss = 0.14273398\n",
      "Iteration 170, loss = 0.14212400\n",
      "Iteration 171, loss = 0.14132281\n",
      "Iteration 172, loss = 0.14080105\n",
      "Iteration 173, loss = 0.14002143\n",
      "Iteration 174, loss = 0.13965596\n",
      "Iteration 175, loss = 0.13870118\n",
      "Iteration 176, loss = 0.13827578\n",
      "Iteration 177, loss = 0.13748053\n",
      "Iteration 178, loss = 0.13707710\n",
      "Iteration 179, loss = 0.13632697\n",
      "Iteration 180, loss = 0.13591944\n",
      "Iteration 181, loss = 0.13517128\n",
      "Iteration 182, loss = 0.13446748\n",
      "Iteration 183, loss = 0.13392709\n",
      "Iteration 184, loss = 0.13339037\n",
      "Iteration 185, loss = 0.13297690\n",
      "Iteration 186, loss = 0.13195163\n",
      "Iteration 187, loss = 0.13166329\n",
      "Iteration 188, loss = 0.13110988\n",
      "Iteration 189, loss = 0.13028548\n",
      "Iteration 190, loss = 0.12985470\n",
      "Iteration 191, loss = 0.12950305\n",
      "Iteration 192, loss = 0.12868279\n",
      "Iteration 193, loss = 0.12809220\n",
      "Iteration 194, loss = 0.12759869\n",
      "Iteration 195, loss = 0.12687194\n",
      "Iteration 196, loss = 0.12634146\n",
      "Iteration 197, loss = 0.12583965\n",
      "Iteration 198, loss = 0.12526917\n",
      "Iteration 199, loss = 0.12473483\n",
      "Iteration 200, loss = 0.12419025\n",
      "192.61727470000005\n",
      "SGD - Training Size: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.88511174\n",
      "Iteration 2, loss = 0.54246532\n",
      "Iteration 3, loss = 0.48404271\n",
      "Iteration 4, loss = 0.45262625\n",
      "Iteration 5, loss = 0.43203950\n",
      "Iteration 6, loss = 0.41665004\n",
      "Iteration 7, loss = 0.40430486\n",
      "Iteration 8, loss = 0.39374464\n",
      "Iteration 9, loss = 0.38471385\n",
      "Iteration 10, loss = 0.37722532\n",
      "Iteration 11, loss = 0.37008198\n",
      "Iteration 12, loss = 0.36387032\n",
      "Iteration 13, loss = 0.35827516\n",
      "Iteration 14, loss = 0.35284452\n",
      "Iteration 15, loss = 0.34824770\n",
      "Iteration 16, loss = 0.34344236\n",
      "Iteration 17, loss = 0.33934664\n",
      "Iteration 18, loss = 0.33525290\n",
      "Iteration 19, loss = 0.33153632\n",
      "Iteration 20, loss = 0.32802235\n",
      "Iteration 21, loss = 0.32436214\n",
      "Iteration 22, loss = 0.32141555\n",
      "Iteration 23, loss = 0.31808092\n",
      "Iteration 24, loss = 0.31518573\n",
      "Iteration 25, loss = 0.31218270\n",
      "Iteration 26, loss = 0.30962622\n",
      "Iteration 27, loss = 0.30667676\n",
      "Iteration 28, loss = 0.30413224\n",
      "Iteration 29, loss = 0.30156893\n",
      "Iteration 30, loss = 0.29924479\n",
      "Iteration 31, loss = 0.29672698\n",
      "Iteration 32, loss = 0.29441239\n",
      "Iteration 33, loss = 0.29218574\n",
      "Iteration 34, loss = 0.28987013\n",
      "Iteration 35, loss = 0.28773483\n",
      "Iteration 36, loss = 0.28562484\n",
      "Iteration 37, loss = 0.28360388\n",
      "Iteration 38, loss = 0.28166142\n",
      "Iteration 39, loss = 0.27953330\n",
      "Iteration 40, loss = 0.27752401\n",
      "Iteration 41, loss = 0.27579966\n",
      "Iteration 42, loss = 0.27390545\n",
      "Iteration 43, loss = 0.27229296\n",
      "Iteration 44, loss = 0.27027305\n",
      "Iteration 45, loss = 0.26854008\n",
      "Iteration 46, loss = 0.26692408\n",
      "Iteration 47, loss = 0.26522872\n",
      "Iteration 48, loss = 0.26371910\n",
      "Iteration 49, loss = 0.26182148\n",
      "Iteration 50, loss = 0.26029963\n",
      "Iteration 51, loss = 0.25868285\n",
      "Iteration 52, loss = 0.25702107\n",
      "Iteration 53, loss = 0.25541517\n",
      "Iteration 54, loss = 0.25398348\n",
      "Iteration 55, loss = 0.25219903\n",
      "Iteration 56, loss = 0.25102407\n",
      "Iteration 57, loss = 0.24961026\n",
      "Iteration 58, loss = 0.24808309\n",
      "Iteration 59, loss = 0.24677757\n",
      "Iteration 60, loss = 0.24527713\n",
      "Iteration 61, loss = 0.24412430\n",
      "Iteration 62, loss = 0.24242607\n",
      "Iteration 63, loss = 0.24123416\n",
      "Iteration 64, loss = 0.23982251\n",
      "Iteration 65, loss = 0.23851007\n",
      "Iteration 66, loss = 0.23705875\n",
      "Iteration 67, loss = 0.23602119\n",
      "Iteration 68, loss = 0.23492914\n",
      "Iteration 69, loss = 0.23332906\n",
      "Iteration 70, loss = 0.23219285\n",
      "Iteration 71, loss = 0.23093117\n",
      "Iteration 72, loss = 0.22978115\n",
      "Iteration 73, loss = 0.22837698\n",
      "Iteration 74, loss = 0.22743476\n",
      "Iteration 75, loss = 0.22627472\n",
      "Iteration 76, loss = 0.22503224\n",
      "Iteration 77, loss = 0.22382166\n",
      "Iteration 78, loss = 0.22280733\n",
      "Iteration 79, loss = 0.22164515\n",
      "Iteration 80, loss = 0.22061142\n",
      "Iteration 81, loss = 0.21946371\n",
      "Iteration 82, loss = 0.21846816\n",
      "Iteration 83, loss = 0.21714726\n",
      "Iteration 84, loss = 0.21602372\n",
      "Iteration 85, loss = 0.21512736\n",
      "Iteration 86, loss = 0.21394936\n",
      "Iteration 87, loss = 0.21276744\n",
      "Iteration 88, loss = 0.21203976\n",
      "Iteration 89, loss = 0.21075640\n",
      "Iteration 90, loss = 0.20972603\n",
      "Iteration 91, loss = 0.20876652\n",
      "Iteration 92, loss = 0.20787699\n",
      "Iteration 93, loss = 0.20666696\n",
      "Iteration 94, loss = 0.20578532\n",
      "Iteration 95, loss = 0.20462213\n",
      "Iteration 96, loss = 0.20376774\n",
      "Iteration 97, loss = 0.20268008\n",
      "Iteration 98, loss = 0.20175463\n",
      "Iteration 99, loss = 0.20089548\n",
      "Iteration 100, loss = 0.19986655\n",
      "Iteration 101, loss = 0.19899553\n",
      "Iteration 102, loss = 0.19774950\n",
      "Iteration 103, loss = 0.19685714\n",
      "Iteration 104, loss = 0.19618463\n",
      "Iteration 105, loss = 0.19520858\n",
      "Iteration 106, loss = 0.19421573\n",
      "Iteration 107, loss = 0.19317594\n",
      "Iteration 108, loss = 0.19253292\n",
      "Iteration 109, loss = 0.19152330\n",
      "Iteration 110, loss = 0.19056711\n",
      "Iteration 111, loss = 0.18964309\n",
      "Iteration 112, loss = 0.18882837\n",
      "Iteration 113, loss = 0.18787964\n",
      "Iteration 114, loss = 0.18700877\n",
      "Iteration 115, loss = 0.18663506\n",
      "Iteration 116, loss = 0.18530734\n",
      "Iteration 117, loss = 0.18463037\n",
      "Iteration 118, loss = 0.18370558\n",
      "Iteration 119, loss = 0.18264127\n",
      "Iteration 120, loss = 0.18203202\n",
      "Iteration 121, loss = 0.18111200\n",
      "Iteration 122, loss = 0.18033271\n",
      "Iteration 123, loss = 0.17951241\n",
      "Iteration 124, loss = 0.17875692\n",
      "Iteration 125, loss = 0.17792808\n",
      "Iteration 126, loss = 0.17696393\n",
      "Iteration 127, loss = 0.17636910\n",
      "Iteration 128, loss = 0.17560412\n",
      "Iteration 129, loss = 0.17462130\n",
      "Iteration 130, loss = 0.17383601\n",
      "Iteration 131, loss = 0.17319776\n",
      "Iteration 132, loss = 0.17264751\n",
      "Iteration 133, loss = 0.17165002\n",
      "Iteration 134, loss = 0.17079175\n",
      "Iteration 135, loss = 0.17006861\n",
      "Iteration 136, loss = 0.16944591\n",
      "Iteration 137, loss = 0.16841400\n",
      "Iteration 138, loss = 0.16790789\n",
      "Iteration 139, loss = 0.16691402\n",
      "Iteration 140, loss = 0.16628689\n",
      "Iteration 141, loss = 0.16562710\n",
      "Iteration 142, loss = 0.16466681\n",
      "Iteration 143, loss = 0.16418195\n",
      "Iteration 144, loss = 0.16362338\n",
      "Iteration 145, loss = 0.16275805\n",
      "Iteration 146, loss = 0.16200913\n",
      "Iteration 147, loss = 0.16143170\n",
      "Iteration 148, loss = 0.16057449\n",
      "Iteration 149, loss = 0.15987917\n",
      "Iteration 150, loss = 0.15903315\n",
      "Iteration 151, loss = 0.15851358\n",
      "Iteration 152, loss = 0.15785258\n",
      "Iteration 153, loss = 0.15698208\n",
      "Iteration 154, loss = 0.15652247\n",
      "Iteration 155, loss = 0.15577078\n",
      "Iteration 156, loss = 0.15514872\n",
      "Iteration 157, loss = 0.15446743\n",
      "Iteration 158, loss = 0.15353001\n",
      "Iteration 159, loss = 0.15316399\n",
      "Iteration 160, loss = 0.15235125\n",
      "Iteration 161, loss = 0.15184387\n",
      "Iteration 162, loss = 0.15103836\n",
      "Iteration 163, loss = 0.15050952\n",
      "Iteration 164, loss = 0.14980486\n",
      "Iteration 165, loss = 0.14890042\n",
      "Iteration 166, loss = 0.14843412\n",
      "Iteration 167, loss = 0.14762636\n",
      "Iteration 168, loss = 0.14726139\n",
      "Iteration 169, loss = 0.14643905\n",
      "Iteration 170, loss = 0.14591148\n",
      "Iteration 171, loss = 0.14493313\n",
      "Iteration 172, loss = 0.14483741\n",
      "Iteration 173, loss = 0.14404405\n",
      "Iteration 174, loss = 0.14332648\n",
      "Iteration 175, loss = 0.14303647\n",
      "Iteration 176, loss = 0.14191328\n",
      "Iteration 177, loss = 0.14173564\n",
      "Iteration 178, loss = 0.14094347\n",
      "Iteration 179, loss = 0.14037327\n",
      "Iteration 180, loss = 0.13987423\n",
      "Iteration 181, loss = 0.13923241\n",
      "Iteration 182, loss = 0.13860603\n",
      "Iteration 183, loss = 0.13788169\n",
      "Iteration 184, loss = 0.13732372\n",
      "Iteration 185, loss = 0.13684572\n",
      "Iteration 186, loss = 0.13620205\n",
      "Iteration 187, loss = 0.13589002\n",
      "Iteration 188, loss = 0.13512437\n",
      "Iteration 189, loss = 0.13454744\n",
      "Iteration 190, loss = 0.13414869\n",
      "Iteration 191, loss = 0.13337622\n",
      "Iteration 192, loss = 0.13286531\n",
      "Iteration 193, loss = 0.13227853\n",
      "Iteration 194, loss = 0.13157674\n",
      "Iteration 195, loss = 0.13108998\n",
      "Iteration 196, loss = 0.13054920\n",
      "Iteration 197, loss = 0.13024308\n",
      "Iteration 198, loss = 0.12964040\n",
      "Iteration 199, loss = 0.12902734\n",
      "Iteration 200, loss = 0.12844036\n",
      "222.0792262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\CS7641\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for solver in solvers:\n",
    "    clf = MLPClassifier(solver=solver.lower(), max_iter=200, verbose=1, hidden_layer_sizes=(100,))\n",
    "    for i in range(1, 11, 1):\n",
    "        print(\"{} - Training Size: {}%\".format(solver, (i * 10)))\n",
    "        start_time = timer()\n",
    "        with parallel_backend('threading'):\n",
    "            clf.fit(training_data[:int((60000 * (0.1 * i))), :], training_labels[:int((60000 * (0.1 * i)))])\n",
    "        end_time = timer()\n",
    "        elapsed_time = end_time - start_time\n",
    "        if i == 10:\n",
    "            classifier_list.append(clf)\n",
    "        print(elapsed_time)\n",
    "        if solver == \"SGD\":\n",
    "            sgd_accuracy.append(clf.score(testing_data, testing_labels))\n",
    "            sgd_runtime.append(elapsed_time)\n",
    "        else:\n",
    "            adam_accuracy.append(clf.score(testing_data, testing_labels))\n",
    "            adam_runtime.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_accuracy = np.asarray(adam_accuracy)\n",
    "adam_runtime = np.asarray(adam_runtime)\n",
    "sgd_accuracy = np.asarray(sgd_accuracy)\n",
    "sgd_runtime = np.asarray(sgd_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_accuracy.tofile('adam_accuracy_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "adam_runtime.tofile('adam_runtime_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "sgd_accuracy.tofile('sgd_accuracy_{}.csv'.format(DataSetName),sep=',',format='%.3f')\n",
    "sgd_runtime.tofile('sgd_runtime_{}.csv'.format(DataSetName),sep=',',format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nResults\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Results\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = [\"tab:orange\", \"tab:blue\", \"tab:green\", \"tab:red\"]\n",
    "\n",
    "run = [sgd_runtime, adam_runtime]\n",
    "acc = [sgd_accuracy, adam_accuracy]\n",
    "\n",
    "for solver in range(len(solvers)):\n",
    "    with plt.style.context('ggplot'):\n",
    "        fig0, ax0 = plt.subplots()\n",
    "        ax0.set_xlabel(\"Percent of Training Set\")\n",
    "        ax0.set_ylabel(\"Accuracy (%)\", color='tab:orange')\n",
    "        ax0.set_title(\"Accuracy vs Training Set Size vs Training Time {} \\n {}\".format(solvers[solver], DataSetName))\n",
    "        ax0.tick_params(axis='y', labelcolor=\"black\")\n",
    "        ax0.set_ylim(0, 1.1)\n",
    "        ax3 = ax0.twinx()\n",
    "        ax3.set_ylabel(\"Training Time (s)\", color=\"tab:blue\")\n",
    "        ax3.set_ylim(0, max(max(adam_runtime), max(sgd_runtime)) + 10)\n",
    "        ax3.tick_params(axis='y', labelcolor=\"black\")\n",
    "        for i in range(1):        \n",
    "            ax0.plot([i for i in range(11)], acc[solver], colors[i], marker='o', label=solvers[solver])\n",
    "            ax3.plot([i for i in range(11)], run[solver], colors[i+1], marker=\"1\", label=\"{} training-time\".format(solvers[solver]))\n",
    "        fig0.tight_layout()\n",
    "        directory = \"{}/Training_{}_{}_Set_Size_Impact_vs_Training_Time.png\".format(cwd, solvers[solver], DataSetName)\n",
    "        plt.savefig(directory)\n",
    "#         plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classifier_list)):\n",
    "    temp = np.asarray(classifier_list[i].loss_curve_)\n",
    "    temp.tofile('{}_Loss_Curve_{}.csv'.format(solvers[i], DataSetName),sep=',',format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = 0\n",
    "for net in classifier_list:\n",
    "    with plt.style.context('bmh'):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xlabel(\"Iterations\")\n",
    "        ax.set_ylabel(\"Loss (%)\")\n",
    "        ax.set_title(\"Loss vs Iterations ({})\".format(solvers[count]))\n",
    "        ax.set_ylim(0, 1.1)\n",
    "\n",
    "        ax.plot([i for i in range(len(net.loss_curve_))], net.loss_curve_, marker='o',\n",
    "                label=solvers[count])\n",
    "        ax.legend()\n",
    "        plt.savefig(\"{}/{}_{}_Training_Size_Impact.png\"\n",
    "                    .format(cwd, solvers[count], DataSetName))\n",
    "        count += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
